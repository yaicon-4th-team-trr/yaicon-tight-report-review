Skip to main content

[![Cornell University](/static/browse/0.3.4/images/icons/cu/cornell-reduced-
white-SMALL.svg)](https://www.cornell.edu/)

We gratefully acknowledge support from the Simons Foundation, [member
institutions](https://info.arxiv.org/about/ourmembers.html), and all
contributors. [Donate](https://info.arxiv.org/about/donate.html)

[]({url_path\('ignore_me'\)})

[![arxiv logo](/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](/)
> [cs](/list/cs/recent) > arXiv:2212.10560

[Help](https://info.arxiv.org/help) | [Advanced
Search](https://arxiv.org/search/advanced)

All fields Title Author Abstract Comments Journal reference ACM classification
MSC classification Report number arXiv identifier DOI ORCID arXiv author ID
Help pages Full text

Search

[![arXiv logo](/static/browse/0.3.4/images/arxiv-logomark-small-
white.svg)](https://arxiv.org/)

[ ![Cornell University Logo](/static/browse/0.3.4/images/icons/cu/cornell-
reduced-white-SMALL.svg) ](https://www.cornell.edu/)

open search

GO

open navigation menu

## quick links

  * [Login](https://arxiv.org/login)
  * [Help Pages](https://info.arxiv.org/help)
  * [About](https://info.arxiv.org/about)

# Computer Science > Computation and Language

**arXiv:2212.10560** (cs)

[Submitted on 20 Dec 2022 ([v1](https://arxiv.org/abs/2212.10560v1)), last
revised 25 May 2023 (this version, v2)]

# Title:Self-Instruct: Aligning Language Models with Self-Generated
Instructions

Authors:[Yizhong
Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+Y), [Yeganeh
Kordi](https://arxiv.org/search/cs?searchtype=author&query=Kordi,+Y), [Swaroop
Mishra](https://arxiv.org/search/cs?searchtype=author&query=Mishra,+S), [Alisa
Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+A), [Noah A.
Smith](https://arxiv.org/search/cs?searchtype=author&query=Smith,+N+A),
[Daniel
Khashabi](https://arxiv.org/search/cs?searchtype=author&query=Khashabi,+D),
[Hannaneh
Hajishirzi](https://arxiv.org/search/cs?searchtype=author&query=Hajishirzi,+H)

View a PDF of the paper titled Self-Instruct: Aligning Language Models with
Self-Generated Instructions, by Yizhong Wang and 6 other authors

[View PDF](/pdf/2212.10560)

> Abstract:Large "instruction-tuned" language models (i.e., finetuned to
> respond to instructions) have demonstrated a remarkable ability to
> generalize zero-shot to new tasks. Nevertheless, they depend heavily on
> human-written instruction data that is often limited in quantity, diversity,
> and creativity, therefore hindering the generality of the tuned model. We
> introduce Self-Instruct, a framework for improving the instruction-following
> capabilities of pretrained language models by bootstrapping off their own
> generations. Our pipeline generates instructions, input, and output samples
> from a language model, then filters invalid or similar ones before using
> them to finetune the original model. Applying our method to the vanilla
> GPT3, we demonstrate a 33% absolute improvement over the original model on
> Super-NaturalInstructions, on par with the performance of InstructGPT-001,
> which was trained with private user data and human annotations. For further
> evaluation, we curate a set of expert-written instructions for novel tasks,
> and show through human evaluation that tuning GPT3 with Self-Instruct
> outperforms using existing public instruction datasets by a large margin,
> leaving only a 5% absolute gap behind InstructGPT-001. Self-Instruct
> provides an almost annotation-free method for aligning pre-trained language
> models with instructions, and we release our large synthetic dataset to
> facilitate future studies on instruction tuning. Our code and data are
> available at [this https URL](https://github.com/yizhongw/self-instruct).

Comments: | ACL 2023 camera ready, 23 pages, 9 figures, 11 tables  
---|---  
Subjects: |  Computation and Language (cs.CL); Artificial Intelligence (cs.AI)  
Cite as: | [arXiv:2212.10560](https://arxiv.org/abs/2212.10560) [cs.CL]  
  | (or  [arXiv:2212.10560v2](https://arxiv.org/abs/2212.10560v2) [cs.CL] for
this version)  
  |  <https://doi.org/10.48550/arXiv.2212.10560>

Focus to learn more

arXiv-issued DOI via DataCite  
  
## Submission history

From: Yizhong Wang [[view email](/show-email/303371ba/2212.10560)]  
**[[v1]](/abs/2212.10560v1)** Tue, 20 Dec 2022 18:59:19 UTC (4,072 KB)  
**[v2]** Thu, 25 May 2023 23:50:07 UTC (7,954 KB)  

Full-text links:

## Access Paper:

View a PDF of the paper titled Self-Instruct: Aligning Language Models with
Self-Generated Instructions, by Yizhong Wang and 6 other authors

  * [View PDF](/pdf/2212.10560)
  * [TeX Source](/src/2212.10560)
  * [Other Formats](/format/2212.10560)

[ ![license icon](https://arxiv.org/icons/licenses/by-4.0.png) view license
](http://creativecommons.org/licenses/by/4.0/ "Rights to this article")

Current browse context:

cs.CL

[< prev](/prevnext?id=2212.10560&function=prev&context=cs.CL "previous in
cs.CL \(accesskey p\)")   |   [next
>](/prevnext?id=2212.10560&function=next&context=cs.CL "next in cs.CL
\(accesskey n\)")  

[new](/list/cs.CL/new) |  [recent](/list/cs.CL/recent) |
[2022-12](/list/cs.CL/2022-12)

Change to browse by:

[cs](/abs/2212.10560?context=cs)  
[cs.AI](/abs/2212.10560?context=cs.AI)  

### References & Citations

  * [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2212.10560)
  * [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2212.10560)
  * [Semantic Scholar](https://api.semanticscholar.org/arXiv:2212.10560)

[a](/static/browse/0.3.4/css/cite.css) export BibTeX citation Loading...

## BibTeX formatted citation

Ã—

loading...

Data provided by:

### Bookmark

[ ![BibSonomy logo](/static/browse/0.3.4/images/icons/social/bibsonomy.png)
](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2212.10560&description=Self-
Instruct: Aligning Language Models with Self-Generated Instructions "Bookmark
on BibSonomy") [ ![Reddit
logo](/static/browse/0.3.4/images/icons/social/reddit.png)
](https://reddit.com/submit?url=https://arxiv.org/abs/2212.10560&title=Self-
Instruct: Aligning Language Models with Self-Generated Instructions "Bookmark
on Reddit")

Bibliographic Tools

# Bibliographic and Citation Tools

Bibliographic Explorer Toggle

Bibliographic Explorer _([What is the
Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-
explorer))_

Litmaps Toggle

Litmaps _([What is Litmaps?](https://www.litmaps.co/))_

scite.ai Toggle

scite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_

Code, Data, Media

# Code, Data and Media Associated with this Article

Links to Code Toggle

CatalyzeX Code Finder for Papers _([What is
CatalyzeX?](https://www.catalyzex.com))_

DagsHub Toggle

DagsHub _([What is DagsHub?](https://dagshub.com/))_

GotitPub Toggle

Gotit.pub _([What is GotitPub?](http://gotit.pub/faq))_

Links to Code Toggle

Papers with Code _([What is Papers with Code?](https://paperswithcode.com/))_

ScienceCast Toggle

ScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_

Demos

# Demos

Replicate Toggle

Replicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_

Spaces Toggle

Hugging Face Spaces _([What is
Spaces?](https://huggingface.co/docs/hub/spaces))_

Spaces Toggle

TXYZ.AI _([What is TXYZ.AI?](https://txyz.ai))_

Related Papers

# Recommenders and Search Tools

Link to Influence Flower

Influence Flower _([What are Influence
Flowers?](https://influencemap.cmlab.dev/))_

Connected Papers Toggle

Connected Papers _([What is Connected
Papers?](https://www.connectedpapers.com/about))_

Core recommender toggle

CORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_

  * Author
  * Venue
  * Institution
  * Topic

About arXivLabs

# arXivLabs: experimental projects with community collaborators

arXivLabs is a framework that allows collaborators to develop and share new
arXiv features directly on our website.

Both individuals and organizations that work with arXivLabs have embraced and
accepted our values of openness, community, excellence, and user data privacy.
arXiv is committed to these values and only works with partners that adhere to
them.

Have an idea for a project that will add value for arXiv's community? [**Learn
more about arXivLabs**](https://info.arxiv.org/labs/index.html).

[Which authors of this paper are endorsers?](/auth/show-endorsers/2212.10560)
| [Disable MathJax](javascript:setMathjaxCookie\(\)) ([What is
MathJax?](https://info.arxiv.org/help/mathjax.html))

  * [About](https://info.arxiv.org/about)
  * [Help](https://info.arxiv.org/help)

  * contact arXivClick here to contact arXiv [ Contact](https://info.arxiv.org/help/contact.html)
  * subscribe to arXiv mailingsClick here to subscribe [ Subscribe](https://info.arxiv.org/help/subscribe)

  * [Copyright](https://info.arxiv.org/help/license/index.html)
  * [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)

  * [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)
  * [arXiv Operational Status ](https://status.arxiv.org)  
Get status notifications via
[email](https://subscribe.sorryapp.com/24846f03/email/new) or
[slack](https://subscribe.sorryapp.com/24846f03/slack/new)

