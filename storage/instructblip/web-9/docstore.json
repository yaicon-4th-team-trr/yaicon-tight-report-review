{"docstore/metadata": {"c9ef9b7c-6dd0-4935-a552-9b3674a6f388": {"doc_hash": "0aabd50dc4c5ab13f3a917f150b8976adb00326a2a0654b2e879c8710f3cc572"}, "9e1bb884-42d3-4a53-b6fd-0c763c91b8ff": {"doc_hash": "0dddf5bf69a835a468364a576ba8cf9cfe899cf6170088b0f0a5fd5cae2a8af7", "ref_doc_id": "c9ef9b7c-6dd0-4935-a552-9b3674a6f388"}, "7344652d-6789-4c15-96cc-ea8f7128b966": {"doc_hash": "253ce19eb04bcc376e45f7bedf37452dfa4fe826a9be2ed58e6f3f656efa976a"}, "e504fc55-ba53-482d-8ee8-08eb0be8e6f2": {"doc_hash": "db8c5cc228bad7229d7a3112e3fd3f3d79bf0dedcd650b40ef74102a1a46b269", "ref_doc_id": "7344652d-6789-4c15-96cc-ea8f7128b966"}, "951cb1fd-c1c1-48e4-9e60-c1db7e07330d": {"doc_hash": "31d4fe5e986c94b6827098c11f56fad1bfb4ba2a672704a0f9407e14a4c143d9", "ref_doc_id": "7344652d-6789-4c15-96cc-ea8f7128b966"}, "a0be635d-53c4-4af1-aa1f-159804d24d42": {"doc_hash": "b1cc6360c81ae0ce5ba01dbc2b10cabb9c8f19642c960619187b4c5e6ca3e372"}, "c0b1c862-2f78-4caa-9563-fbf240184e19": {"doc_hash": "1aab6d60cfd80a3ef70080fa1cedf5402af6b77865c0bb3b61a101f28dc41c6c", "ref_doc_id": "a0be635d-53c4-4af1-aa1f-159804d24d42"}, "76e09f0d-354d-49eb-8183-61a2659bc563": {"doc_hash": "53a9f33a0315888a21212387226e476c731162233222299977007705018a4b22", "ref_doc_id": "a0be635d-53c4-4af1-aa1f-159804d24d42"}, "e0d9fd1d-07e8-459b-9e75-8fb3f251a5e8": {"doc_hash": "c3c046ed2a5e776f157a17f0abaaf9aa65e93ad0b36c4dde4e9d3cf3a2c2b579", "ref_doc_id": "a0be635d-53c4-4af1-aa1f-159804d24d42"}, "904ecbfa-69e9-4ab9-859c-d6fe5dbb6772": {"doc_hash": "995d066284df103c6a73e044eedada3b97ed31eb97d2935d1b015af4e5a054c2", "ref_doc_id": "a0be635d-53c4-4af1-aa1f-159804d24d42"}, "df597bea-1054-4d7c-80a9-a79b03167424": {"doc_hash": "46910d84705f387d0f3f07c0ed6a783be7f47ea827917bb362bc0b34b77b7069", "ref_doc_id": "a0be635d-53c4-4af1-aa1f-159804d24d42"}, "0e1af00a-a606-4caf-abe2-3c87351354ab": {"doc_hash": "c213d5036bfa8c305dc58c9e1dc17ef4739fb243627f754e5d18aa411c68e5f5", "ref_doc_id": "a0be635d-53c4-4af1-aa1f-159804d24d42"}, "6de95ee5-2f6b-4475-a7bc-5a0e045bbfac": {"doc_hash": "3961f979139e3c16d90b5202ee0b1ab1263d9a80675b4359a9dc6397676432eb", "ref_doc_id": "a0be635d-53c4-4af1-aa1f-159804d24d42"}, "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b": {"doc_hash": "7ec8d3e8c95c039a749fa1f4b91865231544965d851248e250e60e4fdd0c54f5"}, "e9ce05d6-e33a-40d9-94b7-0d3187b003af": {"doc_hash": "ff1964a500a05435310fad482d228345160b5575c8741078a5e21a646d7e3a06", "ref_doc_id": "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b"}, "ff8aada7-d24d-4eb8-bd37-d8bf6a2c07f1": {"doc_hash": "1d1ab6e5c037a3918178a5547c71717da9aa48d3aa3a05a4a359e3aa2ef0c4ff", "ref_doc_id": "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b"}, "bfa1340d-53c2-4715-ba59-b0a5b404a84b": {"doc_hash": "164479d30e29dc2cd5e3e94c53e29cbca27df5e592fa0b4e2a83b2cfddad34e9", "ref_doc_id": "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b"}, "03631b0e-5da0-4baa-8eb9-b90ff2c02826": {"doc_hash": "9c96786e9d2c117aae8294092cf8b5db0cfbed46c1e78905c365efbf7dac00ab", "ref_doc_id": "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b"}, "93ad53d0-8842-433d-94f9-a8e6ad6c83b9": {"doc_hash": "ec94e150f26fff6a2f5c34bba184983fe5acd53b6791b03537fdddfe2bfe53ee"}, "128387ff-4463-4a80-9d22-f9b9393e8e1d": {"doc_hash": "ce21cec05c02fece9a3a4b5b7f3a011c4c3e19a062083d04276043ae44cd5222", "ref_doc_id": "93ad53d0-8842-433d-94f9-a8e6ad6c83b9"}, "8381e89e-3d9a-43ee-b0ce-0b28e3d6276b": {"doc_hash": "c7d27989e25178a7a77d5e5d633b41115ae7c67b3b4a62225422f172ea3b2aa7", "ref_doc_id": "93ad53d0-8842-433d-94f9-a8e6ad6c83b9"}, "f6208959-dd0a-4c25-af91-3bb8b2e8e4a1": {"doc_hash": "0bf31c347150c67642cdd8283068d0cd8f02e1edc4584cee48db104b5384dc25", "ref_doc_id": "93ad53d0-8842-433d-94f9-a8e6ad6c83b9"}, "fbf0b3ce-8fdd-4b54-aa50-91e99160d972": {"doc_hash": "cc4fc04c0884622972ce995a87a35310d8b0a495ae107ed3856fef22e13c7c09", "ref_doc_id": "93ad53d0-8842-433d-94f9-a8e6ad6c83b9"}, "bee567a9-3d08-41be-a2ee-10c916f2455f": {"doc_hash": "a42c55c505b074ea197382be92203906d53bcd2cae8ecb115249517a307bdd66"}, "774dad0b-ea64-4c36-b0f5-fcbd871218c3": {"doc_hash": "a8c7e7dfb689d1ac80d99aa146daa0c293b689b14049ad2cd01114544210a429", "ref_doc_id": "bee567a9-3d08-41be-a2ee-10c916f2455f"}, "736ffa74-53d0-4fef-ae17-a0ac147eb3f5": {"doc_hash": "3377c496cd2f339e353466d1f8f52310bb3c39c60cf89436c22f40a7d550c6c0"}, "b5b458c9-ec3d-4cfd-8e07-a4b30b392533": {"doc_hash": "49ca68e4eb354e74cc396b03aa6c81f71a05fc8ca769fb3316ad5065f5259a86", "ref_doc_id": "736ffa74-53d0-4fef-ae17-a0ac147eb3f5"}, "77aaeb5f-e9bc-41a8-b6fc-6adce564b68e": {"doc_hash": "dff3493b8207721505736a428e48cac040f73a9c339a79d7f75dd4cbc170b69c", "ref_doc_id": "736ffa74-53d0-4fef-ae17-a0ac147eb3f5"}, "718a8243-5290-4bcc-9e58-53e28796a3a0": {"doc_hash": "2e4b5cc32d5372c62f163e89154bf5150888ef4bd36f8bb475c4d875e66c7239", "ref_doc_id": "736ffa74-53d0-4fef-ae17-a0ac147eb3f5"}, "93745d78-19d1-453e-9c94-4b1fb5fb8cc8": {"doc_hash": "93bfa653cfaadc33d25c83163c03f9323391cccb3ecfff62969ab1e603ff400e"}, "24719111-9af2-4786-8839-f72734d6dd93": {"doc_hash": "bde3f7eb59e1e5ca284083747a0bb9f7bf57caed886151852b024d814153b6e0", "ref_doc_id": "93745d78-19d1-453e-9c94-4b1fb5fb8cc8"}, "fdef97b7-bee4-478b-9056-9055c4a71454": {"doc_hash": "03ab42e8ebb7b6478b337b40d0303fb346f3272940ff3b9ce310216cf19597fe", "ref_doc_id": "93745d78-19d1-453e-9c94-4b1fb5fb8cc8"}, "214a3f20-1676-40bd-b0b5-d84d9be7ff33": {"doc_hash": "6efdc8f05440fa1b5abb2a3b7a791aa0628b3034c21e71e0d6b99cb5cfa5a8c1", "ref_doc_id": "93745d78-19d1-453e-9c94-4b1fb5fb8cc8"}, "58c0404a-5344-4120-9114-567073e84eae": {"doc_hash": "5a2a48ee2edd95cff0a138af81c5d0505ad19a8c674bd4653d299e7fbf904fc1"}, "0fee632c-f8a3-4512-9eea-6f99b0f2f33a": {"doc_hash": "ca6c54f617529cb4d4eedb2dea154fdf97c17fad2bd12ed8fb7aa50463d0f3b9", "ref_doc_id": "58c0404a-5344-4120-9114-567073e84eae"}, "6f341021-8fd7-4af6-bd3a-2f2f6518161a": {"doc_hash": "dd67261c69fbd9607c918bc4c82675dc17d0ca6fe8561205ab2dff3cda538921", "ref_doc_id": "58c0404a-5344-4120-9114-567073e84eae"}, "39a6f96e-0092-4108-9efe-e5188c4d7b5b": {"doc_hash": "bf99c6623c61a7f3df09cdf8da68f8312eb1a5fdc232573f35278e6e20adabf5", "ref_doc_id": "58c0404a-5344-4120-9114-567073e84eae"}, "653071b9-84f6-402b-a0a3-befc27ca14cb": {"doc_hash": "4f9d888ffbb03579c0d82ab0b8fb2b13d02e6b3b875ba27f89c857f20a7311a1", "ref_doc_id": "58c0404a-5344-4120-9114-567073e84eae"}, "68f8468d-9422-45c4-af8e-1e2d6a0b910d": {"doc_hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b"}, "2bff4304-f47f-4130-a344-3f16f56915d1": {"doc_hash": "7f8718fe251685e8bb7847ecc10286ba14dd93df9cbf70722dfa578f9fb6b491", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "09837228-925f-41d0-a672-1e1a9d909905": {"doc_hash": "dccf9c6276056cfc439524c2052c6515115c7a65ec0bf4ce69803f7b28211a69", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "d6016afa-1808-40dc-8f75-b749e7750b53": {"doc_hash": "32076d8d372c7f4dd3e317330d3c744a914e6a87ad166efef4734747bd249a1d", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "2ac50580-600c-4f0e-930b-e591e9190573": {"doc_hash": "049fc913a0173ce3753a2c33055b84bc249f14f65016ad4f073e52327a96c06b", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "2c8118d5-8ee6-459a-8d47-d0adeb7c88ea": {"doc_hash": "edde167762c4f2e3ec16466516227701e137b7e516cd9674a8f280d81836cad9", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "e4132a9e-01fc-4b83-a576-900a601a81dc": {"doc_hash": "59ce563b1a39e341042884da956f63670fba88ad1fceba4af9e0ddce2e4bd43e", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "63e78434-4316-43fc-98b4-bb5a102b5a82": {"doc_hash": "ece52e8c6d99749c09809342916d234324ca6644080fc7eab80c9816b2da3e15", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f6221846-2f0b-4d27-b2f5-d4764f14f363": {"doc_hash": "721e262400a7828f1ebdb767a50d089f95e2a5dea92f388046e42ddeee5eaa37", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f50b83d7-83c4-4364-b9fb-c2c54c13a5d0": {"doc_hash": "be08c546ea2936891d942ce108a583e1091a4f010192e6ffbaa8169903a6aff0", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "29a3955f-1eec-4f21-b111-4a930a04fc57": {"doc_hash": "a045e90f30cdbf03120bc308d4f41ced98c617f90eb8d2d040a3eb8bd64c7185", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "69e42855-2b5b-4a27-ae9a-c7a7a9b6a80e": {"doc_hash": "21c802016c667d46960e8514164d5cb3e2d1d08e7b5c23407b0751324a66b047", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "09e07a31-cbf9-4575-871f-82c65c439d4d": {"doc_hash": "14f0ac8e5bd81afb8ff3981135997b8aba3a09a4ae79d5552e07d715d5bc83eb", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "7cc687bb-5bbf-4d3a-884a-b6d51734215d": {"doc_hash": "abec2387ae2bcc4c633e26eafaf69a562adb4da867e71e159ddde335cdaef783", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "1796d83a-5be7-42b6-87ec-24399b21afa3": {"doc_hash": "0941370ad3e87c0f8191d2916fb50fe2248aef578f0da4c72c2452576a8421dc", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "1b4f63ef-c861-4800-9b23-19aa1867c6fc": {"doc_hash": "5fc18e31536107f4b45a35b018434f8b426c62d7487baa3eb5c7927e37faafc2", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "692dd480-b89f-44eb-bd18-a271fc308a31": {"doc_hash": "4b43cffb19c651203a32e11f03206cc827b225a6e999a9610ccbd8bff7929746", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "7847cd41-6bf2-496d-b331-006630532bf6": {"doc_hash": "c44658ab724cb7cba6e9cd08ede21b9239bd7bfb5696151d93456f8ca740addf", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "48e7530b-4abb-43eb-ba42-8ed2c5d3d1f8": {"doc_hash": "d029097e55233a955e39ef08c4cc7e60584667af9f3037edfef75d008fce1c3c", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f38f7c57-2595-4a26-a283-eac7b1493f8c": {"doc_hash": "3d446ac2ad2036509c515138f792f1272c24f0a55d7c9a7b7b2482e5627bf3ee", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "de2f43e5-81a4-4b76-971b-09d56f830a0d": {"doc_hash": "db051858c884bc11d5d16ec51b6a0c34a14ef7f504df30ec1fef1c267b1bdc19", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "67d5a9f1-b98f-4918-a691-2f09cd39b52e": {"doc_hash": "4002781f3a254f10610aa38d7e4c8a8a2823eeaf6a1d02d498266eceafd8a806", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "3f17c214-7ce9-4dd6-b23c-397afe8e3301": {"doc_hash": "b55a99c88b69fd99e53d5c71abde1f9b50c3aad95f593028b3fe3435982a45f7", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "841baa43-4d68-4b8a-ad99-515ea87d4970": {"doc_hash": "72e638ea493cdc3735f73b5bb3a65f57162135da4c3489a51230b9aca0ef40d9", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "1b6938d8-518c-46ef-b824-4b68729c8e81": {"doc_hash": "a9bee1a93b24e0713f24f18424a57147bd3b6e2dfe375315f00615a9f9385447", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f5cf9b75-38a5-4196-beb1-886352f4435f": {"doc_hash": "24dda1d52599f263758e1762bcb65d6cca1a5df2918d8fd5a40027c8426879da", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "be75c88e-a3e8-4369-8907-b2abcd783d9f": {"doc_hash": "4fa559076c9482d17aa96dd6bf8c9b3c8e6b3af9e7fb83605dcba4299c7469e2", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "1a75e047-7241-4079-8bcf-e60eba7a861f": {"doc_hash": "8f7ada7f67fba4d62c89e62d03954b6cd7dc5f42b747ac1a51d45d3aec675793", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "81bd2cd9-2848-402a-b315-83f383fbb36d": {"doc_hash": "a6eff5e401235bd1a1c6600487f311788631eb9d42cd0ff5ceb5e28d9e8b8130", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "b608a4ed-8b87-4a28-abf0-352e0c6686ef": {"doc_hash": "47baa7da3f0d6b70b59d0bc08fafba37c6e2401fdc2713cfc43c7523019c7049", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "a0491ea4-aae1-41e6-a26d-8b71db814d4c": {"doc_hash": "b9f1063c0b78eebe1a1f0b0cd14f3f924fadfaa1c031c2136daa7796844efa3c", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "67b9db09-81af-43d4-8965-df9d05d9f063": {"doc_hash": "34bb70a895f76962d7e930ae9aef54b637ba9486e07e8efee94217d84a3b53a5", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "7bc9b8ba-5ded-4474-a89a-228102d65a56": {"doc_hash": "8bd1af471b7b0f54d0accb658b1c34ec0b8dad19094bf1af297a3be443e8403b", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f4039ad2-a6cc-410a-9630-394c05fd647d": {"doc_hash": "aa902fee6b1c56b1f9eb01f96ec358ef6fb6002a6f5d1b5ce5504299348105b7", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "69a56a7b-a5e4-4b28-a043-c10cedbcc356": {"doc_hash": "ba1e3a0e34530ea783aadf568d068b59b91bbc1a48f5b500b5f42131e4dd73f8", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "9436d80f-e285-41dd-a507-d4396bdf6e6a": {"doc_hash": "beff3c4005ea10cc12b78fe810ce62abb8cf854792cffca89ad58606478b7b8d", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "817185e1-164a-486b-9b0e-9001d23dd401": {"doc_hash": "468368f50070fc963e7c89f223b727fc65f1d8ca7ee90a1e515f4d187312657d", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "3a006d69-c3e2-4b2d-9506-549de80c388a": {"doc_hash": "31fbe1a49e8abc6e1f3849dcedfbf534e1be63841730ed18e925a6441759dded", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "0518ea29-c4d0-4724-b871-7ef6d8871a87": {"doc_hash": "ad38f82b0968d78b9c1629c94e231b819246da0697726d7a48f6bf7e44b47791", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "5b6693e2-a5f7-4b04-86d6-eabe2d477c67": {"doc_hash": "13c6bd6d1897a9a393fcb5751267a0c15775385bd004594936356845c9031c93", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "06d50fc6-c953-4536-bd20-2aac0f5a1f15": {"doc_hash": "fbfbd1434f3e600b85884ae5452e1d76c051cf55e28ada2a4761139e3d3c5cd5", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "8056d1a5-acb6-4b4a-8b6b-a230a1d06c92": {"doc_hash": "130ef631415cb0abc9f55922be41fbce834f238856f0741bdfd8ed4b1d97468f", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "b63f9e37-bec9-4009-89f1-2c806e26e0ef": {"doc_hash": "97dc936ddd7ad15a4fbb0a8573e94d7b8baf81315568fd38047a60df2e0682b7", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "034583f6-3a9c-4af9-a591-877e506b3c1c": {"doc_hash": "a55fdf4f2aa4e2b4b5243c10c8ce927a4752c8a0251427786cf05ece28668ed3", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "8c407867-9246-4b9e-9d39-f641013f4422": {"doc_hash": "82079e7484bb38a2cedb32696f06f2e0397867be779ba8c41ecd6f7b12f47b92", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "c4cc42aa-331e-4ba2-aabd-b13525f0ef49": {"doc_hash": "f01dc57defe04f0f88ddbc55009df3a7d32a5aa0c0c3ec7f7ef8a97d1e40bae3", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f16f8843-d47c-4911-adda-d35456826266": {"doc_hash": "8ed471e7164104f281b912ad4da1035bebd373e2a7281b1f889f32ec065c6254", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "8d20577f-cabf-4d27-97d3-579525727cda": {"doc_hash": "0ef994454593ce04b8e8cdd1fa69be57f78a923104edff6457d179841b541e90", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "1a6a2f28-3e5d-4526-8f79-37c9003e6d86": {"doc_hash": "fb3c0497a6a32318a3b950eb5cff7bd90e833021d46e01c724091a9a19e20c33", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "6835c55a-f229-43ab-bbd5-87a292013817": {"doc_hash": "730797bcb48c4f2682d514ef7039505f227f5811be50f10848e68d9e2eb07f99", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "67b70369-c8bb-4188-bbc6-2d1e2fcf406a": {"doc_hash": "828c944ebfe8968d7be78d99c8e1a9d18153579ddc07f4f0dfb3a448e1fe3b91", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "a552d385-eb25-4078-bcbe-a7fb7bbbe20d": {"doc_hash": "b9d35a167d366123368ae68a2218f3897b16fe7008005057e993c253b379c6bf", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "90b5691f-a8e1-4ce0-a541-c616310beed0": {"doc_hash": "5c868e526eca737c459ad70a20588b8c75efd24a1a64aed2ab9274a15e10fa74", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "ef2eb7f5-10af-4cc0-90dd-d8ba6cb3a618": {"doc_hash": "4b65cc579c9fa4ee36f3c70b3c14f0d17457d9a0d6b05a1675fff0c6bf24dba7", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "59212883-943f-4db3-ba9f-ff2a0a37b354": {"doc_hash": "6a33522f06e17bac00e084e6af20139be672563945723f31fb5b91152070bcb9", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "395415da-c009-4a56-bf74-14767ffe2569": {"doc_hash": "dab975311c417a75308c54c00ace5acee8abb67502f2450621467e56d728fc14", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "0dba4b81-ac5e-4ddb-a599-19d7d06e467f": {"doc_hash": "d9a0d559e4415d98315b1936eeaf2bcfd81aedfd69e6e791bd11d35b49661025", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "b92b11b5-bc2f-44f1-b03e-6b6190be6468": {"doc_hash": "e4b9fa36503db61f6c3d13badd8ab9e8130976cf33cfdbde510651b3c49d8451", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f3194d3d-ce89-4614-8cc8-8ca1ff19799e": {"doc_hash": "50ca80645ab759ee56b492644b533ffe4bdbc0beb2e342ac7620d5834daecfc6", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "e4be4a19-c952-4fb3-a822-b74dc194db7a": {"doc_hash": "1cbe499089c90c7d2afe4020ea347441b33cb84fcdd07214a8a34ba967992b5c", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "081ddc23-9b68-47d7-97df-e6b8144e70a6": {"doc_hash": "e5431a9cfe504994a4877ac7f6024a59f90e56a32a6a717c76ffcf17600df42d", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f792e19d-6df0-4c8e-9537-d1c8980950a1": {"doc_hash": "1972f8a836f9b0bbc74e5793878a829181062c0e3f2d53466ba264e6b6b179a2", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "212c8633-e701-469a-b1f3-6a29b66ec871": {"doc_hash": "58c91bfcae9ca46066c517b510c3dbc833b4d93ed7c5531d32884fa10fa4491e", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "aab985eb-59c5-45de-b0d9-e916a7c38a5a": {"doc_hash": "17061d878a64d0c32b16a7126777f99997b2568048227cd061340dc1957521fd", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "01cce7b7-e903-49bd-b511-19b923474bf9": {"doc_hash": "3cace8ac72bb900387f0005a114d559570087652cc3ab0c87beaae1a520817b0", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "85c04fbd-1a96-476f-89e5-234d7c3eaeea": {"doc_hash": "8cdf5ed91aadc8dc45edc7b3ca605698c76a706beff78803c64326bc7f786229", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "54945853-e802-4db1-b5a9-8ca6ebd8bfa6": {"doc_hash": "802117cf9fa7d9933eaa7f073a626f40901568c92482b7176e585506c98c208c", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "fe10d0cc-74fd-4188-bbe8-d31fe21b3a24": {"doc_hash": "d89b70b475150d8133ca3476cab796230f2dd028c3518eb1108f392d850e7fbd", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "7c64e9df-1a27-4c83-ae90-0045725d26d7": {"doc_hash": "cc072975b3cf98650cee7c0b55c902fcf80af3e4a8ecddd35d21ea3089123157", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "017aad40-317b-4269-a124-46c7947efde7": {"doc_hash": "fd8714bc8dc4f6f7bea33e0fbe4ea97d3ea638bdf40c7971a59d698377b87057", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "184affb0-5e02-4812-a443-37cf2d3b126e": {"doc_hash": "08cafd6de4eedbc0a6c387ec68822004d4c96cd5afd82c6852ae59fdbc63fbb1", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "8bb03e2b-a7c8-47ed-aa3f-550a07cb0319": {"doc_hash": "95429ff8c9d7d35a3744c5923f0d8836947f5c6dcd79b12c5931f3f86c8ec467", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "20bbdb7a-ea09-4232-9ae0-93ef74b0485f": {"doc_hash": "2fbb03fdb329a83e316f5081169bb0f4e0e9f9bc3bc57bde18f241fb40ebe293", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "6e29bc09-fd3d-432d-9621-09ca062d2689": {"doc_hash": "8763f854ab6046df67fd7cc49159b3289c01877c4967b4cac0615f881dd1f96c", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "71697a0f-dcf8-4450-82e7-30355655667c": {"doc_hash": "8463596c4cf5be3953b28df7d8e52829f5d92dc28d97be0e5a2d2f680c986c44", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f3d15e56-a243-4c8b-a1b3-eec78b49523a": {"doc_hash": "b8be30dda8b74be42c03cafcf5c18588ca3571cf1e5582445772f80321a2afea", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "cbf26d84-2b36-463a-96f6-7b4bc7c975dc": {"doc_hash": "a0709175d6e94021752bd23ecef61a47a9279156c4a86744530350f6a4bf6504", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "9fb52c0b-d599-4a2a-8ef9-fba163159f29": {"doc_hash": "22de1f89ea75ab7d1b1123ec7fadb0c826d03a27c88ba0ec36b75934efe8ad26", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "5c578d8d-9d1f-425d-b9a7-87ed55410fe4": {"doc_hash": "3e5a80bb7999b43aa1edd134b1949b4bc3233ab3a7b8224d359efb5dce1087aa", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "ac0f355f-375b-470b-8436-d7c41c1f9043": {"doc_hash": "71f9618a5eac130b488795db642418f25fb9ace86433fefda60b4dfd47fa66c0", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "3c02b981-df4f-46ba-aeaa-9bfea91e9f5b": {"doc_hash": "d7778beb8fca661f5034137a4d6cebe56dc7f8aba0bc0171a0e1d2507c4d6bc3", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "5b9d14e5-9e26-4604-8dcc-510e81f136d8": {"doc_hash": "0ec493c21d0ea21f539b89d3688d3deea3ba967e99dc28bf46f5bf27d8a28271", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "f7e3635b-8d04-4eed-88ed-dc1cae2abe74": {"doc_hash": "ff8d038450081d5b730ea4d9776af6f1f08fae7c1fa3d189367b5f0b753adaf3", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "4f55b8aa-c792-49b5-9d80-64713df534c5": {"doc_hash": "79adf77d483106975c43c05672943f0857f643781d36c4a002af6b58c82e2892", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "48e1240f-8d2d-49b3-9dd1-f243a76b44e6": {"doc_hash": "275236e1af7d9eb3be028bac3084de6160e3b367384a0cd682a11a732053ff1c", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "b43bc357-06a4-47da-8f03-da3509491ea7": {"doc_hash": "b075017b27980895ec2281a4e60b3e85611489788ec000233666b169ce007fc0", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "ee0cfe5c-c3db-454b-9e13-33db1bab87f4": {"doc_hash": "f68af8bdd04a1aac7cd211e536d61ad0b0a2ddbb93d2fb991b595fb294c48621", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "0b35a892-6483-4111-adeb-2a1bea4fae9a": {"doc_hash": "e8a60d6050d85780d6223e11033882043861f071e3a64b49de2e6675d169054f", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "e3d49e79-0357-45dd-b3b1-3d84ce5e7e19": {"doc_hash": "0bc7e1147eabcad079a6605bd1384319352b9e86d7d2c4ae5e20ede4d9976a29", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "8ce21e9b-9a76-4a21-a3d9-a79f96cef94c": {"doc_hash": "ad280693aeee5f7dac1f76cb2620249f1b2dc96190ae8721916b2a080bede02b", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "901847c2-03d1-4186-b48b-7a6d047e1f4c": {"doc_hash": "e705f4ab4d1d9e94cef6ac17277d87078af54d3f3ed10bd55c906d62e8b7134e", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "88c3bbda-4050-4618-9836-9ef45dbb9eda": {"doc_hash": "51fe46f09c013b047fbdc4041bd9770773ae5f28e3615ab15547217ec2105110", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "bd9bf0d2-c2b1-4d1b-894b-4ac7416182b1": {"doc_hash": "291abab013da0e991e249902214845a06fb01d6ef41098b6e66c03e6237c8be2", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "e57147ab-9e3c-4c6b-bf0e-92f8c195843a": {"doc_hash": "5851a0678864fd481b03829417e7a1b7606cdae4fdcf5811d67e00110785f939", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "2ebe27a4-ee28-4149-9743-85b59d08fd6b": {"doc_hash": "b461fde66705a902b6e5c21019b2d828b2bf922ad8d0287ff8cfcd2629f09a41", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "a2bfdb16-abbd-46ca-8849-e6d63bbb3f79": {"doc_hash": "db002d050918a1514d6b62a6d28222913246fb2446acfb997d403f125ed1e113", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "0521a981-f013-442b-b558-120dbef93839": {"doc_hash": "9abd3dbe1d57a1017e71cf7b067a8342554afa2c5afb7dc3830ef5c777ece306", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "4d6e1ecc-6a42-44bc-9e64-a625996cda4c": {"doc_hash": "9b5beaa5975d4e7dfbc2b5ea01e41514a9e96ace156daacdfa3d0aefb0871b38", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "aad62f9a-261f-4fac-a0d6-5f838a8e9328": {"doc_hash": "88a74ee5e6e531533e55040faeb528ab4d170e17fc096a157073d179cd55f927", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "6c000b3c-f989-4b64-b81f-9e8bd376c891": {"doc_hash": "3145902706fce3c6f0c49d668a7c0f0710438b0f0847b598dbcd8410618b4b7a", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "b9aba0a4-89b5-45fc-b3b2-62dcfa26196e": {"doc_hash": "85fb802d412b6c0b30f80fdbc13810f46468ddcc3e7a9dd417ddf3364f28e521", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "5749cac3-dcf1-4276-895d-be27cbcde49f": {"doc_hash": "5e598cfeee5d71eba059ba75fd84be908f1db6349d53a93327c8cbeca81e7732", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "01708502-0de4-422b-b649-aab0c42b321f": {"doc_hash": "4c71c1b08f852973cc7dd1f977ed61bd5f726bbb2573c0bb8ccc85ee78194e4f", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "39e07a45-8390-477e-aca8-58c7b41415b4": {"doc_hash": "07c6a2babe366ee88bd9a6252927471d72035e98d46cd8d21aac593cacde233e", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "4b2e1dd2-e66c-4e6a-a4ec-ed43823045eb": {"doc_hash": "ccdc41efc12b9f9841bb9a9e5f186c756ae016570f54911541c79cb6ec159872", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "42a89060-e97c-493f-a919-89b378104baa": {"doc_hash": "5e11a406a154fb132cc141d979f1cd530e10b23fd576a71f2737a464aed38e36", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "940dc357-2574-4c07-af28-8b76e704d6ea": {"doc_hash": "f193ceaf46cb9319d96452e13b326f7c53fd678144e11e0e243ad9711fb8170d", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "561f6ebf-71de-4e6e-88af-09da27c698e0": {"doc_hash": "317ff5653bfc0bd170de7bb0165165b187b07c6d04e6fe5ef2a378afd17ea390", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "4c704a28-9bf2-48b4-8e0d-77ac3e48010e": {"doc_hash": "21986d8894f31afb9865894e6697bec21786e907708c47a1642514005e49f6c3", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "ac67d285-ba98-4f0d-b1f5-99b4ac3c5ffc": {"doc_hash": "b38e6ad61ac6da0b703bd8a2437b0438d9347c94f8bd680b54396b172cd14a25", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "09d64c6e-651d-4432-b7d4-cd15b9c1be4e": {"doc_hash": "e72ca52923a45d79a5c9e4bd8b975803de186f8392415c077ff426ef413723da", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}, "c08e4b23-5352-40a4-a09b-259c53440965": {"doc_hash": "c33a381007afa137600f3e295e0e6e5119770cec94f5451343304c2a89d76d6d", "ref_doc_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d"}}, "docstore/data": {"9e1bb884-42d3-4a53-b6fd-0c763c91b8ff": {"__data__": {"id_": "9e1bb884-42d3-4a53-b6fd-0c763c91b8ff", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-0.txt", "file_name": "output-0.txt", "file_type": "text/plain", "file_size": 61, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c9ef9b7c-6dd0-4935-a552-9b3674a6f388", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-0.txt", "file_name": "output-0.txt", "file_type": "text/plain", "file_size": 61, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "0aabd50dc4c5ab13f3a917f150b8976adb00326a2a0654b2e879c8710f3cc572", "class_name": "RelatedNodeInfo"}}, "text": "# 403 Forbidden\n\nRequest forbidden by administrative rules.", "start_char_idx": 0, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e504fc55-ba53-482d-8ee8-08eb0be8e6f2": {"__data__": {"id_": "e504fc55-ba53-482d-8ee8-08eb0be8e6f2", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-1.txt", "file_name": "output-1.txt", "file_type": "text/plain", "file_size": 4805, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7344652d-6789-4c15-96cc-ea8f7128b966", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-1.txt", "file_name": "output-1.txt", "file_type": "text/plain", "file_size": 4805, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "253ce19eb04bcc376e45f7bedf37452dfa4fe826a9be2ed58e6f3f656efa976a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "951cb1fd-c1c1-48e4-9e60-c1db7e07330d", "node_type": "1", "metadata": {}, "hash": "a97f315051673ece8b4a009e54ba0dcfc460b4fd8bc0946a48a068b12ec2890e", "class_name": "RelatedNodeInfo"}}, "text": "[ \ud30c\uc774\ud1a0\uce58 \ud55c\uad6d \uc0ac\uc6a9\uc790 \ubaa8\uc784 ](/)\n\n#  [Salesforce, InstructBLIP \ubaa8\ub378\uc758 \ub17c\ubb38 / \ucf54\ub4dc / \uac00\uc911\uce58 \uacf5\uac1c](/t/salesforce-\ninstructblip/1571)\n\n[ \uc77d\uc744\uac70\ub9ac&\uc815\ubcf4\uacf5\uc720 ](/c/news/14)\n\n[lavis](https://discuss.pytorch.kr/tag/lavis),\n[blip2](https://discuss.pytorch.kr/tag/blip2),\n[minigpt-4](https://discuss.pytorch.kr/tag/minigpt-4),\n[instructblip](https://discuss.pytorch.kr/tag/instructblip),\n[salesforce](https://discuss.pytorch.kr/tag/salesforce),\n[gpt-4](https://discuss.pytorch.kr/tag/gpt-4),\n[multimodal](https://discuss.pytorch.kr/tag/multimodal), [vision-\nlanguage](https://discuss.pytorch.kr/tag/vision-language)\n\n[9bow](https://discuss.pytorch.kr/u/9bow) (\ubc15\uc815\ud658)  5\uc6d4 17, 2023, 9:59\uc624\uc804  1\n\nSalesforce\uc5d0\uc11c BLIP-2 \ubaa8\ub378\uc5d0 \uc774\uc5b4 InstructBLIP \ubaa8\ub378\uc758 \ub17c\ubb38\uacfc \uad6c\ud604, \uadf8\ub9ac\uace0 \ud559\uc2b5\ub41c \uac00\uc911\uce58\ub97c \uacf5\uac1c\ud588\uc2b5\ub2c8\ub2e4.\n\n##  InstructBLIP: Towards General-purpose Vision-Language Models with\nInstruction Tuning\n\n[![image](https://discuss.pytorch.kr/uploads/default/original/2X/7/720b1a5fdeccd3fb8e52ace10a474304e32beee9.jpeg)](https://github.com/salesforce/LAVIS/tree/main/projects/instructblip)\n\n\uc544\ub798\uc640 \uac19\uc774 Vicuna, T5\ub97c \uc0ac\uc6a9\ud55c 2 \uc885\ub958\uc758 \ubaa8\ub378\uc774 \uc788\uc73c\uba70,\n\n    \n    \n    # ==================================================\n    # Architectures                  Types\n    # ==================================================\n    # blip2_vicuna_instruct          vicuna7b, vicuna13b\n    # blip2_t5_instruct              flant5xl, flant5xxl\n    \n\n~~[Salesforce\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 LAVIS \ud328\ud0a4\uc9c0](https://github.com/salesforce/LAVIS)(`pip\ninstall salesforce-lavis`)\ub97c \uc124\uce58\ud558\uc5ec \ubc14\ub85c \uc0ac\uc6a9\ud574 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.~~  \n\uc544\uc9c1 PyPI\uc758 \ud328\ud0a4\uc9c0\uc5d0\ub294 InstructBLIP \ubaa8\ub378\ub4e4\uc774 \ubc18\uc601\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc544\uc11c, GitHub\uc5d0\uc11c \uc9c1\uc811 \uc124\uce58\ud558\uc154\uc57c \ud569\ub2c8\ub2e4.\n\n    \n    \n    git clone https://github.com/salesforce/LAVIS.git\n    cd LAVIS\n    pip install -e .\n    \n    \n    \n    from lavis.models import load_model_and_preprocess\n    # loads InstructBLIP model\n    model, vis_processors, _ = load_model_and_preprocess(name=\"blip2_vicuna_instruct\", model_type=\"vicuna7b\", is_eval=True, device=device)\n    # prepare the image\n    image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n    \n\n  \n\ucf54\ub4dc\uc640 \uc0ac\uc6a9\ubc95\uc774 \uad81\uae08\ud558\uc2e0 \ubd84\ub4e4\uaed8\uc11c\ub294 GitHub \uc800\uc7a5\uc18c\uc5d0\uc11c,\n\n![](https://github.githubassets.com/favicons/favicon.svg)\n[github.com](https://github.com/salesforce/LAVIS/tree/main/projects/instructblip)\n\n### [LAVIS/projects/instructblip at main \u00b7\nsalesforce/LAVIS](https://github.com/salesforce/LAVIS/tree/main/projects/instructblip)\n\n[main/projects/instructblip](https://github.com/salesforce/LAVIS/tree/main/projects/instructblip)\n\nLAVIS - A One-stop Library for Language-Vision Intelligence\n\n  \n\ub17c\ubb38\uc774 \uad81\uae08\ud558\uc2e0 \ubd84\ub4e4\uaed8\uc11c\ub294 arXiv\uc5d0\uc11c \ubc14\ub85c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \n~~(\uc800\ub294 \uc624\ub298\ub3c4 \uc77d\uae30 \ud050\uc5d0 \ub123\uae30\ub9cc \ud558\uace0\n\uc788\uc2b5\ub2c8\ub2e4;;;![:sweat_smile:](https://discuss.pytorch.kr/images/emoji/apple/sweat_smile.png?v=12)\n)~~\n\n![](https://discuss.pytorch.kr/uploads/default/original/2X/c/c683569a48ce1952ba841c851ae3b1f282d4b00f.png)\n[arXiv.org](https://arxiv.org/abs/2305.06500)\n\n!", "start_char_idx": 0, "end_char_idx": 2748, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "951cb1fd-c1c1-48e4-9e60-c1db7e07330d": {"__data__": {"id_": "951cb1fd-c1c1-48e4-9e60-c1db7e07330d", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-1.txt", "file_name": "output-1.txt", "file_type": "text/plain", "file_size": 4805, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7344652d-6789-4c15-96cc-ea8f7128b966", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-1.txt", "file_name": "output-1.txt", "file_type": "text/plain", "file_size": 4805, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "253ce19eb04bcc376e45f7bedf37452dfa4fe826a9be2ed58e6f3f656efa976a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e504fc55-ba53-482d-8ee8-08eb0be8e6f2", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-1.txt", "file_name": "output-1.txt", "file_type": "text/plain", "file_size": 4805, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "db8c5cc228bad7229d7a3112e3fd3f3d79bf0dedcd650b40ef74102a1a46b269", "class_name": "RelatedNodeInfo"}}, "text": "~~(\uc800\ub294 \uc624\ub298\ub3c4 \uc77d\uae30 \ud050\uc5d0 \ub123\uae30\ub9cc \ud558\uace0\n\uc788\uc2b5\ub2c8\ub2e4;;;![:sweat_smile:](https://discuss.pytorch.kr/images/emoji/apple/sweat_smile.png?v=12)\n)~~\n\n![](https://discuss.pytorch.kr/uploads/default/original/2X/c/c683569a48ce1952ba841c851ae3b1f282d4b00f.png)\n[arXiv.org](https://arxiv.org/abs/2305.06500)\n\n![](https://discuss.pytorch.kr/uploads/default/original/2X/8/86a2c8ac52804c90ede238d99cb944037c6f82f6.png)\n\n### [InstructBLIP: Towards General-purpose Vision-Language Models with\nInstruction...](https://arxiv.org/abs/2305.06500)\n\nGeneral-purpose language models that can solve various language-domain tasks\nhave emerged driven by the pre-training and instruction-tuning pipeline.\nHowever, building general-purpose vision-language models is challenging due to\nthe increased task...\n\n  \n\ubb38\uc11c\uc758 \ub9c8\uc9c0\ub9c9\uc5d0 \uc81c\uc2dc\ub41c \uc774\ubbf8\uc9c0\uc758 \uc774\uc0c1\ud55c \ubd80\ubd84\uc744 \uc124\uba85\ud558\ub77c\ub294 \uc9c0\ubb38\uc5d0 \ub300\ud55c `InstructBLIP`\uacfc `GPT-4`, `miniGPT-4` \ub4f1\uc758\n\ub2f5\ubcc0\uc744 \ube44\uad50\ud574 \ub450\uc5c8\ub294\ub370 \uc778\uc0c1\uc801\uc774\ub124\uc694.\n![:monkey:](https://discuss.pytorch.kr/images/emoji/apple/monkey.png?v=12)\n\n![image](https://discuss.pytorch.kr/uploads/default/original/2X/e/ea9a956b0e6f6adb323ec01f0234cdac379b4d68.png)\n\n[[\ubb34\ub8cc/\uc628\ub77c\uc778/\uc601\uc5b4] ChatGPT\uc640 CLIP\uc744 \uc0ac\uc6a9\ud55c Semantic Visual Search\n\ub9cc\ub4e4\uae30](https://discuss.pytorch.kr/t/chatgpt-clip-semantic-visual-search/1731)\n\n[9bow](https://discuss.pytorch.kr/u/9bow) (\ubc15\uc815\ud658)  5\uc6d4 17, 2023, 10:04\uc624\uc804  2\n\n\ub17c\ubb38\uc5d0 \uc694\ub7f0 \uc0ac\ub840\ub3c4 \ucca8\ubd80\ub418\uc5b4 \uc788\ub124\uc694\n![:smiley:](https://discuss.pytorch.kr/images/emoji/apple/smiley.png?v=12)\n\n![image](https://discuss.pytorch.kr/uploads/default/original/2X/5/5f4b2578db249d9572ae390976096877be804d16.png)\n\n  * [\ud648 ](/)\n  * [\uce74\ud14c\uace0\ub9ac ](/categories)\n  * [FAQ/\uac00\uc774\ub4dc\ub77c\uc778 ](/guidelines)\n  * [\uc774\uc6a9\uc57d\uad00 ](/tos)\n  * [\uac1c\uc778\uc815\ubcf4 \ucde8\uae09\ubc29\uce68 ](/privacy)\n\n[Discourse](https://www.discourse.org)\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. JavaScript\uac00 \ud65c\uc131\ud654\ub41c \uc0c1\ud0dc\uc5d0\uc11c \uac00\uc7a5 \uc798\n\ubcf4\uc785\ub2c8\ub2e4.", "start_char_idx": 2473, "end_char_idx": 4128, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c0b1c862-2f78-4caa-9563-fbf240184e19": {"__data__": {"id_": "c0b1c862-2f78-4caa-9563-fbf240184e19", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0be635d-53c4-4af1-aa1f-159804d24d42", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b1cc6360c81ae0ce5ba01dbc2b10cabb9c8f19642c960619187b4c5e6ca3e372", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "76e09f0d-354d-49eb-8183-61a2659bc563", "node_type": "1", "metadata": {}, "hash": "cb74bb9c8b1ff581cc1a7f9f4ea29431a022cec4c0e48143aa32ea34b37d9073", "class_name": "RelatedNodeInfo"}}, "text": "#  [ IBOK ](https://bo-10000.tistory.com/ \"IBOK\")\n\n  * [\ud648](/)\n\n\ud83c\udf0c Deep Learning/\ub17c\ubb38 \ub9ac\ubdf0 [KOR]\n\n## \uce74\uce74\uc624\ube0c\ub808\uc778 Multimodal LLM Honeybee \ub17c\ubb38 \ub9ac\ubdf0\n\n\ubcf5\ub9cc 2024\\. 3. 2. 16:09\n\n\uce74\uce74\uc624\ube0c\ub808\uc778\uc5d0\uc11c \uc791\ub144 \ub9d0 Multimodal LLM\uc778 Honeybee\ub97c \ubc1c\ud45c\ud588\ub2e4. \uc544\uc27d\uac8c\ub3c4 \ud55c\uad6d\uc5b4 \ubaa8\ub378\uc740 \uc544\ub2c8\uace0 \uc601\uc5b4 \ubaa8\ub378\uc774\uace0, 5\uac1c\uc758\n\ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c SoTA\ub97c \ub2ec\uc131\ud588\ub2e4\uace0 \ud574\uc11c \ub274\uc2a4\uac00 \uc5c4\uccad \ub9ce\uc774 \ub098\uc654\ub2e4.\n\n\n\n\ub17c\ubb38: <https://arxiv.org/pdf/2312.06742.pdf>\n\n\uae43\ud5d9: <https://github.com/kakaobrain/honeybee>\n\n[  \n\nGitHub - kakaobrain/honeybee: The official implementation of project\n\"Honeybee\"\n\nThe official implementation of project \"Honeybee\". Contribute to\nkakaobrain/honeybee development by creating an account on GitHub.\n\ngithub.com\n\n](https://github.com/kakaobrain/honeybee)\n\n\n\n\n\n\n\n\n\n## **1\\. \ubc30\uacbd**\n\n\n\n**MLLM (Multimodal LLM)** \uc740 _**vision encoder, LLM, projector**_ \uc138\uac00\uc9c0\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/2LHDY/btsFoEXC9jw/KGnS1YJYP9zSFjO7MqM7D1/img.png)\n\n\n\n**vision encoder** \uacfc **LLM** \uc740 \uac01\uac01 \ub530\ub85c\ub530\ub85c \uc0ac\uc804\ud559\uc2b5\ub41c \uac83\uc744 \uc0ac\uc6a9\ud55c\ub2e4. \ub530\ub77c\uc11c \ub450 \ubaa8\ub378\uc744 \uc5f0\uacb0\ud574\uc8fc\uae30 \uc704\ud574\n**projector** \uac00 \ud544\uc694\ud558\ub2e4.  **projector\uc740 vision encoder\uc5d0\uc11c \ub098\uc628 visual feature\uc744 LLM\uc758\nfeature space\ub85c \ub9e4\ud551** \ud574\uc8fc\ub294 \uc5ed\ud560\uc744 \ud55c\ub2e4. \uc77c\ubc18\uc801\uc73c\ub85c **vision encoder\uacfc LLM\uc740 \uace0\uc815\ud574\ub450\uace0 projector\uc744\n\ud559\uc2b5** \ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \ud559\uc2b5\uc774 \uc9c4\ud589\ub41c\ub2e4.\n\n\n\n\n\n\ub530\ub77c\uc11c \uc774 projector\uc758 \uc5ed\ud560\uc774 \ub9e4\uc6b0 \uc911\uc694\ud55c\ub370, **\ud06c\uac8c \ub450 \uac00\uc9c0 \ud0c0\uc785\uc73c\ub85c \ub098\ub20c \uc218 \uc788\ub2e4.**\n\n\n\n![](https://blog.kakaocdn.net/dn/bsC2Wt/btsFnX4bBfH/qwb0kaNXJkxbezxzCkzTx0/img.png)\n\n\n\n\uccab\ubc88\uc9f8\ub294 LLaVA \ub4f1\uc5d0\uc11c \uc0ac\uc6a9\ud55c _**linear projector**_ \uc774\ub2e4. \ub9d0\uadf8\ub300\ub85c linear layer\uc744 \uc774\uc6a9\ud574 image\nfeature\uc744 \ubcc0\ud658\ud558\ub294 \ubc29\uc2dd\uc778\ub370, \uc774 \ubc29\ubc95\uc740 **feature\uc744 \uc77c\ub300\uc77c \ub9e4\ud551\ud574\uc57c \ud558\uae30 \ub54c\ubb38\uc5d0 \uacc4\uc0b0\ub7c9\uc774 \ub9ce\ub2e4** \ub294 \ub2e8\uc810\uc774 \uc788\ub2e4.\n\n\n\n\ub2e4\ub978 \ud558\ub098\ub294 _**Abstractor**_ \ub77c\uace0 \ubd88\ub9ac\ub294 \uae30\ubc95\uc73c\ub85c, InstructBLIP, BLIP-2, miniGPT-4 \ub4f1\uc5d0\uc11c \uc0ac\uc6a9\ud55c\n\ubc29\ubc95\uc774\ub2e4. \uc774\ub4e4\uc740 \uc815\ud574\uc9c4 \uc218\uc758 visual token\uc744 \ucd94\ucd9c\ud574 \uc0ac\uc6a9\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c, **visual token\uc758 \uc218\ub97c \uc801\uc808\ud558\uac8c \uc870\uc808\ud560 \uc218 \uc788\uc5b4\nflexibility\uc640 efficiency\uac00 \ub192\uc73c\ub098 information loss\uac00 \uc788\uc744 \uc218 \uc788\ub2e4.** Abstractor \ubc29\uc2dd\uc740\nresampler, Q-former \ub4f1\uc774 \uc788\ub2e4.\n\n\n\n\n\n\uc774\ub7ec\ud55c efficiency\uc640 flexibility \ub54c\ubb38\uc5d0 **\ucd5c\uadfc abstractor \ubc29\uc2dd\uc774 \ub9ce\uc774 \uc0ac\uc6a9\ub418\uace0 \uc788\ub2e4.** \uadf8\ub7ec\ub098\nabstractor\uc740 **locality preservation\uc774 \uc57d\ud558\ub2e4** \ub294 \ub2e8\uc810\uc774 \uc788\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/cPex1B/btsFoaWz72R/NVLm1YtB7iQAmc8vBnLNAk/img.png)\n\n\n\n\uc704 \uadf8\ub9bc\uc744 \ubcf4\uba74 \ud070 feature\uc778 man\ub9cc \uc7a1\uc544\ub0b4\uace0 pizza, glass \uac19\uc740 \uc560\ub4e4\uc740 \ubabb \uc7a1\uc544 \ub0b4\uace0 \uc788\ub294\uac78 \ubcfc \uc218 \uc788\ub2e4. \ub530\ub77c\uc11c\nspatial understanding \ub2a5\ub825\uc774 \ub5a8\uc5b4\uc9c4\ub2e4.", "start_char_idx": 0, "end_char_idx": 1960, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "76e09f0d-354d-49eb-8183-61a2659bc563": {"__data__": {"id_": "76e09f0d-354d-49eb-8183-61a2659bc563", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0be635d-53c4-4af1-aa1f-159804d24d42", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b1cc6360c81ae0ce5ba01dbc2b10cabb9c8f19642c960619187b4c5e6ca3e372", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c0b1c862-2f78-4caa-9563-fbf240184e19", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "1aab6d60cfd80a3ef70080fa1cedf5402af6b77865c0bb3b61a101f28dc41c6c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e0d9fd1d-07e8-459b-9e75-8fb3f251a5e8", "node_type": "1", "metadata": {}, "hash": "c093dbd8492d212560a0ab72e6f1692902b6d95fbe836f33eacc9616503c00a3", "class_name": "RelatedNodeInfo"}}, "text": "\uc774\ub7ec\ud55c efficiency\uc640 flexibility \ub54c\ubb38\uc5d0 **\ucd5c\uadfc abstractor \ubc29\uc2dd\uc774 \ub9ce\uc774 \uc0ac\uc6a9\ub418\uace0 \uc788\ub2e4.** \uadf8\ub7ec\ub098\nabstractor\uc740 **locality preservation\uc774 \uc57d\ud558\ub2e4** \ub294 \ub2e8\uc810\uc774 \uc788\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/cPex1B/btsFoaWz72R/NVLm1YtB7iQAmc8vBnLNAk/img.png)\n\n\n\n\uc704 \uadf8\ub9bc\uc744 \ubcf4\uba74 \ud070 feature\uc778 man\ub9cc \uc7a1\uc544\ub0b4\uace0 pizza, glass \uac19\uc740 \uc560\ub4e4\uc740 \ubabb \uc7a1\uc544 \ub0b4\uace0 \uc788\ub294\uac78 \ubcfc \uc218 \uc788\ub2e4. \ub530\ub77c\uc11c\nspatial understanding \ub2a5\ub825\uc774 \ub5a8\uc5b4\uc9c4\ub2e4.\n\n\n\n\ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc774\ub7ec\ud55c \ub2e8\uc810\uc744 \uadf9\ubcf5\ud558\uae30 \uc704\ud574 _**local context\ub97c \ubcf4\uc874\ud560 \uc218 \uc788\ub294 abstractor \ubc29\uc2dd**_ \uc744 \uc0c8\ub86d\uac8c\n\uc81c\uc548\ud558\uace0, \uc774\ub97c \uc801\uc6a9\ud55c MLLM\uc778 _**Honeybee**_ \ub97c \ubc1c\ud45c\ud588\ub2e4.\n\n\n\n\n\n\n\n## **\b2. Honeybee**\n\n\n\n![](https://blog.kakaocdn.net/dn/bHHahh/btsFsaapgzl/M2JR8DM52SpjwzxaQqKKVK/img.png)\n\n\n\nHoneybee\uc758 \uc804\uccb4 \uad6c\uc870\ub294 \uc704\uc640 \uac19\ub2e4. **vision encoder** \uc5d0\uc11c visual feature\uc744 \ucd94\ucd9c \ud6c4\n**projector** \uc744 \uac70\uccd0 visual token\uc73c\ub85c \ubcc0\ud658\ud558\uace0, text token\uacfc \ud568\uaed8 **LLM** \uc758 input\uc73c\ub85c \ub123\ub294\ub2e4.\n\n\n\n\uc5ec\uae30\uae4c\uc9c0\ub294 \uc5ec\ud0c0 MLLM\ub4e4\uacfc \ub3d9\uc77c\ud55c \uad6c\uc870\uc774\uace0, \ud575\uc2ec \uad6c\uc870\ub294 \uc0c8\ub86d\uac8c \uc81c\uc548\ud55c projector\uc778 _**C-abstractor**_ \uacfc\n_**D-abstractor**_ \uc774\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/bMUtIq/btsFodZ9BI0/FCgCK1ItgJOt7BQYu50GK1/img.png)\n\n\n\n_**C-Abstractor**_ \uc740 local context\ub97c \uc798 \ud3ec\ucc29\ud558\ub294 convolution\uc744 \uc774\uc6a9\ub2e4. ResNet\uc744 \uc5ec\ub7ec\uac1c \uc313\uc544\nvisual token\uc744 \ucd94\ucd9c\ud55c\ub2e4.\n\n**_D-Abstractor_** \uc740 [DETR](https://arxiv.org/pdf/2005.12872.pdf)\uc5d0\uc11c \uc81c\uc548\ud55c\ndeformable attention\uc744 \uc774\uc6a9\ud558\uc5ec visual token\uc744 \ucd94\ucd9c\ud55c\ub2e4.\n\n\n\n\n\n\n\n## **3\\. \ud559\uc2b5\ubc29\ubc95**\n\n\n\n\ud559\uc2b5\uc740 \ub450\ub2e8\uacc4\ub85c \uc9c4\ud589\ub41c\ub2e4. \uccab\ubc88\uc9f8\ub85c vision encoder\uacfc LLM\uc740 freeze\ud558\uace0 abstractor\ub9cc \ud559\uc2b5\ud55c\ub2e4. \uadf8 \ub2e4\uc74c\uc73c\ub85c\nfreeze\ub97c \ud480\uace0 \ubaa8\ub4e0 parameter\uc744 \uc138\ubd80 \uc870\uc815\ud558\ub294 \ub2e8\uacc4\ub97c \uac70\uce5c\ub2e4.\n\n\n\nLLM\uc73c\ub85c\ub294 Vicuna-v1.5 (7B, 13B) \ub450\uac00\uc9c0 \ud06c\uae30\uc758 \ubaa8\ub378\uc744 \uc774\uc6a9\ud588\uace0, vision encoder\uc740 CLIP ViT-L/14\n\ubaa8\ub378\uc744 \uc774\uc6a9\ud588\ub2e4.\n\n\n\n\n\n\n\n## **4\\. \uc2e4\ud5d8\uacb0\uacfc**\n\n\n\n\uacb0\uacfc \uc694\uc57d - **5\uac1c bench\uc5d0\uc11c SoTA\ub97c \ub2ec\uc131\ud588\ub2e4.**\n\n\n\n![](https://blog.kakaocdn.net/dn/cwKCS4/btsFmmiWfD3/KbhYskCikJTU8e9SekjgvK/img.png)\n\n\n\n\ucc38\uace0\ub85c \uac01 bench\uc758 \uc608\uc2dc\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/bCNB3J/btsFm7y7kIA/Z43wTCdauhfptj3yR94I31/img.png)\n\n\n\n\uc194\uc9c1\ud788 \uc0ac\ub78c\uc774 \ubd10\ub3c4 \uc880 \uc5b4\ub835\ub2e4.\n\n\n\n\ubcf4\ub2e4 \uc790\uc138\ud55c \uacb0\uacfc \uc9c0\ud45c\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/wrSvo/btsFuHS6tv0/AzYweMkg2mjAKsPnjyOczK/img.png)", "start_char_idx": 1642, "end_char_idx": 3374, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e0d9fd1d-07e8-459b-9e75-8fb3f251a5e8": {"__data__": {"id_": "e0d9fd1d-07e8-459b-9e75-8fb3f251a5e8", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0be635d-53c4-4af1-aa1f-159804d24d42", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b1cc6360c81ae0ce5ba01dbc2b10cabb9c8f19642c960619187b4c5e6ca3e372", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "76e09f0d-354d-49eb-8183-61a2659bc563", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "53a9f33a0315888a21212387226e476c731162233222299977007705018a4b22", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "904ecbfa-69e9-4ab9-859c-d6fe5dbb6772", "node_type": "1", "metadata": {}, "hash": "c6186340f522325ca540a135eeab2069f385018c17ec1ee761adb73bba2cb6a2", "class_name": "RelatedNodeInfo"}}, "text": "![](https://blog.kakaocdn.net/dn/cwKCS4/btsFmmiWfD3/KbhYskCikJTU8e9SekjgvK/img.png)\n\n\n\n\ucc38\uace0\ub85c \uac01 bench\uc758 \uc608\uc2dc\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/bCNB3J/btsFm7y7kIA/Z43wTCdauhfptj3yR94I31/img.png)\n\n\n\n\uc194\uc9c1\ud788 \uc0ac\ub78c\uc774 \ubd10\ub3c4 \uc880 \uc5b4\ub835\ub2e4.\n\n\n\n\ubcf4\ub2e4 \uc790\uc138\ud55c \uacb0\uacfc \uc9c0\ud45c\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/wrSvo/btsFuHS6tv0/AzYweMkg2mjAKsPnjyOczK/img.png)\n\n\n\nQwen\uc774\ub098 LLaVA \ub4f1\uc740 \ub354 \ud070 vision encoder / image resolution / \ub354 \ub9ce\uc740 visual token\uc744\n\uc774\uc6a9\ud588\uc9c0\ub9cc Honeybee\uc758 \uc131\ub2a5\uc774 \ub354 \ub192\uc558\ub2e4\uace0 \ud55c\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/beW08S/btsFuNMzzrQ/binNxMunkybjmob5oJGtl1/img.png)\n\n\n\nHoneybee\ub3c4 \uc774\ub807\uac8c image resolution\uacfc visual token \uc218\ub97c \ub192\uc774\uba74 \uc131\ub2a5\uc774 \ub354 \uc0c1\uc2b9\ud55c\ub2e4\uace0 \ud55c\ub2e4.\n\n\n\n\n\n\ub2e4\uc74c\uc740 \uc2e4\ud5d8\ub2e8\uacc4\uc5d0\uc11c \uc138\uc6b4 \uac01 \uac00\uc124\uc5d0 \ub300\ud55c \uac80\uc99d\uc774\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/btmjs6/btsFn9i79Ck/4sL3JZmXCk62THWgXrCxS1/img.png)\n\n\n\nC/D-abstractor\uc774 local context preservation\uc5d0 \uc88b\ub2e4\ub294 \uac83\uc744 \ubcf4\uc774\uae30 \uc704\ud574 spatial\nunderstanding capability\ub97c \ubcfc \uc218 \uc788\ub294 task\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \uce21\uc815\ud588\ub2e4\uace0 \ud55c\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/bVFBIL/btsFsaha1TU/65IB1parTaujQC7s2P1bT0/img.png)\n\n\n\n\uc704\ub294 performance\uc640 efficiency\uc5d0 \ub300\ud55c \ube44\uad50\uc774\ub2e4. linear\uc740 \uc55e\uc11c \ub9d0\ud588\ub4ef\uc774 \uc77c\ub300\uc77c \ub300\uc751\uc774\ub77c flexibility\uac00 \uc544\uc608\n\uc5c6\ub2e4. resampler\uacfc C-abstractor\uc740 flexible\ud558\uac8c \ub514\uc790\uc778\ud560 \uc218 \uc788\uc73c\uba70, visual token \uc218\uac00 \ub298\uc5b4\ub0a0\uc218\ub85d \uc131\ub2a5\uc774\n\uc99d\uac00\ud558\ub294 \uc591\uc0c1\uc744 \ubcf4\uc774\ub098 C-abstractor\uc758 \uc131\ub2a5\uc774 \ud6e8\uc52c \uc88b\ub2e4.\n\n\n\n\n\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c Honeybee\uac00 \uc0dd\uc131\ud55c \ub2f5\ubcc0\uc758 \uc608\uc2dc\ub4e4\uc774\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/bzQkIe/btsFoaWAfZe/FhzUQNAnB8V5QjIHVdpokk/img.png)\n![](https://blog.kakaocdn.net/dn/vpM1G/btsFqNzNeoe/RjiwgyCKodTVzGjsI8FwTK/img.png)", "start_char_idx": 3044, "end_char_idx": 4377, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "904ecbfa-69e9-4ab9-859c-d6fe5dbb6772": {"__data__": {"id_": "904ecbfa-69e9-4ab9-859c-d6fe5dbb6772", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0be635d-53c4-4af1-aa1f-159804d24d42", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b1cc6360c81ae0ce5ba01dbc2b10cabb9c8f19642c960619187b4c5e6ca3e372", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e0d9fd1d-07e8-459b-9e75-8fb3f251a5e8", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "c3c046ed2a5e776f157a17f0abaaf9aa65e93ad0b36c4dde4e9d3cf3a2c2b579", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "df597bea-1054-4d7c-80a9-a79b03167424", "node_type": "1", "metadata": {}, "hash": "d25457c36a5ef85fc0c7733b33d36ec9381399282eba582e42aaca7df69eb450", "class_name": "RelatedNodeInfo"}}, "text": "\ub9c8\uc9c0\ub9c9\uc73c\ub85c Honeybee\uac00 \uc0dd\uc131\ud55c \ub2f5\ubcc0\uc758 \uc608\uc2dc\ub4e4\uc774\ub2e4.\n\n\n\n![](https://blog.kakaocdn.net/dn/bzQkIe/btsFoaWAfZe/FhzUQNAnB8V5QjIHVdpokk/img.png)\n![](https://blog.kakaocdn.net/dn/vpM1G/btsFqNzNeoe/RjiwgyCKodTVzGjsI8FwTK/img.png)\n\n\n\n\ucc38 \uc798\ud558\ub124..\n\n\ubc18\uc751\ud615\n\n\uacf5\uc720\ud558\uae30\n\n\uac8c\uc2dc\uae00 \uad00\ub9ac\n\n_\uad6c\ub3c5\ud558\uae30_ **IBOK**\n\n#### '[\ud83c\udf0c Deep Learning](/category/%F0%9F%8C%8C%20Deep%20Learning) > [\ub17c\ubb38 \ub9ac\ubdf0\n[KOR]](/category/%F0%9F%8C%8C%20Deep%20Learning/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0%20%5BKOR%5D)'\n\uce74\ud14c\uace0\ub9ac\uc758 \ub2e4\ub978 \uae00\n\n[[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] MeZO: Fine-Tuning Language Models with Just Forward Passes\n(NeurIPS 2023)](/206)  (2) | 2024.01.28  \n---|---  \n[[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] AIM: Scalable Pre-training of Large Autoregressive Image Models\n(Apple, 2024)](/205)  (0) | 2024.01.21  \n[Apple\uc758 Multimodal LLM Ferret \ub17c\ubb38 \ub9ac\ubdf0](/203)  (2) | 2024.01.07  \n[[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-\ninvariant Weights (Naver AI Lab, ICLR 2021)](/195)  (0) | 2023.07.23  \n[[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] Audio-Visual Speech Enhancement Using Multimodal Deep\nConvolutional Neural Networks](/168)  (1) | 2022.09.21  \n  \n### Tag\n\n[mllm](/tag/mllm), [Multimodal](/tag/Multimodal)\n\n### '\ud83c\udf0c Deep Learning/\ub17c\ubb38 \ub9ac\ubdf0 [KOR]'\uc758 \ub2e4\ub978\uae00\n\n  * [\uc774\uc804\uae00 **[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] MeZO: Fine-Tuning Language Models with Just Forward Passes (NeurIPS 2023)**](/206)\n  * \ud604\uc7ac\uae00 **\uce74\uce74\uc624\ube0c\ub808\uc778 Multimodal LLM Honeybee \ub17c\ubb38 \ub9ac\ubdf0**\n  * \n\n### \uad00\ub828\uae00\n\n  * [ **[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] MeZO: Fine-Tuning Language Models with Just Forward Passes (NeurIPS 2023)** 2024.01.28 ](/206?category=948904)\n  * [ **[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] AIM: Scalable Pre-training of Large Autoregressive Image Models (Apple, 2024)** 2024.01.21 ](/205?category=948904)\n  * [ **Apple\uc758 Multimodal LLM Ferret \ub17c\ubb38 \ub9ac\ubdf0** 2024.01.07 ](/203?category=948904)\n  * [ **[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights (Naver AI Lab, ICLR 2021)** 2023.07.23 ](/195?category=948904)\n\n\ub313\uae00 1\n\n  * \n\n\ube44\ubc00\uae00 \ub4f1\ub85d\n\n!", "start_char_idx": 4177, "end_char_idx": 5994, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "df597bea-1054-4d7c-80a9-a79b03167424": {"__data__": {"id_": "df597bea-1054-4d7c-80a9-a79b03167424", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0be635d-53c4-4af1-aa1f-159804d24d42", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b1cc6360c81ae0ce5ba01dbc2b10cabb9c8f19642c960619187b4c5e6ca3e372", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "904ecbfa-69e9-4ab9-859c-d6fe5dbb6772", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "995d066284df103c6a73e044eedada3b97ed31eb97d2935d1b015af4e5a054c2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0e1af00a-a606-4caf-abe2-3c87351354ab", "node_type": "1", "metadata": {}, "hash": "697a21797801cda05c0908a47976b6ea6fddc204c310322cc10495416648bc51", "class_name": "RelatedNodeInfo"}}, "text": "[\ud504\ub85c\ud544\uc0ac\uc9c4](https://tistory1.daumcdn.net/tistory/3487102/attach/fb04976601014f93b22d0aff6d652500)\n\n\ud83d\udc2c\n\n  * [ \ubd84\ub958 \uc804\uccb4\ubcf4\uae30 (174) ](/category)\n    * [ \ud83c\udf0c Deep Learning (50) ](/category/%F0%9F%8C%8C%20Deep%20Learning)\n      * [ \ub17c\ubb38 \ub9ac\ubdf0 [KOR] (24) ](/category/%F0%9F%8C%8C%20Deep%20Learning/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0%20%5BKOR%5D)\n      * [ Paper Review [ENG] (0) ](/category/%F0%9F%8C%8C%20Deep%20Learning/Paper%20Review%20%5BENG%5D)\n      * [ DL & ML \uc870\uac01 \uc9c0\uc2dd (4) ](/category/%F0%9F%8C%8C%20Deep%20Learning/DL%20%26%20ML%20%EC%A1%B0%EA%B0%81%20%EC%A7%80%EC%8B%9D)\n      * [ Overview (6) ](/category/%F0%9F%8C%8C%20Deep%20Learning/Overview)\n      * [ Dataset (3) ](/category/%F0%9F%8C%8C%20Deep%20Learning/Dataset)\n      * [ \ud3c9\uac00 (3) ](/category/%F0%9F%8C%8C%20Deep%20Learning/%ED%8F%89%EA%B0%80)\n      * [ Implementation (6) ](/category/%F0%9F%8C%8C%20Deep%20Learning/Implementation)\n      * [ Etc. (4) ](/category/%F0%9F%8C%8C%20Deep%20Learning/Etc.)\n    * [ \ud83d\udc0d Python & library (49) ](/category/%F0%9F%90%8D%20Python%20%26%20library)\n      * [ Python (5) ](/category/%F0%9F%90%8D%20Python%20%26%20library/Python)\n      * [ PyTorch (18) ](/category/%F0%9F%90%8D%20Python%20%26%20library/PyTorch)\n      * [ PyTorch Lightning (2) ](/category/%F0%9F%90%8D%20Python%20%26%20library/PyTorch%20Lightning)\n      * [ Tensorflow (1) ](/category/%F0%9F%90%8D%20Python%20%26%20library/Tensorflow)\n      * [ Flax (0) ](/category/%F0%9F%90%8D%20Python%20%26%20library/Flax)\n      * [ HuggingFace (5) ](/category/%F0%9F%90%8D%20Python%20%26%20library/HuggingFace)\n      * [ Scikit-Learn (4) ](/category/%F0%9F%90%8D%20Python%20%26%20library/Scikit-Learn)\n      * [ numpy (2) ](/category/%F0%9F%90%8D%20Python%20%26%20library/numpy)\n      * [ librosa (4) ](/category/%F0%9F%90%8D%20Python%20%26%20library/librosa)\n      * [ SimpleITK (4) ](/category/%F0%9F%90%8D%20Python%20%26%20library/SimpleITK)\n      * [ Etc. (4) ](/category/%F0%9F%90%8D%20Python%20%26%20library/Etc.)", "start_char_idx": 5994, "end_char_idx": 7945, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0e1af00a-a606-4caf-abe2-3c87351354ab": {"__data__": {"id_": "0e1af00a-a606-4caf-abe2-3c87351354ab", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0be635d-53c4-4af1-aa1f-159804d24d42", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b1cc6360c81ae0ce5ba01dbc2b10cabb9c8f19642c960619187b4c5e6ca3e372", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "df597bea-1054-4d7c-80a9-a79b03167424", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "46910d84705f387d0f3f07c0ed6a783be7f47ea827917bb362bc0b34b77b7069", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6de95ee5-2f6b-4475-a7bc-5a0e045bbfac", "node_type": "1", "metadata": {}, "hash": "da64866a7a89523f284b44d3c9eeeb931a197bde145b7cb35a294f5342f37ced", "class_name": "RelatedNodeInfo"}}, "text": "(4) ](/category/%F0%9F%90%8D%20Python%20%26%20library/Etc.)\n    * [ \ud83d\udc7b OS & Tools (33) ](/category/%F0%9F%91%BB%20OS%20%26%20Tools)\n      * [ Ubuntu (14) ](/category/%F0%9F%91%BB%20OS%20%26%20Tools/Ubuntu)\n      * [ Mac (3) ](/category/%F0%9F%91%BB%20OS%20%26%20Tools/Mac)\n      * [ Windows (1) ](/category/%F0%9F%91%BB%20OS%20%26%20Tools/Windows)\n      * [ VSCode (3) ](/category/%F0%9F%91%BB%20OS%20%26%20Tools/VSCode)\n      * [ Git (3) ](/category/%F0%9F%91%BB%20OS%20%26%20Tools/Git)\n      * [ LaTeX (8) ](/category/%F0%9F%91%BB%20OS%20%26%20Tools/LaTeX)\n      * [ Tools (1) ](/category/%F0%9F%91%BB%20OS%20%26%20Tools/Tools)\n    * [ \ud83d\udc7d Language & Frameworks (6) ](/category/%F0%9F%91%BD%20Language%20%26%20Frameworks)\n      * [ Matlab (1) ](/category/%F0%9F%91%BD%20Language%20%26%20Frameworks/Matlab)\n      * [ Spark (5) ](/category/%F0%9F%91%BD%20Language%20%26%20Frameworks/Spark)\n    * [ \ud83d\udd2c Medical Image (13) ](/category/%F0%9F%94%AC%20Medical%20Image)\n      * [ MRI (3) ](/category/%F0%9F%94%AC%20Medical%20Image/MRI)\n      * [ Processing (5) ](/category/%F0%9F%94%AC%20Medical%20Image/Processing)\n      * [ \ub17c\ubb38 \ub9ac\ubdf0 (5) ](/category/%F0%9F%94%AC%20Medical%20Image/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0)\n    * [ \ud83d\udca9 \uc5d0\ub7ec \ud574\uacb0 (7) ](/category/%F0%9F%92%A9%20%EC%97%90%EB%9F%AC%20%ED%95%B4%EA%B2%B0)\n    * [ \ud83d\udd11 CS (11) ](/category/%F0%9F%94%91%20CS)\n      * [ \ucf54\ub529\ud14c\uc2a4\ud2b8 (10) ](/category/%F0%9F%94%91%20CS/%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8)\n      * [ \uc54c\uace0\ub9ac\uc998 (1) ](/category/%F0%9F%94%91%20CS/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)\n    * [ \ud83e\udd68 \uc774\uac83\uc800\uac83 (5) ](/category/%F0%9F%A5%A8%20%EC%9D%B4%EA%B2%83%EC%A0%80%EA%B2%83)\n    * [ \ud83d\udcd6 \ub3c5\ud6c4\uac10 (0) ](/category/%F0%9F%93%96%20%EB%8F%85%ED%9B%84%EA%B0%90)\n\n\ubc18\uc751\ud615\n\n### \ucd5c\uadfc\uae00\uacfc \uc778\uae30\uae00\n\n  * \ucd5c\uadfc\uae00\n  * \uc778\uae30\uae00\n\n  * [\n\n**\uce74\uce74\uc624\ube0c\ub808\uc778 Multimodal LLM Honeybee \ub17c\ubb38 \ub9ac\ubdf0** 2024.03.02 16:09 ](/207)\n\n  * [\n\n**[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] MeZO: Fine-Tuning Language Models with Just Forward Passes \u22ef**\n2024.01.", "start_char_idx": 7886, "end_char_idx": 9778, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6de95ee5-2f6b-4475-a7bc-5a0e045bbfac": {"__data__": {"id_": "6de95ee5-2f6b-4475-a7bc-5a0e045bbfac", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0be635d-53c4-4af1-aa1f-159804d24d42", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b1cc6360c81ae0ce5ba01dbc2b10cabb9c8f19642c960619187b4c5e6ca3e372", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0e1af00a-a606-4caf-abe2-3c87351354ab", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "c213d5036bfa8c305dc58c9e1dc17ef4739fb243627f754e5d18aa411c68e5f5", "class_name": "RelatedNodeInfo"}}, "text": "03.02 16:09 ](/207)\n\n  * [\n\n**[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] MeZO: Fine-Tuning Language Models with Just Forward Passes \u22ef**\n2024.01.28 22:42 ](/206)\n\n  * [\n\n**[\ub525\ub7ec\ub2dd \ub17c\ubb38\ub9ac\ubdf0] AIM: Scalable Pre-training of Large Autoregressive Image Mo\u22ef**\n2024.01.21 23:03 ](/205)\n\n  * [\n\n**\ub0b4\uac00 \ubcf4\ub824\uace0 \uc815\ub9ac\ud558\ub294 LaTex \uc790\uc8fc \uc4f0\ub294 \uc218\uc2dd \uc815\ub9ac** 2021.11.16 15:29 ](/97)\n\n  * [\n\n**LaTex \ud45c \uad00\ub828 \ud301 (\ud45c \uc790\ub3d9 \uc0dd\uc131\uae30, \ud3f0\ud2b8 \ud06c\uae30 \uc870\uc815, \uc140 \ub108\ube44, \ud45c \ub0b4\ubd80 \uc5ec\ubc31, footnote \ub2ec\uae30)** 2022.04.26\n22:14 ](/128)\n\n  * [\n\n**[matplotlib] matplotlib.pyplot\uc744 \uc774\uc6a9\ud55c \uc774\ubbf8\uc9c0 \uc2dc\uac01\ud654 \ucd1d\uc815\ub9ac** 2022.08.29 15:58 ](/161)\n\n### \ucd5c\uadfc\ub313\uae00\n\n  * [ **\ub17c\ubb38\uc744 \ubcf4\uba74 ResNet-D\ub294 ResNet-B\uc5d0 average pooling\uc744 \ucd94\uac00\ud55c \ud615\ud0dc\u22ef**\n\n\ud589\uc778\n\n](/133#comment21315301)\n\n  * [ **https://m.blog.naver.com/edennnie/223155243141**\n\nhmm\n\n](/73#comment21295201)\n\n  * [ **nvidia-smi\ub294 GPU\ub4dc\ub77c\uc774\ubc84\uac00 \uc9c0\uc6d0\ud558\ub294 \ucd5c\uc2e0 CUDA\ubc84\uc804\uc774\uace0, nvcc --vers\u22ef**\n\nhmm\n\n](/73#comment21295174)\n\n### \ubc29\ubb38\uc790\uc218Total\n\n412,621\n\n  * Today : 37\n  * Yesterday : 867\n\n### Calendar\n\n[\u00ab](/archive/202404 \"1\uac1c\uc6d4 \uc55e\uc758 \ub2ec\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\")   [2024/05](/archive/202405 \"\ud604\uc7ac \ub2ec\uc758\n\ub2ec\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\")   [\u00bb](/archive/202406 \"1\uac1c\uc6d4 \ub4a4\uc758 \ub2ec\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\") \uc77c | \uc6d4 | \ud654 | \uc218 | \ubaa9 | \uae08\n| \ud1a0  \n---|---|---|---|---|---|---  \n|  |  | 1 | 2 | 3 | 4  \n5 | 6 | 7 | 8 | 9 | 10 | 11  \n12 | 13 | 14 | 15 | 16 | 17 | 18  \n19 | 20 | 21 | 22 | 23 | 24 | 25  \n26 | 27 | 28 | 29 | 30 | 31 |  \n  \nCopyright \u00a9 Kakao Corp. All rights reserved.\n\n\uad00\ub828\uc0ac\uc774\ud2b8\n\n  * [Github](https://github.com/bo-10000)\n\n## \ud2f0\uc2a4\ud1a0\ub9ac\ud234\ubc14\n\n**IBOK** _\uad6c\ub3c5\ud558\uae30_", "start_char_idx": 9666, "end_char_idx": 10981, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e9ce05d6-e33a-40d9-94b7-0d3187b003af": {"__data__": {"id_": "e9ce05d6-e33a-40d9-94b7-0d3187b003af", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "7ec8d3e8c95c039a749fa1f4b91865231544965d851248e250e60e4fdd0c54f5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ff8aada7-d24d-4eb8-bd37-d8bf6a2c07f1", "node_type": "1", "metadata": {}, "hash": "4a008f93ed3bddadd280d52b7b641064ed075245f92c4654efe47288532c3e0c", "class_name": "RelatedNodeInfo"}}, "text": "![](https://www.facebook.com/tr?id=579484675976917&ev=PageView&noscript=1)\n\n[](/home)\n\n[\ucee4\ub9ac\uc5b4\ub9ac \ud2b8\ub80c\ub4dc\n\n](/trends)[\ud604\uc9c1\uc790 Q&A](/qnas)\n\n[\uc0ac\uc774\ub4dc \ud504\ub85c\uc81d\ud2b8\n\n](/lounge)\n\n\ub85c\uadf8\uc778\n\n\ud68c\uc6d0\uac00\uc785\n\n[![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![\uc18c\uc131\uc740\ub2d8\uc758\n\ud504\ub85c\ud544 \uc0ac\uc9c4](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\uc18c\uc131\uc740\n\nSolutions Architect @ AWS\n\n](/profiles/16843)\n\n\ud314\ub85c\uc6b0\n\n# Salesforce\uc758 InstructBLIP\n\n\uc5bc\ub9c8 \uc804\uc5d0 Salesforce \uc5d0\uc11c BLIP2\ub97c \uacf5\uac1c\ud588\uc5c8\uc2b5\ub2c8\ub2e4. \ub192\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 Vision-Language LLM \uc774\uc5c8\uace0, \ud14c\uc2a4\ud2b8\ub97c \ud574\n\ubd24\uc744 \ub54c \uaf64 \ud765\ubbf8\ub85c\uc6b4 \uacb0\uacfc (\uc608\ub97c \ub4e4\uc5b4 \uc774\ubbf8\uc9c0 \ub0b4\uc758 \uc0ac\ub78c\uc774\ub098 \uac1d\uccb4 \uac2f\uc218\ub97c \uc798 \uce74\uc6b4\ud305\ud558\ub294 \ub4f1) \ub97c \ubcf4\uc5ec\uc8fc\uae30\ub3c4 \ud574\uc11c \ubc1c\uc804 \uc18d\ub3c4\uac00 \ub180\ub78d\ub2e4\uace0 \uc0dd\uac01\uc744\n\ud588\uc5c8\uc2b5\ub2c8\ub2e4. \uc774\ubc88\uc5d0 Salesforce\uc5d0\uc11c \uadf8 \ud6c4\uc18d\uc73c\ub85c InstrcutBLIP\uc744 \uacf5\uac1c\ud558\uc600\uc2b5\ub2c8\ub2e4. \\- \ucf54\ub4dc:\nhttps://github.com/salesforce/LAVIS/tree/main/projects/instructblip \uae30\uc874\uc758 BLIP2\n\uae30\ubc18\uc73c\ub85c \uc5ec\ub7ec \uac00\uc9c0 public dataset \uc744 \uac00\uc838\ub2e4\uac00 instruct tuning\uc774 \uac00\ub2a5\ud55c \ud615\ud0dc\ub85c \ub9cc\ub4e4\uc5b4\uc11c fine-tuning\uc744\n\uc9c4\ud589\ud55c \uac83\uc774\uace0, \ub9e4\uc6b0 \ud070 Vision-Language \ub370\uc774\ud130\uc14b\uc778 Flamingo\ub97c \ud3ec\ud568\ud55c \uc5ec\ub7ec \ub370\uc774\ud130\uc5d0 \ub300\ud574\uc11c zero-shot \uc5d0\uc11c\nSOTA\ub97c \ub2ec\uc131\ud558\uc600\ub2e4\uace0 \ud569\ub2c8\ub2e4. \ub17c\ubb38\uc744 \uc0b4\ud3b4\ubcf4\uba74 \uad6c\uc870 \uc790\uccb4\ub294 \uae30\uc874 BLIP2 \uc640 \ub2e4\ub97c \uac83\uc774 \ubcc4\ub85c \uc5c6\uc2b5\ub2c8\ub2e4. BLIP\uc758 \ud575\uc2ec\uc778 Q-former\n\ubd80\ubd84\uc5d0 \uae30\uc874\uc5d0\ub294 Query + Text \ud615\ud0dc\ub85c \ub123\ub358 \uac83\uc5d0\uc11c text\ub97c instruction \uc73c\ub85c \ud55c \uc815\ub3c4\ub9cc \ucc28\uc774\ub77c\uace0 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n(Instruct-tuning \uc774\ubbc0\ub85c \ub2f9\uc5f0\ud55c \uac83\uc785\ub2c8\ub2e4\ub9cc...\u314e\u314e) \uc774\ubc88 \uc5f0\uad6c\ub294 \ubaa8\ub378 \uc544\ud0a4\ud14d\uccd0 \ub4f1\uc774 \uac1c\uc120\ub418\uc5c8\ub2e4\uae30 \ubcf4\ub2e4\ub294, \uc5ec\ub7ec \ub370\uc774\ud130\uc14b\uc5d0\n\ub300\ud574\uc11c fine-tuning\uc744 \uc9c4\ud589\ud558\uace0 \uc774 \ubaa8\ub378\uc744 \uacf5\uac1c\ud55c \uac83\uc5d0 \uc758\uc758\uac00 \uc788\ub2e4\uace0 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 Vicuna\uc640 FlanT5\uae30\ubc18\uc73c\ub85c \ub41c\n\ubaa8\ub378\uc744 \uacf5\uac1c\ud558\uc600\ub294\ub370 MiniGPT4 (https://github.com/Vision-CAIR/MiniGPT-4) \uc640 \ube44\uc2b7\ud558\ub124\uc694. \uc5b4\ucc0c\ub418\uc5c8\uac74\n\ucd5c\uadfc\uc5d0 Vision/Language\ub97c \uac19\uc774 \ub2e4\ub8e8\ub294 LLM\ub4e4\uc774 \ub9ce\uc544\uc9c0\uace0 \uc788\uace0 \uc810\uc810 \ub354 \uc5ec\ub7ec modality \ub85c \ud655\uc7a5\ub418\uc5b4 \uac00\ub294 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\n\uadf8\uc640\ub294 \ubcc4\uac1c\ub85c Meta\uc758 OPT, LLaMA\ub098 Google\uc758 FlanT5 \ub4f1\uc740 \uc624\ud508\uc18c\uc2a4 \ucabd\uc5d0 \uc815\ub9d0 \ud070 \uae30\uc5ec\ub97c \ud558\uace0 \uc788\ub294 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\n\n[LAVIS/projects/instructblip at main \u00b7 salesforce/LAVIS\n\nGitHub\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27160%27%20height=%27120%27/%3e)![LAVIS/projects/instructblip\nat main \u00b7\nsalesforce/LAVIS](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)!", "start_char_idx": 0, "end_char_idx": 1830, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ff8aada7-d24d-4eb8-bd37-d8bf6a2c07f1": {"__data__": {"id_": "ff8aada7-d24d-4eb8-bd37-d8bf6a2c07f1", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "7ec8d3e8c95c039a749fa1f4b91865231544965d851248e250e60e4fdd0c54f5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e9ce05d6-e33a-40d9-94b7-0d3187b003af", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ff1964a500a05435310fad482d228345160b5575c8741078a5e21a646d7e3a06", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bfa1340d-53c2-4715-ba59-b0a5b404a84b", "node_type": "1", "metadata": {}, "hash": "d585fb613ce1388719ca9f76720d4356078fc896fac5e0bf1cb6abac40009f33", "class_name": "RelatedNodeInfo"}}, "text": "\uadf8\uc640\ub294 \ubcc4\uac1c\ub85c Meta\uc758 OPT, LLaMA\ub098 Google\uc758 FlanT5 \ub4f1\uc740 \uc624\ud508\uc18c\uc2a4 \ucabd\uc5d0 \uc815\ub9d0 \ud070 \uae30\uc5ec\ub97c \ud558\uace0 \uc788\ub294 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\n\n[LAVIS/projects/instructblip at main \u00b7 salesforce/LAVIS\n\nGitHub\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27160%27%20height=%27120%27/%3e)![LAVIS/projects/instructblip\nat main \u00b7\nsalesforce/LAVIS](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)![LAVIS/projects/instructblip\nat main \u00b7\nsalesforce/LAVIS](/_next/image?url=https%3A%2F%2Fpubly.imgix.net%2Farticle-\nthumbnails%2F2023.05%2F61115babdeb468d80642377c4d3e698ddf46eed0f9fc19c9e9d40415fa084290.webp%3Fw%3D200%26h%3D200&w=384&q=75)](https://github.com/salesforce/LAVIS/tree/main/projects/instructblip)\n\n\ub2e4\uc74c \ub0b4\uc6a9\uc774 \uad81\uae08\ud558\ub2e4\uba74?\n\n![kakao_icon](/_next/static/images/img_symbol-\nkakao-b1fe6197135e5beead71b1a90f8e2b7d.png)\uce74\uce74\uc624\ub85c 3\ucd08\ub9cc\uc5d0 \uac00\uc785\ud558\uae30\n\n\ub610\ub294\n\n\uc774\uba54\uc77c\ub85c \uac00\uc785\ud558\uae30\n\n\uc774\ubbf8 \ud68c\uc6d0\uc774\uc2e0\uac00\uc694?\n\n\ub85c\uadf8\uc778\ud558\uae30\n\n2023\ub144 5\uc6d4 14\uc77c \uc624\ud6c4 3:31\n\n\uc88b\uc544\uc694 **2**\n\n\u2022\n\n\ub9ac\ud3ec\uc2a4\ud2b8 **1**\n\n[ \uc800\uc7a5 **2** \u2022 \uc870\ud68c **2,803**\n\n](/comments/83593)\n\n\uc88b\uc544\uc694\n\n\ub9ac\ud3ec\uc2a4\ud2b8\n\n### \ub313\uae00 0\n\n![](/_next/static/images/img_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png)\n\n* * *\n\n* * *\n\n* * *\n\n### \ube44\uc2b7\ud55c \uac8c\uc2dc\ubb3c\n\n### \uc8fc\uac04 \uc778\uae30 TOP 10\n\n[1![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\uc774\uc7a5\uadfc NAVER \ub370\uc774\ud130\ubd84\uc11d\n\n\ud68c\uc0ac \ud14c\ud06c \ube14\ub85c\uadf8 \ubaa8\uc74c \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb\n\n](/comments/103945)[2![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\ud55c\uc815\uc218 Software Engineer\n\n498\uac1c\uc758 \ud14c\uc2a4\ud2b8 \ucf54\ub4dc (\ubc88\uc5ed)\n\n](/comments/103928)[3![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)!", "start_char_idx": 1419, "end_char_idx": 3298, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bfa1340d-53c2-4715-ba59-b0a5b404a84b": {"__data__": {"id_": "bfa1340d-53c2-4715-ba59-b0a5b404a84b", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "7ec8d3e8c95c039a749fa1f4b91865231544965d851248e250e60e4fdd0c54f5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff8aada7-d24d-4eb8-bd37-d8bf6a2c07f1", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "1d1ab6e5c037a3918178a5547c71717da9aa48d3aa3a05a4a359e3aa2ef0c4ff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "03631b0e-5da0-4baa-8eb9-b90ff2c02826", "node_type": "1", "metadata": {}, "hash": "b1d540f414fe5aa9d3ac0beb44f8a4efe47e86485f5b5723186eda49034f7fce", "class_name": "RelatedNodeInfo"}}, "text": "[](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\ud55c\uc815\uc218 Software Engineer\n\n498\uac1c\uc758 \ud14c\uc2a4\ud2b8 \ucf54\ub4dc (\ubc88\uc5ed)\n\n](/comments/103928)[3![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\uc774\uc591\uc77c NaverCloud \ubc31\uc5d4\ub4dc \uac1c\ubc1c\uc790\n\n\ud83c\udf10 \uac1c\ubc1c\uc790\uac00 \uc54c\uace0 \uc788\uc73c\uba74 \uc88b\uc740 \uc0ac\uc774\ud2b8\n\n](/comments/103947)[4![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\ud558\uc870\uc740 Software Engineer\n\n\uc131\uc7a5\uc758 \uc774\uc720\n\n](/comments/103875)[5![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\uae40\uc758\uc911 \uc704\ub300\ud55c\uc0c1\uc0c1 \uac1c\ubc1c\uc790\n\nReact 19 \ubca0\ud0c0 \ucd9c\uc2dc: Actions\uc758 \ub3c4\uc785\uacfc \uc0c8\ub85c\uc6b4 \ube44\ub3d9\uae30\n\n](/comments/103907)\n\n[6![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\uc1a1\uc694\ucc3d \ubc30\ubbfc \ud504\ub860\ud2b8\uc5d4\ub4dc \ud504\ub85c\uadf8\ub798\uba38\n\n\uc2e0\uc785 \uac1c\ubc1c\uc790\uc758 \ud55c \ub2ec\n\n](/comments/103929)[7![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\ub178\uc218\uc9c4 \ub274\uc695\uc758 \uc2a4\ud0c0\ud2b8\uc5c5 \ud504\ub85c\uadf8\ub798\uba38\n\n\ucf54\ub529\ud558\ub2e4\uac00 \b\ub9c9\ud614\uc744\ub54c \uadf9\ubcf5\ud558\ub294 5\uac00\uc9c0 \ubc29\ubc95\n\n](/comments/103985)[8![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)!", "start_char_idx": 2986, "end_char_idx": 4858, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "03631b0e-5da0-4baa-8eb9-b90ff2c02826": {"__data__": {"id_": "03631b0e-5da0-4baa-8eb9-b90ff2c02826", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "7ec8d3e8c95c039a749fa1f4b91865231544965d851248e250e60e4fdd0c54f5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bfa1340d-53c2-4715-ba59-b0a5b404a84b", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "164479d30e29dc2cd5e3e94c53e29cbca27df5e592fa0b4e2a83b2cfddad34e9", "class_name": "RelatedNodeInfo"}}, "text": "[](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\ub178\uc218\uc9c4 \ub274\uc695\uc758 \uc2a4\ud0c0\ud2b8\uc5c5 \ud504\ub85c\uadf8\ub798\uba38\n\n\ucf54\ub529\ud558\ub2e4\uac00 \b\ub9c9\ud614\uc744\ub54c \uadf9\ubcf5\ud558\ub294 5\uac00\uc9c0 \ubc29\ubc95\n\n](/comments/103985)[8![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\uc774\uba85\uc9c4 \ud55c\uad6d\ub808\ub4dc\ud587 \uc194\ub8e8\uc158 \uc544\ud0a4\ud14d\ud2b8\n\n\ube44\uc96c\uc5bc \uc2a4\ud29c\ub514\uc624 \ucf54\ub4dc\uc5d0\uc11c Llama 3 \uc2e4\ud589\ud558\uae30\n\n](/comments/103969)[9![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\n\ub808\ub4dc\ubc84\uc2a4\ubc31\ub9e8 \ub9ac\uc11c\ucc98 \uc564 \ub77c\uc774\ud130\n\n\u27ea\uc131\uc219\ud55c \uc0ac\ub78c\uc774 \ub418\uae30 \uc704\ud55c 10\uac00\uc9c0 \ub178\ub825\u27eb\n\n](/comments/103955)[10![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e)![](/_next/image?url=%2F_next%2Fstatic%2Fimages%2Fimg_profile-\ndummy-f39ccb87481ab4a70525a9d2d461307d.png&w=256&q=75)\n\nK\ub9ac\uadf8 \ud504\ub85c\uadf8\ub798\uba38 \ucee4\ud53c\ud55c\uc794 \uac1c\ubc1c\uc790\n\n\uc9d1\uc5d0\uc11c \uc11c\ubc84\ub97c \uc6b4\uc601\ud558\ub294 \uac8c \uac00\ub2a5\ud55c\uac00\uc694?\n\n](/comments/103919)\n\n### \ucd94\ucc9c \ud504\ub85c\ud544", "start_char_idx": 4543, "end_char_idx": 5682, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "128387ff-4463-4a80-9d22-f9b9393e8e1d": {"__data__": {"id_": "128387ff-4463-4a80-9d22-f9b9393e8e1d", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "93ad53d0-8842-433d-94f9-a8e6ad6c83b9", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ec94e150f26fff6a2f5c34bba184983fe5acd53b6791b03537fdddfe2bfe53ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8381e89e-3d9a-43ee-b0ce-0b28e3d6276b", "node_type": "1", "metadata": {}, "hash": "461d6188672094f1b330e2e6b66d543ac2e45bb8ed6c5c90bfb59f60585b0726", "class_name": "RelatedNodeInfo"}}, "text": "# [AttentionX](https://attentionx.github.io/)\n\n# ![image](https://i.ibb.co/jJJV9fs/1686903632416.jpg) AttentionX: AI Research\n& Startup Group\n\n## \ub3d9\uc544\ub9ac \ubaa9\ud45c/\ud65c\ub3d9\n\n  1. \ucee8\ud37c\ub7f0\uc2a4 \ub17c\ubb38 Accept\n  2. \uc624\ud508 \uc18c\uc2a4 \uae30\uc5ec\n  3. AI \uc2a4\ud0c0\ud2b8\uc5c5 \uc591\uc131\n\n## \ud83d\udca1 \ub3d9\uc544\ub9ac \uc18c\uac1c\n\n\uc548\ub155\ud558\uc138\uc694 \uc800\ud76c\ub294 \uc11c\uc6b8\ub300\ud559\uad50, \uce74\uc774\uc2a4\ud2b8, \uc678\uad6d \ub300\ud559\uad50 (Berkeley, Stanford, CMU, Oxford)\uc758\n\ud559\ubd80\uc0dd/\ub300\ud559\uc6d0\uc0dd\ub4e4(\uae40\uac74\ud76c, \uc11c\ubbfc\uc900, \uc774\uac15\uc6b1 \uad50\uc218\ub2d8 \uc5f0\uad6c\uc2e4)\uacfc ML \ud604\uc9c1\uc790\ub4e4(\uce74\uce74\uc624 \ube0c\ub808\uc778, \ud06c\ub798\ud504\ud1a4 \ub4f1)\uc774 \ud65c\ub3d9\ud574\uc628 \uac1c\ubc1c\uc790\uc640 \uc5f0\uad6c\uc790,\n\uc2a4\ud0c0\ud2b8\uc5c5 \ucc3d\uc5c5\uac00\ub4e4\uc758 \ucee4\ubba4\ub2c8\ud2f0\uc785\ub2c8\ub2e4.  \n\uc800\ud76c\ub294 LLM, Multimodal Language Model, Generative Model (3D, Audio, Video)\uc5d0 \uad00\ud55c\n\uc5f0\uad6c\ub97c \ud1b5\ud574 \ub17c\ubb38 \uc2e4\uc801\uc744 \ub0b4\uace0 \uc5f0\uad6c \uae30\ubc18 \ud504\ub85c\ub355\ud2b8 \uac1c\ubc1c\uacfc \uc2a4\ud0c0\ud2b8\uc5c5 \ube4c\ub529\uc744 \ud558\ub294 \uc870\uc9c1\uc785\ub2c8\ub2e4!\n\n### \u2728 2023\ub144 \ud65c\ub3d9 \uc694\uc57d\n\n  1. \ub17c\ubb38 \uc131\uacfc \n    * InstructBLIP PEFT\ud300, [NeurIPS Workshop 2023](https://neurips2023-enlsp.github.io/accepted_papers.html#:~:text=Parameter%2DEfficient%20Fine%2Dtuning%20of%20InstructBLIP%20for%20Visual%20Reasoning%20Tasks) accept (\uc11c\uc6b8\ub300\ud559\uad50 \uc774\uc7ac\uc724 \uad50\uc218\ub2d8 \uad50\uc2e0 \uc800\uc790)\n    * [Video-LLaMA Drive](https://github.com/sungyeonparkk/vision-assistant-for-driving)\ud300, WACV Workshop 2024 accept (\uc11c\uc6b8\ub300\ud559\uad50 \uae40\ub3d9\uaddc \uad50\uc218\ub2d8 \uad50\uc2e0 \uc800\uc790)\n  2. \uc2a4\ud0c0\ud2b8\uc5c5 \n    * 1\uae30 \uc2a4\ud0c0\ud2b8\uc5c5 2\ud300, [Krew Capital](https://krewcapital.com/) \ud22c\uc790 \uc720\uce58 \n      * [fastrepl](https://fastrepl.com)\n      * [Weavel](https://www.promptmodel.run)\n    * 2\ud300, YC W24 \uc778\ud130\ubdf0\n  3. \ub9e4\uc2a4\ud504\ub808\uc18c\uc640 \ud611\uc5c5, Math LLM \uc5f0\uad6c \ud504\ub85c\uc81d\ud2b8 \uc9c4\ud589\n  4. \ud574\ucee4\ud1a4 \uc131\uacfc \n    1. Weavel \ud300, OpenAI \uc8fc\uad00 [Prompter Day \ud574\ucee4\ud1a4](https://www.prompterday.com/main) 5\ub4f1 (500\ub9cc\uc6d0 \uc218\uc0c1)\n    2. [Agent Eval](https://www.youtube.com/watch?v=sjEMBY3Ngbk): [AGI House Agent \ud574\ucee4\ud1a4](https://partiful.com/e/I4oVKOY4DXEG5Bn9U61h) \uc6b0\uc2b9\n    3. LAWI \ud300, [\ud504\ub77c\uc774\uba38 Gen AI \ud574\ucee4\ud1a4](https://www.newswire.co.kr/newsRead.php?no=965386) \uacb0\uc120 \uc9c4\ucd9c\n  5. \ud504\ub85c\ub355\ud2b8 \uac1c\ubc1c & \ub7f0\uce6d \n    * [NALY](https://disquiet.io/@marc/makerlog/8017) (\uc2a4\ub9c8\ud2b8 \uc2a4\ud53c\ucee4): \ud504\ub9ac\uc624\ub354 800\ub9cc\uc6d0 \uae30\ub85d\n    * [\uac1c\uc778\ud654 \ucc57\ubd07, \ud504\ub85c\ub355\ud2b8 \ud5cc\ud2b8 Product of the Day 3\ub4f1](https://www.producthunt.com/products/is-it-you#is-it-you)\n  6.", "start_char_idx": 0, "end_char_idx": 1679, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8381e89e-3d9a-43ee-b0ce-0b28e3d6276b": {"__data__": {"id_": "8381e89e-3d9a-43ee-b0ce-0b28e3d6276b", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "93ad53d0-8842-433d-94f9-a8e6ad6c83b9", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ec94e150f26fff6a2f5c34bba184983fe5acd53b6791b03537fdddfe2bfe53ee", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "128387ff-4463-4a80-9d22-f9b9393e8e1d", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ce21cec05c02fece9a3a4b5b7f3a011c4c3e19a062083d04276043ae44cd5222", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f6208959-dd0a-4c25-af91-3bb8b2e8e4a1", "node_type": "1", "metadata": {}, "hash": "ad7ff7b40d67646ab0c48fa4a38873d98bef7db22270f6ec22dfe3ab2d36d5ef", "class_name": "RelatedNodeInfo"}}, "text": "LAWI \ud300, [\ud504\ub77c\uc774\uba38 Gen AI \ud574\ucee4\ud1a4](https://www.newswire.co.kr/newsRead.php?no=965386) \uacb0\uc120 \uc9c4\ucd9c\n  5. \ud504\ub85c\ub355\ud2b8 \uac1c\ubc1c & \ub7f0\uce6d \n    * [NALY](https://disquiet.io/@marc/makerlog/8017) (\uc2a4\ub9c8\ud2b8 \uc2a4\ud53c\ucee4): \ud504\ub9ac\uc624\ub354 800\ub9cc\uc6d0 \uae30\ub85d\n    * [\uac1c\uc778\ud654 \ucc57\ubd07, \ud504\ub85c\ub355\ud2b8 \ud5cc\ud2b8 Product of the Day 3\ub4f1](https://www.producthunt.com/products/is-it-you#is-it-you)\n  6. \uc624\ud508\uc18c\uc2a4 Project \n    * [TestGPT](https://github.com/AttentionX/testGPT): TDD\ub85c GPT \uad6c\ud604 (Andrej Karpathy\uc758 NanoGPT \uae30\ubc18)\n    * [InstructBLIP Fine-tuning](https://github.com/salesforce/LAVIS/issues/302#issuecomment-1931380335)\n  7. \uc624\ud508\uc18c\uc2a4 Contribution \n    * lit-llama: [PR#357](https://github.com/Lightning-AI/lit-llama/pull/357), [PR#238](https://github.com/Lightning-AI/lit-llama/pull/238), [PR#242](https://github.com/Lightning-AI/lit-llama/pull/242)\n  8. \uc11c\uc6b8\ub300\ud559\uad50 \uacf5\uacfc\ub300\ud559, GPU \ud074\ub7ec\uc2a4\ud130 \uc9c0\uc6d0 (a100 32\uac1c \uacf5\ub3d9 \uc0ac\uc6a9)\n\n### \ud83d\udd2c 3\uae30 \ud504\ub85c\uc81d\ud2b8\ub4e4\n\n  1. Autonomous Driving Assistant (\ubc15\uc131\uc5f0, \uace0\ub824\ub300 \uae40\uc9c4\uaddc \uad50\uc218\ub2d8 \uc9c0\ub3c4)\n  2. Math LLM (\uc870\uc8fc\ud658, \ub9e4\uc2a4\ud504\ub808\uc18c \ud611\uc5c5)\n  3. In-Context Knowledge Distillation (\uae40\ubbfc\ucc2c)\n  4. Controlled 3D Generation (3D MM) (\uae40\uc131\uacbd, \uce74\uc774\uc2a4\ud2b8 \uc131\ubbfc\ud601 \uad50\uc218\ub2d8 \uc9c0\ub3c4)\n  5. Cache Merging & Spend Less on V.A.T (\uc548\uc601\uc9c4)\n  6. Dynamic 3D Generation (\uc774\uc544\ub2f4, \uace0\ub824\ub300 \uae40\uc2b9\ub8e1 \uad50\uc218\ub2d8 \uc9c0\ub3c4)\n  7. LLM jailbreaking \uacf5\uaca9/\ubc29\uc5b4 (\uc720\uc0c1\uc724)\n  8. Video Highlight/Captioning (\ud55c\ub3d9\ud6c8)\n  9. Non-invasive biopotential decoding (\uae40\ub3c4\uc5fd)\n  10. Robot safety reward model (\ud64d\uc21c\ubc94)\n  11. Music Generation Research (\uace0\uacc4\ud6c8)\n  12. Plug-and-Play Knowledge Injection for LLMs (\ubc15\uc740\ud658)\n  13. Resolve LLM ambiguity by throwing questions (\uc11d\uc8fc\uc601)\n  14. Reflective Learning (\uc2e0\uc2b9\uc724)\n\n### \ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc67 \uba64\ubc84\n\n  1. [1\uae30 \uba64\ubc84](https://abecid.notion.site/AttentionX-1-1fd7b9c8efb0422c969c877c8d1c09c4?pvs=4)\n  2. [2\uae30 \uba64\ubc84](https://abecid.notion.site/AttentionX-2-fd86468a8dbd436dab29ef10f5553da1?pvs=4)\n  3.", "start_char_idx": 1390, "end_char_idx": 3018, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f6208959-dd0a-4c25-af91-3bb8b2e8e4a1": {"__data__": {"id_": "f6208959-dd0a-4c25-af91-3bb8b2e8e4a1", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "93ad53d0-8842-433d-94f9-a8e6ad6c83b9", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ec94e150f26fff6a2f5c34bba184983fe5acd53b6791b03537fdddfe2bfe53ee", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8381e89e-3d9a-43ee-b0ce-0b28e3d6276b", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "c7d27989e25178a7a77d5e5d633b41115ae7c67b3b4a62225422f172ea3b2aa7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fbf0b3ce-8fdd-4b54-aa50-91e99160d972", "node_type": "1", "metadata": {}, "hash": "0f62f76e82867024a4c95a0384033ae2ebe81b1a186fe3531e43d95a0c4c360c", "class_name": "RelatedNodeInfo"}}, "text": "Music Generation Research (\uace0\uacc4\ud6c8)\n  12. Plug-and-Play Knowledge Injection for LLMs (\ubc15\uc740\ud658)\n  13. Resolve LLM ambiguity by throwing questions (\uc11d\uc8fc\uc601)\n  14. Reflective Learning (\uc2e0\uc2b9\uc724)\n\n### \ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc67 \uba64\ubc84\n\n  1. [1\uae30 \uba64\ubc84](https://abecid.notion.site/AttentionX-1-1fd7b9c8efb0422c969c877c8d1c09c4?pvs=4)\n  2. [2\uae30 \uba64\ubc84](https://abecid.notion.site/AttentionX-2-fd86468a8dbd436dab29ef10f5553da1?pvs=4)\n  3. [3\uae30 \uba64\ubc84](https://abecid.notion.site/AttentionX-3-936500ae929c487b82bb5d5cbbedd07f?pvs=4)\n\n\uba64\ubc84 \uc18c\uac1c \uc800\ud76c\ub294 \uc11c\uc6b8\ub300\ud559\uad50, \uce74\uc774\uc2a4\ud2b8, \uc678\uad6d \ub300\ud559\uad50 (Berkeley, Stanford, CMU, Oxford) \ucd9c\uc2e0\uc758 \uc5f0\uad6c\uc790, \uac1c\ubc1c\uc790\n\uc704\uc8fc\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uace0 \uae40\uac74\ud76c, \uc11c\ubbfc\uc900, \uc8fc\uc7ac\uac78, \uae40\uc8fc\ud638, \uae40\uc601\ubbfc, \ud669\uc2b9\uc6d0, Kwangwook Lee, Trevor Darrell,\nChelsea Finn \uad50\uc218\ub2d8 \ub7a9 \uc778\ud134\uacfc \uc11d\ubc15\uc0ac \ubd84\ub4e4\uc774 \ud65c\ub3d9\ud574\uc654\uc2b5\ub2c8\ub2e4! \uc5f0\uad6c \ud300\ub4e4\uc740 \uc131\ubbfc\ud601, \uc774\uae30\ubbfc, \uae40\uc2b9\ub8e1, \uc774\uc7ac\uc724 \uad50\uc218\ub2d8, \ucf74\ub2e4 \uc5f0\uad6c\ud300\uacfc\n\uc18c\ud1b5\uc744 \ud558\uac70\ub098 \uc9c0\ub3c4\ub97c \ubc1b\ub294 \ud300\ub4e4\uc774 \uc788\uace0 \ud504\ub85c\ub355\ud2b8 \ud300\ub4e4\uc740 \ub450 \ud300\uc774 \ud06c\ub8e8 \uce90\ud53c\ud138\uc5d0\uc11c \ud22c\uc790\ub97c \ubc1b\uace0 \ub450 \ud300\uc774 YC W24 \uc778\ud130\ubdf0\ub97c \ubcf4\uace0 \ud504\ub85c\ub355\ud2b8\n\uac1c\ubc1c\uc744 \ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. (\uc800\ud76c \uc870\uc9c1\uacfc fit\uc774 \ub9de\uc744\uac83 \uac19\uc740 \ubd84\ub4e4\uc740 \uc5b8\uc81c\ub4e0\uc9c0 \uc774\uba54\uc77c\ub85c \uc5f0\ub77d\uc8fc\uc138\uc694!)\n\n### \ud83e\udd35 \uac8c\uc2a4\ud2b8\n\n1\uae30 \uac8c\uc2a4\ud2b8 1\\. [\ub93c\ud2bc](https://wrtn.ai/) \uc774\uc138\uc601 \ub300\ud45c\ub2d8  \n2\\. [\ud300\ub7ec\ub108\uc2a4](https://www.learners.company/) \ub9f9\uc8fc\uc131 \ub300\ud45c\ub2d8  \n3\\. [\ub9c1\uae00](https://www.ringleplus.com/ko/student/landing/team) \uc774\uc131\ud30c \ub300\ud45c\ub2d8  2\uae30 \uac8c\uc2a4\ud2b8\n1\\. Krew Capital \uc1a1\ubbfc\uc7ac\ub2d8, \ubbfc\ubcd1\ud6c8\ub2d8  \n2\\. Neuralkind \uae40\uc900\ud76c\ub2d8  \n3\\. \ub775\uc2a4\ud50c\ub85c\uc6b0 \uc724\ud76c\uc0c1\ub2d8  \n4\\. \ucf54\ub974\uce74 \uc774\ud0dc\ud638\ub2d8  \n5\\. \ub93c\ud2bc \ud604\uc9c0\uc6c5\ub2d8  \n6\\. \ud574\uce58\ub7a9\uc2a4 \uae40\ubbfc\uc11d\ub2d8  3\uae30 \uac8c\uc2a4\ud2b8 1\\. VRCrew \ucd5c\uc131\uad11 \ub300\ud45c\ub2d8  \n2\\. Shift-up \uae40\ud0dc\ud6c8\ub2d8  \n3\\. Beeble.ai \uae40\ud6c8 \ub300\ud45c\ub2d8  \n\n### \ud83d\udd16 \uc804 \uae30\uc218 \ud65c\ub3d9\n\n  * [1\uae30 \ud65c\ub3d9](https://abecid.notion.site/1-e41e8583e724455ca1959d24332246e5?pvs=4)\n  * [2\uae30 \ud65c\ub3d9](https://abecid.notion.site/2-142fe495a46c4875bc1bef11ac2739f6?pvs=4)\n\n### \ud83d\udcda \uc790\ub8cc\uc2e4\n\n  1. [\ub17c\ubb38 \ub9ac\ubdf0 \uc138\uc158](https://skillful-houseboat-70c.notion.site/Study-Sessions-614371ce36a64c318b6c6bf3980f4467)\n  2.", "start_char_idx": 2636, "end_char_idx": 4140, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fbf0b3ce-8fdd-4b54-aa50-91e99160d972": {"__data__": {"id_": "fbf0b3ce-8fdd-4b54-aa50-91e99160d972", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "93ad53d0-8842-433d-94f9-a8e6ad6c83b9", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ec94e150f26fff6a2f5c34bba184983fe5acd53b6791b03537fdddfe2bfe53ee", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f6208959-dd0a-4c25-af91-3bb8b2e8e4a1", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "0bf31c347150c67642cdd8283068d0cd8f02e1edc4584cee48db104b5384dc25", "class_name": "RelatedNodeInfo"}}, "text": "Shift-up \uae40\ud0dc\ud6c8\ub2d8  \n3\\. Beeble.ai \uae40\ud6c8 \ub300\ud45c\ub2d8  \n\n### \ud83d\udd16 \uc804 \uae30\uc218 \ud65c\ub3d9\n\n  * [1\uae30 \ud65c\ub3d9](https://abecid.notion.site/1-e41e8583e724455ca1959d24332246e5?pvs=4)\n  * [2\uae30 \ud65c\ub3d9](https://abecid.notion.site/2-142fe495a46c4875bc1bef11ac2739f6?pvs=4)\n\n### \ud83d\udcda \uc790\ub8cc\uc2e4\n\n  1. [\ub17c\ubb38 \ub9ac\ubdf0 \uc138\uc158](https://skillful-houseboat-70c.notion.site/Study-Sessions-614371ce36a64c318b6c6bf3980f4467)\n  2. [NLP \uae30\ucd08 \uc790\ub8cc](https://skillful-houseboat-70c.notion.site/NLP-0cf2ffe5cc2542a4a6edd9f8e86fb4ef)\n  3. [NLP \uc8fc\uc694 \ub17c\ubb38\ub4e4](https://skillful-houseboat-70c.notion.site/e805b63e1f304c53aed49b4b177d6019?v=22d6287722c341a3a0936638e73534b8)\n\n### \ud83d\udcac SNS\n\n  * [\uc778\uc2a4\ud0c0\uadf8\ub7a8](https://www.instagram.com/attentionx.ai/)\n  * [GitHub](https://github.com/AttentionX)\n  * [\uc720\ud22c\ube0c](https://www.youtube.com/@attentionx)\n\n### \u260e\ufe0f Contact\n\n  * attentionx.ai@gmail.com", "start_char_idx": 3799, "end_char_idx": 4565, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "774dad0b-ea64-4c36-b0f5-fcbd871218c3": {"__data__": {"id_": "774dad0b-ea64-4c36-b0f5-fcbd871218c3", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-5.txt", "file_name": "output-5.txt", "file_type": "text/plain", "file_size": 1344, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bee567a9-3d08-41be-a2ee-10c916f2455f", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-5.txt", "file_name": "output-5.txt", "file_type": "text/plain", "file_size": 1344, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "a42c55c505b074ea197382be92203906d53bcd2cae8ecb115249517a307bdd66", "class_name": "RelatedNodeInfo"}}, "text": "[](/ \"YouTube\")[](/ \"YouTube\")\n\n[\uc815\ubcf4](https://www.youtube.com/about/)[\ubcf4\ub3c4\uc790\ub8cc](https://www.youtube.com/about/press/)[\uc800\uc791\uad8c](https://www.youtube.com/about/copyright/)[\ubb38\uc758\ud558\uae30](/t/contact_us/)[\ud06c\ub9ac\uc5d0\uc774\ud130](https://www.youtube.com/creators/)[\uad11\uace0](https://www.youtube.com/ads/)[\uac1c\ubc1c\uc790](https://developers.google.com/youtube)[\uc57d\uad00](/t/terms)[\uac1c\uc778\uc815\ubcf4\ucc98\ub9ac\ubc29\uce68](/t/privacy)[\uc815\ucc45\n\ubc0f \uc548\uc804](https://www.youtube.com/about/policies/)[YouTube \uc791\ub3d9\uc758\n\uc6d0\ub9ac](https://www.youtube.com/howyoutubeworks?utm_campaign=ytgen&utm_source=ythp&utm_medium=LeftNav&utm_content=txt&u=https%3A%2F%2Fwww.youtube.com%2Fhowyoutubeworks%3Futm_source%3Dythp%26utm_medium%3DLeftNav%26utm_campaign%3Dytgen)[\uc0c8\ub85c\uc6b4\n\uae30\ub2a5 \ud14c\uc2a4\ud2b8\ud558\uae30](/new)\n\n(C) 2024 Google LLC, Sundar Pichai, 1600 Amphitheatre Parkway, Mountain View\nCA 94043, USA, 0807-882-594 (\ubb34\ub8cc), yt-support-solutions-kr@google.com, \ud638\uc2a4\ud305:\nGoogle LLC,\n[\uc0ac\uc5c5\uc790\uc815\ubcf4](http://www.ftc.go.kr/selectBizOvrCommPop.do?apvPermMgtNo=2022-\uacf5\uc815-0001),\n[\ubd88\ubc95\ucd2c\uc601\ubb3c \uc2e0\uace0](https://support.google.com/youtube?p=korea_report)  \n\ud06c\ub9ac\uc5d0\uc774\ud130\ub4e4\uc774 \uc720\ud29c\ube0c \uc0c1\uc5d0 \uac8c\uc2dc, \ud0dc\uadf8 \ub610\ub294 \ucd94\ucc9c\ud55c \uc0c1\ud488\ub4e4\uc740 \ud310\ub9e4\uc790\ub4e4\uc758 \uc57d\uad00\uc5d0 \ub530\ub77c \ud310\ub9e4\ub429\ub2c8\ub2e4. \uc720\ud29c\ube0c\ub294 \uc774\ub7ec\ud55c \uc81c\ud488\ub4e4\uc744 \ud310\ub9e4\ud558\uc9c0 \uc54a\uc73c\uba70,\n\uadf8\uc5d0 \ub300\ud55c \ucc45\uc784\uc744 \uc9c0\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.", "start_char_idx": 0, "end_char_idx": 1056, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b5b458c9-ec3d-4cfd-8e07-a4b30b392533": {"__data__": {"id_": "b5b458c9-ec3d-4cfd-8e07-a4b30b392533", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-6.txt", "file_name": "output-6.txt", "file_type": "text/plain", "file_size": 7542, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "736ffa74-53d0-4fef-ae17-a0ac147eb3f5", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-6.txt", "file_name": "output-6.txt", "file_type": "text/plain", "file_size": 7542, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "3377c496cd2f339e353466d1f8f52310bb3c39c60cf89436c22f40a7d550c6c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "77aaeb5f-e9bc-41a8-b6fc-6adce564b68e", "node_type": "1", "metadata": {}, "hash": "0468dc3e250c44bea1f199234acc9068db2106fa6baf8dee2098922d4c68fc7f", "class_name": "RelatedNodeInfo"}}, "text": "[LG AI Research](/)\n\n##\n\n  * [ABOUT](/about/vision)\n\n    * [VISION](/about/vision#about1)\n    * [LEADERSHIP](/about/vision#about2)\n    * [ETHICS PRINCIPLES](/about/vision#ethics)\n    * [LOCATION](/about/vision#about3)\n\n  * [SOLUTION](/exaone)\n  * [RESEARCH](/ourwork/research)\n\n    * [ADVANCED ML](/ourwork/research?tab=PA)\n    * [EXAONE](/ourwork/research?tab=PF)\n    * [LANGUAGE](/ourwork/research?tab=PB)\n    * [VISION](/ourwork/research?tab=PC)\n    * [MULTIMODAL](/ourwork/research?tab=PG)\n    * [DATA INTELLIGENCE](/ourwork/research?tab=PD)\n    * [MATERIALS INTELLIGENCE](/ourwork/research?tab=PE)\n\n  * [PUBLICATION](/publication/list)\n  * [CAREERS](/careers)\n\n    * [RECRUIT](/careers#section2)\n    * [RECRUITMENT PROCESS](/careers#section3)\n    * [CULTURE & BENEFIT](/careers#section4)\n    * [ACTIVITY](/careers#section5)\n\n  * [AI GRADUATE SCHOOL](/aigraduateschool/introduction)\n\n    * [INTRODUCTION](/aigraduateschool/introduction)\n    * [MEMBERS](/aigraduateschool/members/)\n    * [COURSE](/aigraduateschool/course)\n    * [FAQ](/aigraduateschool/faq)\n\n  * [BLOG&NEWS](/news)\n\n    * [RESEARCH BLOG](/blog)\n    * [NEWS](/news)\n\n[KR](javascript:;)\n\n  * KR\n  * EN\n\n\uac80\uc0c9 \uac80\uc0c9\ub2eb\uae30  \uba54\ub274\uc5f4\uae30  \uba54\ub274\ub2eb\uae30\n\n[LG AI Research](/)\n\n  * ABOUT\n    * [VISION](/about/vision#about1)\n    * [LEADERSHIP](/about/vision#about2)\n    * [ETHICS PRINCIPLES](/about/vision#ethics)\n    * [LOCATION](/about/vision#about3)\n  * [SOLUTION](/exaone)\n  * RESEARCH\n    * [ADVANCED ML](/ourwork/research?tab=PA)\n    * [EXAONE](/ourwork/research?tab=PF)\n    * [LANGUAGE](/ourwork/research?tab=PB)\n    * [VISION](/ourwork/research?tab=PC)\n    * [DATA INTELLIGENCE](/ourwork/research?tab=PD)\n    * [MATERIALS INTELLIGENCE](/ourwork/research?tab=PE)\n  * [PUBLICATION](/publication/list)\n  * CAREERS\n    * [RECRUIT](/careers#section2)\n    * [RECRUITMENT PROCESS](/careers#section3)\n    * [CULTURE & BENEFIT](/careers#section4)\n    * [ACTIVITY](/careers#section5)\n  * AI GRADUATE SCHOOL\n    * [INTRODUCTION](/aigraduateschool/introduction)\n    * [MEMBERS](/aigraduateschool/members)\n    * [COURSE](/aigraduateschool/course)\n    * [FAQ](/aigraduateschool/faq)\n  * BLOG&NEWS\n    * [RESEARCH BLOG](/blog)\n    * [NEWS](/news)\n\n[RECRUIT](/careers#section2) [LOCATION](/about/vision#about3)\n\n[_RESEARCH BLOG_](javascript:;)\n\n\ucc38\uace0\n\n    \n\n1\\. Redmon, Joseph, et al. \"You only look once: Unified, real-time object\ndetection.\" Proceedings of the IEEE conference on computer vision and pattern\nrecognition. 2016.\n\n2\\. Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. \"U-net: Convolutional\nnetworks for biomedical image segmentation.\" Medical Image Computing and\nComputer-Assisted Intervention?MICCAI 2015: 18th International Conference,\nMunich, Germany, October 5-9, 2015, Proceedings, Part III 18. Springer\nInternational Publishing, 2015.\n\n3\\. He, Kaiming, et al.", "start_char_idx": 0, "end_char_idx": 2808, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "77aaeb5f-e9bc-41a8-b6fc-6adce564b68e": {"__data__": {"id_": "77aaeb5f-e9bc-41a8-b6fc-6adce564b68e", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-6.txt", "file_name": "output-6.txt", "file_type": "text/plain", "file_size": 7542, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "736ffa74-53d0-4fef-ae17-a0ac147eb3f5", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-6.txt", "file_name": "output-6.txt", "file_type": "text/plain", "file_size": 7542, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "3377c496cd2f339e353466d1f8f52310bb3c39c60cf89436c22f40a7d550c6c0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5b458c9-ec3d-4cfd-8e07-a4b30b392533", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-6.txt", "file_name": "output-6.txt", "file_type": "text/plain", "file_size": 7542, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "49ca68e4eb354e74cc396b03aa6c81f71a05fc8ca769fb3316ad5065f5259a86", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "718a8243-5290-4bcc-9e58-53e28796a3a0", "node_type": "1", "metadata": {}, "hash": "5b737409e938148664b8a85b0dff44a4a9f8e0637fd6b224928130b298ce7f33", "class_name": "RelatedNodeInfo"}}, "text": "Redmon, Joseph, et al. \"You only look once: Unified, real-time object\ndetection.\" Proceedings of the IEEE conference on computer vision and pattern\nrecognition. 2016.\n\n2\\. Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. \"U-net: Convolutional\nnetworks for biomedical image segmentation.\" Medical Image Computing and\nComputer-Assisted Intervention?MICCAI 2015: 18th International Conference,\nMunich, Germany, October 5-9, 2015, Proceedings, Part III 18. Springer\nInternational Publishing, 2015.\n\n3\\. He, Kaiming, et al. \"Masked autoencoders are scalable vision learners.\"\nProceedings of the IEEE/CVF conference on computer vision and pattern\nrecognition. 2022.\n\n4\\. Caron, Mathilde, et al. \"Emerging properties in self-supervised vision\ntransformers.\" Proceedings of the IEEE/CVF international conference on\ncomputer vision. 2021.\n\n5\\. Bala?evi?, Ivana, et al. \"Towards In-context Scene Understanding.\" arXiv\npreprint arXiv:2306.01667 (2023).\n\n6\\. Grill, Jean-Bastien, et al. \"Bootstrap your own latent-a new approach to\nself-supervised learning.\" Advances in neural information processing systems\n33 (2020): 21271-21284.\n\n7\\. Gupta, Agrim, et al. \"Siamese Masked Autoencoders.\" arXiv preprint\narXiv:2305.14344 (2023).\n\n8\\. Vaswani, Ashish, et al. \"Attention is all you need.\" Advances in neural\ninformation processing systems 30 (2017).\n\n9\\. Radford, Alec, et al. \"Improving language understanding by generative pre-\ntraining.\" (2018).\n\n10\\. Radford, Alec, et al. \"Language models are unsupervised multitask\nlearners.\" OpenAI blog 1.8 (2019): 9.\n\n11\\. Brown, Tom, et al. \"Language models are few-shot learners.\" Advances in\nneural information processing systems 33 (2020): 1877-1901.\n\n12\\. Touvron, Hugo, et al. \"Llama: Open and efficient foundation language\nmodels.\" arXiv preprint arXiv:2302.13971 (2023).\n\n13\\. Schick, Timo, et al. \"Toolformer: Language models can teach themselves to\nuse tools.\" arXiv preprint arXiv:2302.04761 (2023).\n\n14\\. Hao, Shibo, et al. \"ToolkenGPT: Augmenting Frozen Language Models with\nMassive Tools via Tool Embeddings.\" arXiv preprint arXiv:2305.11554 (2023).\n\n15\\. Alayrac, Jean-Baptiste, et al. \"Flamingo: a visual language model for\nfew-shot learning.\" Advances in Neural Information Processing Systems 35\n(2022): 23716-23736.\n\n16\\. Yang, Zhengyuan, et al. \"The dawn of lmms: Preliminary explorations with\ngpt-4v (ision).\" arXiv preprint arXiv:2309.17421 9.1 (2023).\n\n17\\. Liu, Haotian, et al. \"Visual instruction tuning.\" arXiv preprint\narXiv:2304.08485 (2023).\n\n18\\. Dai, W., et al. \"InstructBLIP: Towards General-purpose Vision-Language\nModels with Instruction Tuning. arXiv 2023.\" arXiv preprint arXiv:2305.06500.\n\n19\\. Huang, Shaohan, et al. \"Language is not all you need: Aligning perception\nwith language models.\" arXiv preprint arXiv:2302.14045 (2023).\n\n20\\. Sun, Yasheng, et al. \"ImageBrush: Learning Visual In-Context Instructions\nfor Exemplar-Based Image Manipulation.\" arXiv preprint arXiv:2308.00906\n(2023).\n\n21\\. Rombach, Robin, et al. \"High-resolution image synthesis with latent\ndiffusion models.\" Proceedings of the IEEE/CVF conference on computer vision\nand pattern recognition. 2022.", "start_char_idx": 2286, "end_char_idx": 5428, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "718a8243-5290-4bcc-9e58-53e28796a3a0": {"__data__": {"id_": "718a8243-5290-4bcc-9e58-53e28796a3a0", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-6.txt", "file_name": "output-6.txt", "file_type": "text/plain", "file_size": 7542, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "736ffa74-53d0-4fef-ae17-a0ac147eb3f5", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-6.txt", "file_name": "output-6.txt", "file_type": "text/plain", "file_size": 7542, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "3377c496cd2f339e353466d1f8f52310bb3c39c60cf89436c22f40a7d550c6c0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "77aaeb5f-e9bc-41a8-b6fc-6adce564b68e", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-6.txt", "file_name": "output-6.txt", "file_type": "text/plain", "file_size": 7542, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "dff3493b8207721505736a428e48cac040f73a9c339a79d7f75dd4cbc170b69c", "class_name": "RelatedNodeInfo"}}, "text": "18\\. Dai, W., et al. \"InstructBLIP: Towards General-purpose Vision-Language\nModels with Instruction Tuning. arXiv 2023.\" arXiv preprint arXiv:2305.06500.\n\n19\\. Huang, Shaohan, et al. \"Language is not all you need: Aligning perception\nwith language models.\" arXiv preprint arXiv:2302.14045 (2023).\n\n20\\. Sun, Yasheng, et al. \"ImageBrush: Learning Visual In-Context Instructions\nfor Exemplar-Based Image Manipulation.\" arXiv preprint arXiv:2308.00906\n(2023).\n\n21\\. Rombach, Robin, et al. \"High-resolution image synthesis with latent\ndiffusion models.\" Proceedings of the IEEE/CVF conference on computer vision\nand pattern recognition. 2022.\n\n22\\. Saxena, Saurabh, et al. \"The Surprising Effectiveness of Diffusion Models\nfor Optical Flow and Monocular Depth Estimation.\" arXiv preprint\narXiv:2306.01923 (2023).\n\n23\\. Chen, Shoufa, et al. \"DiffusionDet: Diffusion model for object\ndetection.\" Proceedings of the IEEE/CVF International Conference on Computer\nVision. 2023.\n\n24\\. Tian, Yonglong, et al. \"StableRep: Synthetic Images from Text-to-Image\nModels Make Strong Visual Representation Learners.\" arXiv preprint\narXiv:2306.00984 (2023).\n\n25\\. Radford, Alec, et al. \"Learning transferable visual models from natural\nlanguage supervision.\" International conference on machine learning. PMLR,\n2021.\n\n26\\. Chen, Ting, et al. \"A simple framework for contrastive learning of visual\nrepresentations.\" International conference on machine learning. PMLR, 2020.\n\n27\\. Ouyang, Long, et al. \"Training language models to follow instructions\nwith human feedback.\" Advances in Neural Information Processing Systems 35\n(2022): 27730-27744.\n\n28\\. Rafailov, Rafael, et al. \"Direct preference optimization: Your language\nmodel is secretly a reward model.\" arXiv preprint arXiv:2305.18290 (2023).\n\n29\\. Fan, Ying, et al. \"DPOK: Reinforcement Learning for Fine-tuning Text-to-\nImage Diffusion Models.\" arXiv preprint arXiv:2305.16381 (2023).\n\n30\\. Devlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional\ntransformers for language understanding.\" arXiv preprint arXiv:1810.04805\n(2018).\n\n\ubaa9\ub85d\ubcf4\uae30\n\n![LG AI Research](/img/common/logo_en.png)\n\n[Youtube](https://www.youtube.com/channel/UCaoWx-ScnGYSrfKKcOn-\nYqA?view_as=subscriber) [Facebook](https://www.facebook.com/LG.ResearchAI/)\n[Linked in](https://www.linkedin.com/company/lgairesearch/)\n[Blog](https://post.naver.com/lgairesearch/)\n\n[CAREERS](/careers) [**\uac1c\uc778\uc815\ubcf4\ucc98\ub9ac\ubc29\uce68**](/policies) [\uc815\ub3c4\uacbd\uc601 \uc0ac\uc774\ubc84\n\uc2e0\ubb38\uace0](https://ethics.lg.co.kr/main/en.do)\n\n\u24d2 2020. LG AI Research. All Rights Reserved.\n\n![](/img/solution/bg_bottom_m.png) ![](/img/solution/bg_bottom_u.png)\n![](/img/solution/bg_bottom_d.png) ![](/img/solution/bg_bottom_a.png)\n\n\uc2a4\ud06c\ub864 \uc704\ub85c", "start_char_idx": 4790, "end_char_idx": 7452, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "24719111-9af2-4786-8839-f72734d6dd93": {"__data__": {"id_": "24719111-9af2-4786-8839-f72734d6dd93", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-7.txt", "file_name": "output-7.txt", "file_type": "text/plain", "file_size": 9323, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "93745d78-19d1-453e-9c94-4b1fb5fb8cc8", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-7.txt", "file_name": "output-7.txt", "file_type": "text/plain", "file_size": 9323, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "93bfa653cfaadc33d25c83163c03f9323391cccb3ecfff62969ab1e603ff400e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fdef97b7-bee4-478b-9056-9055c4a71454", "node_type": "1", "metadata": {}, "hash": "635160af553ae25ab85b5eb21312ed17ea335cdcc082f7448ebd89fd5cbdbfb6", "class_name": "RelatedNodeInfo"}}, "text": "Skip to main content\n\n[![Cornell University](/static/browse/0.3.4/images/icons/cu/cornell-reduced-\nwhite-SMALL.svg)](https://www.cornell.edu/)\n\nWe gratefully acknowledge support from the Simons Foundation, [member\ninstitutions](https://info.arxiv.org/about/ourmembers.html), and all\ncontributors. [Donate](https://info.arxiv.org/about/donate.html)\n\n[]({url_path\\('ignore_me'\\)})\n\n[![arxiv logo](/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](/)\n> [cs](/list/cs/recent) > arXiv:2212.10560\n\n[Help](https://info.arxiv.org/help) | [Advanced\nSearch](https://arxiv.org/search/advanced)\n\nAll fields Title Author Abstract Comments Journal reference ACM classification\nMSC classification Report number arXiv identifier DOI ORCID arXiv author ID\nHelp pages Full text\n\nSearch\n\n[![arXiv logo](/static/browse/0.3.4/images/arxiv-logomark-small-\nwhite.svg)](https://arxiv.org/)\n\n[ ![Cornell University Logo](/static/browse/0.3.4/images/icons/cu/cornell-\nreduced-white-SMALL.svg) ](https://www.cornell.edu/)\n\nopen search\n\nGO\n\nopen navigation menu\n\n## quick links\n\n  * [Login](https://arxiv.org/login)\n  * [Help Pages](https://info.arxiv.org/help)\n  * [About](https://info.arxiv.org/about)\n\n# Computer Science > Computation and Language\n\n**arXiv:2212.10560** (cs)\n\n[Submitted on 20 Dec 2022 ([v1](https://arxiv.org/abs/2212.10560v1)), last\nrevised 25 May 2023 (this version, v2)]\n\n# Title:Self-Instruct: Aligning Language Models with Self-Generated\nInstructions\n\nAuthors:[Yizhong\nWang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+Y), [Yeganeh\nKordi](https://arxiv.org/search/cs?searchtype=author&query=Kordi,+Y), [Swaroop\nMishra](https://arxiv.org/search/cs?searchtype=author&query=Mishra,+S), [Alisa\nLiu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+A), [Noah A.\nSmith](https://arxiv.org/search/cs?searchtype=author&query=Smith,+N+A),\n[Daniel\nKhashabi](https://arxiv.org/search/cs?searchtype=author&query=Khashabi,+D),\n[Hannaneh\nHajishirzi](https://arxiv.org/search/cs?searchtype=author&query=Hajishirzi,+H)\n\nView a PDF of the paper titled Self-Instruct: Aligning Language Models with\nSelf-Generated Instructions, by Yizhong Wang and 6 other authors\n\n[View PDF](/pdf/2212.10560)\n\n> Abstract:Large \"instruction-tuned\" language models (i.e., finetuned to\n> respond to instructions) have demonstrated a remarkable ability to\n> generalize zero-shot to new tasks. Nevertheless, they depend heavily on\n> human-written instruction data that is often limited in quantity, diversity,\n> and creativity, therefore hindering the generality of the tuned model. We\n> introduce Self-Instruct, a framework for improving the instruction-following\n> capabilities of pretrained language models by bootstrapping off their own\n> generations. Our pipeline generates instructions, input, and output samples\n> from a language model, then filters invalid or similar ones before using\n> them to finetune the original model. Applying our method to the vanilla\n> GPT3, we demonstrate a 33% absolute improvement over the original model on\n> Super-NaturalInstructions, on par with the performance of InstructGPT-001,\n> which was trained with private user data and human annotations. For further\n> evaluation, we curate a set of expert-written instructions for novel tasks,\n> and show through human evaluation that tuning GPT3 with Self-Instruct\n> outperforms using existing public instruction datasets by a large margin,\n> leaving only a 5% absolute gap behind InstructGPT-001.", "start_char_idx": 0, "end_char_idx": 3471, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fdef97b7-bee4-478b-9056-9055c4a71454": {"__data__": {"id_": "fdef97b7-bee4-478b-9056-9055c4a71454", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-7.txt", "file_name": "output-7.txt", "file_type": "text/plain", "file_size": 9323, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "93745d78-19d1-453e-9c94-4b1fb5fb8cc8", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-7.txt", "file_name": "output-7.txt", "file_type": "text/plain", "file_size": 9323, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "93bfa653cfaadc33d25c83163c03f9323391cccb3ecfff62969ab1e603ff400e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "24719111-9af2-4786-8839-f72734d6dd93", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-7.txt", "file_name": "output-7.txt", "file_type": "text/plain", "file_size": 9323, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "bde3f7eb59e1e5ca284083747a0bb9f7bf57caed886151852b024d814153b6e0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "214a3f20-1676-40bd-b0b5-d84d9be7ff33", "node_type": "1", "metadata": {}, "hash": "375fbaa0cfb122de4d7f81a9116233fb04a7ceb91ca3fff901c8c5f3dd22ff32", "class_name": "RelatedNodeInfo"}}, "text": "We\n> introduce Self-Instruct, a framework for improving the instruction-following\n> capabilities of pretrained language models by bootstrapping off their own\n> generations. Our pipeline generates instructions, input, and output samples\n> from a language model, then filters invalid or similar ones before using\n> them to finetune the original model. Applying our method to the vanilla\n> GPT3, we demonstrate a 33% absolute improvement over the original model on\n> Super-NaturalInstructions, on par with the performance of InstructGPT-001,\n> which was trained with private user data and human annotations. For further\n> evaluation, we curate a set of expert-written instructions for novel tasks,\n> and show through human evaluation that tuning GPT3 with Self-Instruct\n> outperforms using existing public instruction datasets by a large margin,\n> leaving only a 5% absolute gap behind InstructGPT-001. Self-Instruct\n> provides an almost annotation-free method for aligning pre-trained language\n> models with instructions, and we release our large synthetic dataset to\n> facilitate future studies on instruction tuning. Our code and data are\n> available at [this https URL](https://github.com/yizhongw/self-instruct).\n\nComments: | ACL 2023 camera ready, 23 pages, 9 figures, 11 tables  \n---|---  \nSubjects: |  Computation and Language (cs.CL); Artificial Intelligence (cs.AI)  \nCite as: | [arXiv:2212.10560](https://arxiv.org/abs/2212.10560) [cs.CL]  \n  | (or  [arXiv:2212.10560v2](https://arxiv.org/abs/2212.10560v2) [cs.CL] for\nthis version)  \n  |  <https://doi.org/10.48550/arXiv.2212.10560>\n\nFocus to learn more\n\narXiv-issued DOI via DataCite  \n  \n## Submission history\n\nFrom: Yizhong Wang [[view email](/show-email/303371ba/2212.10560)]  \n**[[v1]](/abs/2212.10560v1)** Tue, 20 Dec 2022 18:59:19 UTC (4,072 KB)  \n**[v2]** Thu, 25 May 2023 23:50:07 UTC (7,954 KB)  \n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Self-Instruct: Aligning Language Models with\nSelf-Generated Instructions, by Yizhong Wang and 6 other authors\n\n  * [View PDF](/pdf/2212.10560)\n  * [TeX Source](/src/2212.10560)\n  * [Other Formats](/format/2212.10560)\n\n[ ![license icon](https://arxiv.org/icons/licenses/by-4.0.png) view license\n](http://creativecommons.org/licenses/by/4.0/ \"Rights to this article\")\n\nCurrent browse context:\n\ncs.CL\n\n[< prev](/prevnext?id=2212.10560&function=prev&context=cs.CL \"previous in\ncs.CL \\(accesskey p\\)\")   |   [next\n>](/prevnext?id=2212.10560&function=next&context=cs.CL \"next in cs.CL\n\\(accesskey n\\)\")  \n\n[new](/list/cs.CL/new) |  [recent](/list/cs.CL/recent) |\n[2212](/list/cs.CL/2212)\n\nChange to browse by:\n\n[cs](/abs/2212.10560?context=cs)  \n[cs.AI](/abs/2212.10560?context=cs.AI)  \n\n### References & Citations\n\n  * [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2212.10560)\n  * [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2212.10560)\n  * [Semantic Scholar](https://api.semanticscholar.org/arXiv:2212.10560)\n\n[a](/static/browse/0.3.4/css/cite.css) export BibTeX citation Loading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nloading...\n\nData provided by:\n\n### Bookmark\n\n[ !", "start_char_idx": 2572, "end_char_idx": 5696, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "214a3f20-1676-40bd-b0b5-d84d9be7ff33": {"__data__": {"id_": "214a3f20-1676-40bd-b0b5-d84d9be7ff33", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-7.txt", "file_name": "output-7.txt", "file_type": "text/plain", "file_size": 9323, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "93745d78-19d1-453e-9c94-4b1fb5fb8cc8", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-7.txt", "file_name": "output-7.txt", "file_type": "text/plain", "file_size": 9323, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "93bfa653cfaadc33d25c83163c03f9323391cccb3ecfff62969ab1e603ff400e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fdef97b7-bee4-478b-9056-9055c4a71454", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-7.txt", "file_name": "output-7.txt", "file_type": "text/plain", "file_size": 9323, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "03ab42e8ebb7b6478b337b40d0303fb346f3272940ff3b9ce310216cf19597fe", "class_name": "RelatedNodeInfo"}}, "text": "[BibSonomy logo](/static/browse/0.3.4/images/icons/social/bibsonomy.png)\n](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2212.10560&description=Self-\nInstruct: Aligning Language Models with Self-Generated Instructions \"Bookmark\non BibSonomy\") [ ![Reddit\nlogo](/static/browse/0.3.4/images/icons/social/reddit.png)\n](https://reddit.com/submit?url=https://arxiv.org/abs/2212.10560&title=Self-\nInstruct: Aligning Language Models with Self-Generated Instructions \"Bookmark\non Reddit\")\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _([What is the\nExplorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-\nexplorer))_\n\nLitmaps Toggle\n\nLitmaps _([What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _([What is\nCatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _([What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _([What is GotitPub?](http://gotit.pub/faq))_\n\nLinks to Code Toggle\n\nPapers with Code _([What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _([What is\nSpaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _([What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _([What are Influence\nFlowers?](https://influencemap.cmlab.dev/))_\n\nConnected Papers Toggle\n\nConnected Papers _([What is Connected\nPapers?](https://www.connectedpapers.com/about))_\n\nCore recommender toggle\n\nCORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_\n\n  * Author\n  * Venue\n  * Institution\n  * Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new\narXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and\naccepted our values of openness, community, excellence, and user data privacy.\narXiv is committed to these values and only works with partners that adhere to\nthem.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn\nmore about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](/auth/show-endorsers/2212.10560)\n| [Disable MathJax](javascript:setMathjaxCookie\\(\\)) ([What is\nMathJax?](https://info.arxiv.org/help/mathjax.html))\n\n  * [About](https://info.arxiv.org/about)\n  * [Help](https://info.arxiv.org/help)\n\n  * contact arXivClick here to contact arXiv [ Contact](https://info.arxiv.org/help/contact.html)\n  * subscribe to arXiv mailingsClick here to subscribe [ Subscribe](https://info.arxiv.org/help/subscribe)\n\n  * [Copyright](https://info.arxiv.org/help/license/index.html)\n  * [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n  * [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n  * [arXiv Operational Status ](https://status.arxiv.org)  \nGet status notifications via\n[email](https://subscribe.sorryapp.com/24846f03/email/new) or\n[slack](https://subscribe.sorryapp.com/24846f03/slack/new)", "start_char_idx": 5696, "end_char_idx": 9320, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0fee632c-f8a3-4512-9eea-6f99b0f2f33a": {"__data__": {"id_": "0fee632c-f8a3-4512-9eea-6f99b0f2f33a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58c0404a-5344-4120-9114-567073e84eae", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "5a2a48ee2edd95cff0a138af81c5d0505ad19a8c674bd4653d299e7fbf904fc1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6f341021-8fd7-4af6-bd3a-2f2f6518161a", "node_type": "1", "metadata": {}, "hash": "4cc4d425075e4b1b5af0297cbcf44c22f29bdb4621aea7b3764326825933ffd1", "class_name": "RelatedNodeInfo"}}, "text": "\ubcf8\ubb38 \ubc14\ub85c\uac00\uae30\n\n# [Ostin X](https://ostin.tistory.com/)\n\n\uba54\ub274\n\n  * [ \ubd84\ub958 \uc804\uccb4\ubcf4\uae30 (479) ](/category)\n    * [ \ub17c\ubb38 \ub9ac\ubdf0 (412) ](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0)\n      * [ Language Model (119) ](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/Language%20Model)\n      * [ Diffusion Model (136) ](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/Diffusion%20Model)\n      * [ Vision Transformer (62) ](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/Vision%20Transformer)\n      * [ Mamba (7) ](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/Mamba)\n      * [ GAN (20) ](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/GAN)\n      * [ etc. (56) ](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/etc.)\n      * [ Concept (5) ](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/Concept)\n      * [ \ub17c\ubb38 \ubd84\ub958 (7) ](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/%EB%85%BC%EB%AC%B8%20%EB%B6%84%EB%A5%98)\n    * [ \ucf54\ub4dc \ub9ac\ubdf0 (8) ](/category/%EC%BD%94%EB%93%9C%20%EB%A6%AC%EB%B7%B0)\n      * [ Diffusion (8) ](/category/%EC%BD%94%EB%93%9C%20%EB%A6%AC%EB%B7%B0/Diffusion)\n    * [ Deep Learning (34) ](/category/Deep%20Learning)\n      * [ GAN (14) ](/category/Deep%20Learning/GAN)\n      * [ Fine Tuning (10) ](/category/Deep%20Learning/Fine%20Tuning)\n      * [ Diffusion (4) ](/category/Deep%20Learning/Diffusion)\n      * [ Memo or etc. (6) ](/category/Deep%20Learning/Memo%20or%20etc.)\n    * [ Code, Error, Tip, Etc. (4) ](/category/Code%2C%20Error%2C%20Tip%2C%20Etc.)\n    * [ Output (8) ](/category/Output)\n      * [ Model (4) ](/category/Output/Model)\n      * [ Small Things (4) ](/category/Output/Small%20Things)\n    * [ \uc0ac\uc124 (13) ](/category/%EC%82%AC%EC%84%A4)\n      * [ X (0) ](/category/%EC%82%AC%EC%84%A4/X)\n      * [ \ub3c5\ud6c4\uac10 (3) ](/category/%EC%82%AC%EC%84%A4/%EB%8F%85%ED%9B%84%EA%B0%90)\n\n\ube14\ub85c\uadf8 \ub0b4 \uac80\uc0c9 \uac80\uc0c9\n\n* * *\n\n\ub17c\ubb38 \ub9ac\ubdf0/Language Model\n\n# Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video\nUnderstanding\n\nOstin 2023\\. 6. 11. 12:56\n\n\ube44\ub514\uc624\ub97c \uc774\ud574\ud558\ub294 \uc5b8\uc5b4 \ubaa8\ub378\n\n\n\n[Github](https://github.com/damo-nlp-sg/video-llama)\n\n[arXiv](https://arxiv.org/abs/2306.02858)\n\n\n\n![](https://blog.kakaocdn.net/dn/cJB0N5/btsjnHt7h7Z/u8vd4xbpPBm1ZIepbwFwKK/img.gif)", "start_char_idx": 0, "end_char_idx": 2139, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6f341021-8fd7-4af6-bd3a-2f2f6518161a": {"__data__": {"id_": "6f341021-8fd7-4af6-bd3a-2f2f6518161a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58c0404a-5344-4120-9114-567073e84eae", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "5a2a48ee2edd95cff0a138af81c5d0505ad19a8c674bd4653d299e7fbf904fc1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0fee632c-f8a3-4512-9eea-6f99b0f2f33a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ca6c54f617529cb4d4eedb2dea154fdf97c17fad2bd12ed8fb7aa50463d0f3b9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "39a6f96e-0092-4108-9efe-e5188c4d7b5b", "node_type": "1", "metadata": {}, "hash": "c29582586074bd1937c8cb8cad7671b7e2787e391f406f4834d421fa6bbee372", "class_name": "RelatedNodeInfo"}}, "text": "[Github](https://github.com/damo-nlp-sg/video-llama)\n\n[arXiv](https://arxiv.org/abs/2306.02858)\n\n\n\n![](https://blog.kakaocdn.net/dn/cJB0N5/btsjnHt7h7Z/u8vd4xbpPBm1ZIepbwFwKK/img.gif)\n\n\n\n## **Abstract**\n\nVideo Q-former, Audio Q-former\ub97c \ud1b5\ud574 \ube44\ub514\uc624\uc758 \uc2dc\uccad\uac01 \ucf58\ud150\uce20\ub97c \uc774\ud574\ud558\ub294 multi-modal framework\uc778\nVideo-LLaMA \uc81c\uc548.\n\n\n\n\n\n\n\n## **Related Works**\n\n[BLIP & BLIP-2](https://junia3.github.io/blog/BLIP)\n\n[MiniGPT-4](https://moon-\nwalker.medium.com/%EB%A6%AC%EB%B7%B0-llama%EA%B8%B0%EB%B0%98-vicuna%EC%99%80-vicuna%EA%B8%B0%EB%B0%98-multi-\nmodal-%EB%AA%A8%EB%8D%B8-minigpt-4-31838c4193c5)\n\n[ImageBind](https://ostin.tistory.com/201)\n\n\n\n\n\n## **Introduction**\n\nBLIP-2\uc758 \uc544\uc774\ub514\uc5b4\ub97c \ucc44\ud0dd\ud574 Video Q-former, Audio Q-former\ub97c \ub3c4\uc785\ud558\uace0 multi-branch cross-\nmodel \uace0\uc548.\n\n![](https://blog.kakaocdn.net/dn/bN3V0g/btsjkGcfAUU/3HlPMzsQ1w4m60BeEU9bz0/img.png)\n\n\n\nAudio-text \ub370\uc774\ud130\uac00 \uc874\uc7ac\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 \ub300\uc751\uc744 \uc704\ud574 ImageBind\ub97c \uc778\ucf54\ub354\ub85c \ud65c\uc6a9.\n\n\n\n\n\n\n\n## ****Method****\n\n#### **Architecture**\n\n#### **Vision-Language Branch**\n\n![](https://blog.kakaocdn.net/dn/bzF3iJ/btsjseyg090/Caj4Nrzple1Dc0U5nTxM3K/img.png)\n\n\uc774\ubbf8\uc9c0 \uc778\ucf54\ub354, \uc704\uce58 \uc784\ubca0\ub529 \ub808\uc774\uc5b4, Q-Former, \ucd5c\uc885 \uc120\ud615 \ub808\uc774\uc5b4\ub85c \uad6c\uc131\n\n\n\n\uac01 \ud504\ub808\uc784\uc744 \uc774\ubbf8\uc9c0 \uc778\ucf54\ub354\ub85c \uc778\ucf54\ub529\ud558\uace0 \uc2dc\uac04 \uc815\ubcf4\ub97c \uc704\uce58 \uc784\ubca0\ub529\uc73c\ub85c \uc8fc\uc785\ud55c \ub4a4, BLIP-2\uc640 \ub3d9\uc77c\ud55c \uc544\ud0a4\ud14d\ucc98\uc758 Q-Former\uc5d0 \uc785\ub825\ud558\uace0\n\uc5b8\uc5b4 \ubaa8\ub378\uacfc \uac19\uc740 \ucc28\uc6d0\uc73c\ub85c \ub9de\ucd94\uae30 \uc704\ud574 \ucd5c\uc885 \uc120\ud615 \ub808\uc774\uc5b4\ub97c \ud1b5\uacfc\ud568.\n\n* * *\n\n#### **Audio-Language Branch**\n\n![](https://blog.kakaocdn.net/dn/dxHxqS/btsjtAusVkO/KT2xkzMzYe6KMSd34RqCdk/img.png)\n\n\uc624\ub514\uc624 \uc778\ucf54\ub354\ub85c ImageBind \uc0ac\uc6a9.\n\n\uad6c\uccb4\uc801\uc73c\ub85c \ube44\ub514\uc624\ub97c M \uad6c\uac04\uc73c\ub85c \ub098\ub208 \ub4a4\uc5d0 spectrogram\uc73c\ub85c \ubcc0\ud658\ud558\uace0 \uc778\ucf54\ub354\ub97c \ud1b5\ud574 \ubca1\ud130\ub85c \uc784\ubca0\ub529\ud558\ub294 \uacfc\uc815\uc744 \uac70\uce68.\n\n\n\n\ub098\uba38\uc9c0\ub294 video branch\uc640 \uac19\uc74c.\n\n\n\n\n\n\n\n#### **Multi-branch Cross-Modal Training**\n\n#### **Training of Vision-Language Branch**\n\n\ub178\uc774\uc988\uac00 \ub9ce\uc740 \ub300\uaddc\ubaa8 video-text \ub370\uc774\ud130\uc5d0\uc11c \uc0ac\uc804 \ud6c8\ub828\ud558\uace0 \uace0\ud488\uc9c8\uc758 \uc18c\uaddc\ubaa8 \ub370\uc774\ud130\uc14b\uc5d0\uc11c fine-tuning\ud558\ub294 \ubc29\ubc95\uc73c\ub85c \ud559\uc2b5.\n\n\ucd5c\uadfc \uc5b8\uc5b4 \ubaa8\ub378 \ud6c8\ub828\uc5d0\uc11c \ub9e4\uc6b0 \ud754\ud558\uac8c \uc4f0\uc774\ub294 \ubc29\ubc95.\n\n\n\n#### **Training of Audio-Language Branch**\n\n\uc77c\ub2e8 audio-text \ub370\uc774\ud130 \uc790\uccb4\uac00 \ub9ce\uc774 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc74c.\n\n\ub530\ub77c\uc11c \uc778\ucf54\ub354\ub85c ImageBind\ub97c \ucc44\ud0dd.", "start_char_idx": 1957, "end_char_idx": 3699, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "39a6f96e-0092-4108-9efe-e5188c4d7b5b": {"__data__": {"id_": "39a6f96e-0092-4108-9efe-e5188c4d7b5b", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58c0404a-5344-4120-9114-567073e84eae", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "5a2a48ee2edd95cff0a138af81c5d0505ad19a8c674bd4653d299e7fbf904fc1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6f341021-8fd7-4af6-bd3a-2f2f6518161a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "dd67261c69fbd9607c918bc4c82675dc17d0ca6fe8561205ab2dff3cda538921", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "653071b9-84f6-402b-a0a3-befc27ca14cb", "node_type": "1", "metadata": {}, "hash": "1a076dbedcc7811b7d272b7488f04cb40fb250229ce24f44791a89d9bf743625", "class_name": "RelatedNodeInfo"}}, "text": "\ub098\uba38\uc9c0\ub294 video branch\uc640 \uac19\uc74c.\n\n\n\n\n\n\n\n#### **Multi-branch Cross-Modal Training**\n\n#### **Training of Vision-Language Branch**\n\n\ub178\uc774\uc988\uac00 \ub9ce\uc740 \ub300\uaddc\ubaa8 video-text \ub370\uc774\ud130\uc5d0\uc11c \uc0ac\uc804 \ud6c8\ub828\ud558\uace0 \uace0\ud488\uc9c8\uc758 \uc18c\uaddc\ubaa8 \ub370\uc774\ud130\uc14b\uc5d0\uc11c fine-tuning\ud558\ub294 \ubc29\ubc95\uc73c\ub85c \ud559\uc2b5.\n\n\ucd5c\uadfc \uc5b8\uc5b4 \ubaa8\ub378 \ud6c8\ub828\uc5d0\uc11c \ub9e4\uc6b0 \ud754\ud558\uac8c \uc4f0\uc774\ub294 \ubc29\ubc95.\n\n\n\n#### **Training of Audio-Language Branch**\n\n\uc77c\ub2e8 audio-text \ub370\uc774\ud130 \uc790\uccb4\uac00 \ub9ce\uc774 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc74c.\n\n\ub530\ub77c\uc11c \uc778\ucf54\ub354\ub85c ImageBind\ub97c \ucc44\ud0dd.\n\n\n\n\ud6c8\ub828\uc740 visual-text \ub370\uc774\ud130\ub85c \uc9c4\ud589\ub418\uc9c0\ub9cc ImageBind\uc758 \ucc3d\ubc1c\uc801\uc778 \ud2b9\uc131 \ub355\ubd84\uc5d0 \uc624\ub514\uc624\ub97c \uc774\ud574\ud560 \uc218 \uc788\uac8c \ub41c\ub2e4\uace0 \ud55c\ub2e4.\n\n(Visual data\uac00 \uc815\ud655\ud788 \uc815\uc758\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc740\ub370, \uc2a4\ud399\ud2b8\ub85c\uadf8\ub7a8\uc744 \ub9d0\ud558\ub294 \ub4ef.\n\n\uc608\uc2dc\ub97c \ubcf4\uba74 \uc74c\uc131 \uc815\ubcf4\ub97c \uc798 \uc774\ud574\ud558\uae34 \ud558\ub294 \ub4ef?)\n\n![](https://blog.kakaocdn.net/dn/cB5vVW/btsjlYDfoF8/XXS5tBK3s4HyMdk6BTOO81/img.png)\n\n\n\n\n\n\n\n## **Examples**\n\n\uc0ac\uc2e4 \uc608\uc2dc\ub85c \ub098\uc640\uc788\ub294 \uc815\ub3c4\ub85c\ub294 \uc131\ub2a5\uc744 \uc54c \uc218 \uc5c6\uc5b4\uc11c [hugging face\nspace](https://huggingface.co/spaces/DAMO-NLP-SG/Video-LLaMA)\uc5d0\uc11c \ud55c \ubc88 \uc368\ubcfc\ub824\uace0 \ud588\ub294\ub370\n\ub85c\ub529\uc774 \ub108~\ubb34 \uc624\ub798 \uac78\ub824\uc11c \ud3ec\uae30\ud568.\n\n![](https://blog.kakaocdn.net/dn/bCAGAe/btsjjCA9g0x/BOioOCWM2hzTwa2UYZyz70/img.png)\n![](https://blog.kakaocdn.net/dn/mpq0Z/btsjpD59tjp/PefZuUWAsG6mzeTNDgwHr1/img.png)\n\n\uacf5\uc720\ud558\uae30\n\n\uac8c\uc2dc\uae00 \uad00\ub9ac\n\n_\uad6c\ub3c5\ud558\uae30_ **Ostin X**\n\n[ \uc800\uc791\uc790\ud45c\uc2dc ](https://creativecommons.org/licenses/by/4.0/deed.ko)\n\n#### '[\ub17c\ubb38 \ub9ac\ubdf0](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0) > [Language\nModel](/category/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/Language%20Model)'\n\uce74\ud14c\uace0\ub9ac\uc758 \ub2e4\ub978 \uae00\n\n[Efficient Streaming Language Models with Attention Sinks\n(StreamingLLM)](/235)  (1) | 2023.10.06  \n---|---  \n[LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models](/228)\n(0) | 2023.09.26  \n[Augmenting Language Models with Long-Term Memory (LongMem)](/218)  (0) |\n2023.07.08  \n[LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model](/209)  (0) |\n2023.06.15  \n[LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init\nAttention](/208)  (0) | 2023.06.15  \n[LoRA: Low-Rank Adaptation of Large Language Models](/171)  (0) | 2023.01.30  \n  \n## **'\ub17c\ubb38 \ub9ac\ubdf0/Language Model'** Related Articles\n\n  * [ ![](//i1.daumcdn.net/thumb/C264x200/?fname=https://img1.daumcdn.net/thumb/R750x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQ5n2E%2FbtsmRMrNGKT%2FnES8k03sshDs3TlTP1sVTK%2Fimg.png) Augmenting Language Models with Long-Term Memory (LongMem) ](/218?category=1070155)\n  * [ !", "start_char_idx": 3369, "end_char_idx": 5452, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "653071b9-84f6-402b-a0a3-befc27ca14cb": {"__data__": {"id_": "653071b9-84f6-402b-a0a3-befc27ca14cb", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58c0404a-5344-4120-9114-567073e84eae", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "5a2a48ee2edd95cff0a138af81c5d0505ad19a8c674bd4653d299e7fbf904fc1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "39a6f96e-0092-4108-9efe-e5188c4d7b5b", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "bf99c6623c61a7f3df09cdf8da68f8312eb1a5fdc232573f35278e6e20adabf5", "class_name": "RelatedNodeInfo"}}, "text": "[](//i1.daumcdn.net/thumb/C264x200/?fname=https://img1.daumcdn.net/thumb/R750x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQ5n2E%2FbtsmRMrNGKT%2FnES8k03sshDs3TlTP1sVTK%2Fimg.png) Augmenting Language Models with Long-Term Memory (LongMem) ](/218?category=1070155)\n  * [ ![](//i1.daumcdn.net/thumb/C264x200/?fname=https://img1.daumcdn.net/thumb/R750x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbfmyoM%2FbtsjZySsjGW%2FlJAZKDCjIQXWSA1ZGC67F0%2Fimg.png) LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model ](/209?category=1070155)\n  * [ ![](//i1.daumcdn.net/thumb/C264x200/?fname=https://img1.daumcdn.net/thumb/R750x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FAkNHl%2Fbtsj5QQ6zrN%2FfIgfgBjFDjr8tEcu5uFzKK%2Fimg.jpg) LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention ](/208?category=1070155)\n  * [ ![](//i1.daumcdn.net/thumb/C264x200/?fname=https://img1.daumcdn.net/thumb/R750x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbjfCWe%2FbtrXBzRJnyU%2FhZxRZYW1SEjgn9NqlnIo7K%2Fimg.png) LoRA: Low-Rank Adaptation of Large Language Models ](/171?category=1070155)\n\nSecret\n\n\ub313\uae00\n\n\ub313\uae00\ub2ec\uae30\n\n* * *\n\nDESIGN BY TISTORY [\uad00\ub9ac\uc790](https://ostin.tistory.com/manage)\n\n## \ud2f0\uc2a4\ud1a0\ub9ac\ud234\ubc14", "start_char_idx": 5163, "end_char_idx": 6426, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2bff4304-f47f-4130-a344-3f16f56915d1": {"__data__": {"id_": "2bff4304-f47f-4130-a344-3f16f56915d1", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "09837228-925f-41d0-a672-1e1a9d909905", "node_type": "1", "metadata": {}, "hash": "929d5f311ff3ba13cc08fcec8467bc2477c03892ecd6dfe492207d261c942b42", "class_name": "RelatedNodeInfo"}}, "text": "Skip to content\n\n## Navigation Menu\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Frosinality%2Fml-\npapers)\n\n  * Product \n\n    * [ Actions Automate any workflow  ](https://github.com/features/actions)\n    * [ Packages Host and manage packages  ](https://github.com/features/packages)\n    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)\n    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Copilot Write better code with AI  ](https://github.com/features/copilot)\n    * [ Code review Manage code changes  ](https://github.com/features/code-review)\n    * [ Issues Plan and track work  ](https://github.com/features/issues)\n    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)\n\nExplore\n\n    * [ All features ](https://github.com/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](https://github.com/enterprise)\n    * [ Teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](https://github.com/solutions/ci-cd)\n    * [ DevOps ](https://github.com/solutions/devops)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners  ](https://partner.github.com)\n\n  * Open Source \n\n    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)\n\n    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)\n\nRepositories\n\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n\n  * [Pricing](https://github.com/pricing)\n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our\n[documentation](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax).\n\nCancel  Create saved search\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Frosinality%2Fml-\npapers)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=rosinality%2Fml-\npapers)\n\nYou signed in with another tab or window. [Reload]() to refresh your session.\nYou signed out in another tab or window. [Reload]() to refresh your session.\nYou switched accounts on another tab or window. [Reload]() to refresh your\nsession.", "start_char_idx": 0, "end_char_idx": 3297, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "09837228-925f-41d0-a672-1e1a9d909905": {"__data__": {"id_": "09837228-925f-41d0-a672-1e1a9d909905", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2bff4304-f47f-4130-a344-3f16f56915d1", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "7f8718fe251685e8bb7847ecc10286ba14dd93df9cbf70722dfa578f9fb6b491", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d6016afa-1808-40dc-8f75-b749e7750b53", "node_type": "1", "metadata": {}, "hash": "7a5f224fdf016d629f37dfbf10d9072fbb32b0f27338c3338de0f81b42e2a970", "class_name": "RelatedNodeInfo"}}, "text": "Cancel  Create saved search\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Frosinality%2Fml-\npapers)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=rosinality%2Fml-\npapers)\n\nYou signed in with another tab or window. [Reload]() to refresh your session.\nYou signed out in another tab or window. [Reload]() to refresh your session.\nYou switched accounts on another tab or window. [Reload]() to refresh your\nsession. Dismiss alert\n\n{{ message }}\n\n[ rosinality ](/rosinality) / **[ml-papers](/rosinality/ml-papers) ** Public\n\n  * [ Notifications ](/login?return_to=%2Frosinality%2Fml-papers)\n  * [ Fork 21 ](/login?return_to=%2Frosinality%2Fml-papers)\n  * [ Star  255 ](/login?return_to=%2Frosinality%2Fml-papers)\n\n  * \n\nMy collection of machine learning papers\n\n### License\n\n[ MIT license ](/rosinality/ml-papers/blob/main/LICENSE)\n\n[ 255 stars ](/rosinality/ml-papers/stargazers) [ 21 forks ](/rosinality/ml-\npapers/forks) [ Branches ](/rosinality/ml-papers/branches) [ Tags\n](/rosinality/ml-papers/tags) [ Activity ](/rosinality/ml-papers/activity)\n\n[ Star  ](/login?return_to=%2Frosinality%2Fml-papers)\n\n[ Notifications ](/login?return_to=%2Frosinality%2Fml-papers)\n\n  * [ Code ](/rosinality/ml-papers)\n  * [ Issues 1 ](/rosinality/ml-papers/issues)\n  * [ Pull requests 0 ](/rosinality/ml-papers/pulls)\n  * [ Actions ](/rosinality/ml-papers/actions)\n  * [ Projects 0 ](/rosinality/ml-papers/projects)\n  * [ Security ](/rosinality/ml-papers/security)\n  * [ Insights ](/rosinality/ml-papers/pulse)\n\nAdditional navigation options\n\n  * [ Code ](/rosinality/ml-papers)\n  * [ Issues ](/rosinality/ml-papers/issues)\n  * [ Pull requests ](/rosinality/ml-papers/pulls)\n  * [ Actions ](/rosinality/ml-papers/actions)\n  * [ Projects ](/rosinality/ml-papers/projects)\n  * [ Security ](/rosinality/ml-papers/security)\n  * [ Insights ](/rosinality/ml-papers/pulse)\n\n# rosinality/ml-papers\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\nmain\n\n[Branches](/rosinality/ml-papers/branches)[Tags](/rosinality/ml-papers/tags)\n\n[](/rosinality/ml-papers/branches)[](/rosinality/ml-papers/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\nName| Name|\n\nLast commit message\n\n|\n\nLast commit date  \n  \n---|---|---|---  \n  \n## Latest commit\n\n## History\n\n[30 Commits](/rosinality/ml-papers/commits/main/)\n\n[](/rosinality/ml-papers/commits/main/)  \n  \n###\n\n[papers](/rosinality/ml-papers/tree/main/papers \"papers\")\n\n|\n\n###\n\n[papers](/rosinality/ml-papers/tree/main/papers \"papers\")\n\n|\n\n|  \n  \n###\n\n[LICENSE](/rosinality/ml-papers/blob/main/LICENSE \"LICENSE\")\n\n|\n\n###\n\n[LICENSE](/rosinality/ml-papers/blob/main/LICENSE \"LICENSE\")\n\n|\n\n|  \n  \n###\n\n[README.md](/rosinality/ml-papers/blob/main/README.md \"README.md\")\n\n|\n\n###\n\n[README.md](/rosinality/ml-papers/blob/main/README.md \"README.md\")\n\n|\n\n|  \n  \nView all files  \n  \n## Repository files navigation\n\n  * README\n  * MIT license\n\n# ML Papers\n\n### Reviews\n\n  1. [191210 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/191210%20Thoughts%20on%20recent%20papers.md)\n  2. [200323 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/200323%20Thoughts%20on%20recent%20papers.md)\n  3.", "start_char_idx": 2782, "end_char_idx": 6068, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d6016afa-1808-40dc-8f75-b749e7750b53": {"__data__": {"id_": "d6016afa-1808-40dc-8f75-b749e7750b53", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09837228-925f-41d0-a672-1e1a9d909905", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "dccf9c6276056cfc439524c2052c6515115c7a65ec0bf4ce69803f7b28211a69", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2ac50580-600c-4f0e-930b-e591e9190573", "node_type": "1", "metadata": {}, "hash": "1087e973ae5edce072bfa20a60010157223d4e54073da990623765e7f002ed2e", "class_name": "RelatedNodeInfo"}}, "text": "[191210 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/191210%20Thoughts%20on%20recent%20papers.md)\n  2. [200323 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/200323%20Thoughts%20on%20recent%20papers.md)\n  3. [200326 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/200326%20Thoughts%20on%20recent%20papers.md)\n  4. [200403 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/200403%20Thoughts%20on%20recent%20papers.md)\n  5. [200411 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/200411%20Thoughts%20on%20recent%20papers.md)\n  6. [200708 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/200708%20Thoughts%20on%20recent%20papers.md)\n  7. [200717 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/200717%20Thoughts%20on%20recent%20papers.md)\n  8. [200726 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/200726%20Thoughts%20on%20recent%20papers.md)\n  9. [200802 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/200802%20Thoughts%20on%20recent%20papers.md)\n  10. [201118 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/201118%20Thoughts%20on%20recent%20papers.md)\n  11. [201120 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/201120%20Thoughts%20on%20recent%20papers.md)\n  12. [201125 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/201125%20Thoughts%20on%20recent%20papers.md)\n  13. [201126 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01 1](/rosinality/ml-papers/blob/main/papers/reviews/201126%20Thoughts%20on%20recent%20papers%201.md)\n  14. [201126 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01 2](/rosinality/ml-papers/blob/main/papers/reviews/201126%20Thoughts%20on%20recent%20papers%202.md)\n  15. [201204 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/201204%20Thoughts%20on%20recent%20papers.md)\n  16. [210121 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210121%20Thoughts%20on%20recent%20papers.md)\n  17. [210121 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210227%20Thoughts%20on%20recent%20papers.md)\n  18. [210305 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210305%20Thoughts%20on%20recent%20papers.md)\n  19.", "start_char_idx": 5829, "end_char_idx": 8010, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2ac50580-600c-4f0e-930b-e591e9190573": {"__data__": {"id_": "2ac50580-600c-4f0e-930b-e591e9190573", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d6016afa-1808-40dc-8f75-b749e7750b53", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "32076d8d372c7f4dd3e317330d3c744a914e6a87ad166efef4734747bd249a1d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c8118d5-8ee6-459a-8d47-d0adeb7c88ea", "node_type": "1", "metadata": {}, "hash": "215b6427dc9c87bd93dd99bab45efc50591af5d44a549abe3ac3374c1d73fb1c", "class_name": "RelatedNodeInfo"}}, "text": "[210121 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210121%20Thoughts%20on%20recent%20papers.md)\n  17. [210121 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210227%20Thoughts%20on%20recent%20papers.md)\n  18. [210305 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210305%20Thoughts%20on%20recent%20papers.md)\n  19. [210319 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210319%20Thoughts%20on%20recent%20papers.md)\n  20. [210323 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210323%20Thoughts%20on%20recent%20papers.md)\n  21. [210326 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210326%20Thoughts%20on%20recent%20papers.md)\n  22. [210403 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210403%20Thoughts%20on%20recent%20papers.md)\n  23. [210412 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210412%20Thoughts%20on%20recent%20papers.md)\n  24. [210424 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210424%20Thoughts%20on%20recent%20papers.md)\n  25. [210429 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210429%20Thoughts%20on%20recent%20papers.md)\n  26. [210430 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01 1](/rosinality/ml-papers/blob/main/papers/reviews/210430%20Thoughts%20on%20recent%20papers%201.md)\n  27. [210430 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210430%20Thoughts%20on%20recent%20papers%202.md)\n  28. [210505 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210505%20Thoughts%20on%20recent%20papers.md)\n  29. [210508 \ucd5c\uadfc \ub17c\ubb38\ub4e4\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/reviews/210508%20Thoughts%20on%20recent%20papers.md)\n  30. [230222 LLM \ud544\uc694 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ub9ac\ubdf0](/rosinality/ml-papers/blob/main/papers/reviews/llm-dataset.md)\n\n## Table of contents\n\n  1. 3d generative model\n  2. activation\n  3. active learning\n  4. adaptation\n  5. adapter\n  6. adversarial training\n  7. alignment\n  8. antialiasing\n  9. asr\n  10. attention\n  11. audio generation\n  12. audio source separation\n  13. augmentation\n  14. autoregressive model\n  15. backbone\n  16. bayesian\n  17. benchmark\n  18. bert\n  19. bias\n  20. calibration\n  21. causality\n  22. channel attention\n  23. chat\n  24. classificiation\n  25. clip\n  26. computation\n  27. continual learning\n  28. contrastive learning\n  29. convolution\n  30. dataset\n  31.", "start_char_idx": 7648, "end_char_idx": 10017, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2c8118d5-8ee6-459a-8d47-d0adeb7c88ea": {"__data__": {"id_": "2c8118d5-8ee6-459a-8d47-d0adeb7c88ea", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2ac50580-600c-4f0e-930b-e591e9190573", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "049fc913a0173ce3753a2c33055b84bc249f14f65016ad4f073e52327a96c06b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e4132a9e-01fc-4b83-a576-900a601a81dc", "node_type": "1", "metadata": {}, "hash": "436e9d624ba3c72c7dc6f6cf5c0a1edc3ce58b932ad6e38069473e9430af2562", "class_name": "RelatedNodeInfo"}}, "text": "activation\n  3. active learning\n  4. adaptation\n  5. adapter\n  6. adversarial training\n  7. alignment\n  8. antialiasing\n  9. asr\n  10. attention\n  11. audio generation\n  12. audio source separation\n  13. augmentation\n  14. autoregressive model\n  15. backbone\n  16. bayesian\n  17. benchmark\n  18. bert\n  19. bias\n  20. calibration\n  21. causality\n  22. channel attention\n  23. chat\n  24. classificiation\n  25. clip\n  26. computation\n  27. continual learning\n  28. contrastive learning\n  29. convolution\n  30. dataset\n  31. ddpm\n  32. decoding\n  33. deep prior\n  34. detr\n  35. dewarping\n  36. dialog\n  37. differentiable operator\n  38. differentiable tree\n  39. discrete vae\n  40. disentangle\n  41. distillation\n  42. distributed training\n  43. domain adaptation\n  44. dropout\n  45. efficiency\n  46. efficient attention\n  47. efficient training\n  48. embedding\n  49. end2end\n  50. energy based model\n  51. ensemble\n  52. federated learning\n  53. few shot\n  54. finetuning\n  55. flow\n  56. fpn\n  57. gan\n  58. gan inversion\n  59. generalization\n  60. generative model\n  61. graph\n  62. hallucination\n  63. hypernetwork\n  64. hyperparameter\n  65. identifiability\n  66. image editing\n  67. image generation\n  68. img2img\n  69. implicit model\n  70. implicit representation\n  71. in context learning\n  72. instance segmentation\n  73. instruct\n  74. interpolation\n  75. knowledge base\n  76. language generation\n  77. language model\n  78. layout\n  79. lightweight\n  80. line\n  81. linear attention\n  82. llm\n  83. lm\n  84. local attention\n  85. loss\n  86. loss surface\n  87. matting\n  88. memory\n  89. meta learning\n  90. metric\n  91. metric learning\n  92. mixture of experts\n  93. mixup\n  94. mlm\n  95. mlops\n  96. moe\n  97. multilingual\n  98. multimodal\n  99. multimodal generation\n  100. multitask\n  101. nas\n  102. nerf\n  103. neural computer\n  104. neural ode\n  105. neural rendering\n  106. nlp\n  107. nmt\n  108. non autoregressive\n  109. norm free\n  110. normalization\n  111. object detection\n  112. ocr\n  113. open set recognition\n  114. optimization\n  115. optimizer\n  116. oriented object detection\n  117. out of distribution\n  118. panoptic segmentation\n  119. perceptual loss\n  120. point cloud\n  121. pooling\n  122. pose\n  123. positional encoding\n  124. practice\n  125. pretraining\n  126. probabilistic model\n  127. prompt\n  128. pruning\n  129. qa\n  130. quantization\n  131. reasoning\n  132. recommender\n  133. regularization\n  134. reinforcement learning\n  135. rendering\n  136. representation\n  137. resampling\n  138. restoration\n  139. retrieval\n  140. review\n  141. rl\n  142. robustness\n  143. saliency\n  144. salient object detection\n  145. scale\n  146. score\n  147. self supervised\n  148.", "start_char_idx": 9496, "end_char_idx": 12195, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e4132a9e-01fc-4b83-a576-900a601a81dc": {"__data__": {"id_": "e4132a9e-01fc-4b83-a576-900a601a81dc", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c8118d5-8ee6-459a-8d47-d0adeb7c88ea", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "edde167762c4f2e3ec16466516227701e137b7e516cd9674a8f280d81836cad9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "63e78434-4316-43fc-98b4-bb5a102b5a82", "node_type": "1", "metadata": {}, "hash": "28764f0cad1f33e719523d87e3012509f9ae930965729c800e72f259ce5e793e", "class_name": "RelatedNodeInfo"}}, "text": "panoptic segmentation\n  119. perceptual loss\n  120. point cloud\n  121. pooling\n  122. pose\n  123. positional encoding\n  124. practice\n  125. pretraining\n  126. probabilistic model\n  127. prompt\n  128. pruning\n  129. qa\n  130. quantization\n  131. reasoning\n  132. recommender\n  133. regularization\n  134. reinforcement learning\n  135. rendering\n  136. representation\n  137. resampling\n  138. restoration\n  139. retrieval\n  140. review\n  141. rl\n  142. robustness\n  143. saliency\n  144. salient object detection\n  145. scale\n  146. score\n  147. self supervised\n  148. self supervised discovery\n  149. semantic factor\n  150. semantic segmentation\n  151. semi supervised learning\n  152. seq2seq\n  153. sgld\n  154. singing voice synthesis\n  155. single image\n  156. speech\n  157. state space model\n  158. structure learning\n  159. style transfer\n  160. stylegan\n  161. super resolution\n  162. table\n  163. text generation\n  164. text2img\n  165. tokenizer\n  166. topic model\n  167. topology\n  168. tracking\n  169. training\n  170. transducer\n  171. transfer\n  172. transformer\n  173. tropical geometry\n  174. tts\n  175. uncertainty\n  176. unsupervised img2img\n  177. unsupervised nmt\n  178. vae\n  179. video\n  180. video transformer\n  181. vision\n  182. vision language\n  183. vision transformer\n  184. visual grounding\n  185. vit\n  186. vocoder\n  187. vq\n  188. vqa\n  189. weak supervision\n  190. yolo\n  191. uncategorized\n\n## 3d generative model\n\n  1. [211220 3D-aware Image Synthesis via Learning Structural and Textural Representations](/rosinality/ml-papers/blob/main/papers/2021/211220%203D-aware%20Image%20Synthesis%20via%20Learning%20Structural%20and%20Textural%20Representations.md)\n  2. [220615 GRAM-HD](/rosinality/ml-papers/blob/main/papers/2022/220615%20GRAM-HD.md)\n  3. [220621 EpiGRAF](/rosinality/ml-papers/blob/main/papers/2022/220621%20EpiGRAF.md)\n  4. [221126 AvatarGen](/rosinality/ml-papers/blob/main/papers/2022/221126%20AvatarGen.md)\n  5. [230209 In-N-Out](/rosinality/ml-papers/blob/main/papers/2023/230209%20In-N-Out.md) #gan_inversion\n  6. [230216 3D-aware Conditional Image Synthesis](/rosinality/ml-papers/blob/main/papers/2023/230216%203D-aware%20Conditional%20Image%20Synthesis.md)\n  7. [230302 3D generation on ImageNet](/rosinality/ml-papers/blob/main/papers/2023/230302%203D%20generation%20on%20ImageNet.md)\n  8. [230627 Free-style and Fast 3D Portrait Synthesis](/rosinality/ml-papers/blob/main/papers/2023/230627%20Free-style%20and%20Fast%203D%20Portrait%20Synthesis.md)\n  9. [230630 Magic123](/rosinality/ml-papers/blob/main/papers/2023/230630%20Magic123.md)\n\n## activation\n\n  1. [201019 Smooth activations and reproducibility in deep networks](/rosinality/ml-papers/blob/main/papers/2020/201019%20Smooth%20activations%20and%20reproducibility%20in%20deep%20networks.md) #stability\n\n## active learning\n\n  1.", "start_char_idx": 11630, "end_char_idx": 14465, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "63e78434-4316-43fc-98b4-bb5a102b5a82": {"__data__": {"id_": "63e78434-4316-43fc-98b4-bb5a102b5a82", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e4132a9e-01fc-4b83-a576-900a601a81dc", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "59ce563b1a39e341042884da956f63670fba88ad1fceba4af9e0ddce2e4bd43e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f6221846-2f0b-4d27-b2f5-d4764f14f363", "node_type": "1", "metadata": {}, "hash": "833d54127c30ade2049a2f256d73ba99350eb2ba9b863876ac585019d5367d24", "class_name": "RelatedNodeInfo"}}, "text": "[230627 Free-style and Fast 3D Portrait Synthesis](/rosinality/ml-papers/blob/main/papers/2023/230627%20Free-style%20and%20Fast%203D%20Portrait%20Synthesis.md)\n  9. [230630 Magic123](/rosinality/ml-papers/blob/main/papers/2023/230630%20Magic123.md)\n\n## activation\n\n  1. [201019 Smooth activations and reproducibility in deep networks](/rosinality/ml-papers/blob/main/papers/2020/201019%20Smooth%20activations%20and%20reproducibility%20in%20deep%20networks.md) #stability\n\n## active learning\n\n  1. [200630 Similarity Search for Efficient Active Learning and Search of Rare](/rosinality/ml-papers/blob/main/papers/2020/200630%20Similarity%20Search%20for%20Efficient%20Active%20Learning%20and%20Search%20of%20Rare.md)\n  2. [210729 Batch Active Learning at Scale](/rosinality/ml-papers/blob/main/papers/2021/210729%20Batch%20Active%20Learning%20at%20Scale.md)\n\n## adaptation\n\n  1. [200129 Side-Tuning](/rosinality/ml-papers/blob/main/papers/2020/200129%20Side-Tuning.md)\n  2. [200130 Once for All](/rosinality/ml-papers/blob/main/papers/2020/200130%20Once%20for%20All.md) #deploy\n\n## adapter\n\n  1. [210608 Compacter](/rosinality/ml-papers/blob/main/papers/2021/210608%20Compacter.md)\n  2. [220524 AdaMix](/rosinality/ml-papers/blob/main/papers/2022/220524%20AdaMix.md) #moe\n\n## adversarial training\n\n  1. [200130 Adversarial Examples Improve Image Recognition](/rosinality/ml-papers/blob/main/papers/2020/200130%20Adversarial%20Examples%20Improve%20Image%20Recognition.md)\n  2. [200625 Smooth Adversarial Training](/rosinality/ml-papers/blob/main/papers/2020/200625%20Smooth%20Adversarial%20Training.md)\n\n## alignment\n\n  1. [230504 Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision](/rosinality/ml-papers/blob/main/papers/2023/230504%20Principle-Driven%20Self-Alignment%20of%20Language%20Models%20from%20Scratch%20with%20Minimal%20Human%20Supervision.md)\n  2. [230517 LeTI](/rosinality/ml-papers/blob/main/papers/2023/230517%20LeTI.md) #prompt\n  3. [230517 SLiC-HF](/rosinality/ml-papers/blob/main/papers/2023/230517%20SLiC-HF.md)\n  4. [230518 LIMA](/rosinality/ml-papers/blob/main/papers/2023/230518%20LIMA.md)\n  5. [230526 Training Socially Aligned Language Models in Simulated Human Society](/rosinality/ml-papers/blob/main/papers/2023/230526%20Training%20Socially%20Aligned%20Language%20Models%20in%20Simulated%20Human%20Society.md)\n  6. [230529 Direct Preference Optimization](/rosinality/ml-papers/blob/main/papers/2023/230529%20Direct%20Preference%20Optimization.md)\n  7. [230607 How Far Can Camels Go](/rosinality/ml-papers/blob/main/papers/2023/230607%20How%20Far%20Can%20Camels%20Go.md)\n  8. [230625 Is RLHF More Difficult than Standard RL](/rosinality/ml-papers/blob/main/papers/2023/230625%20Is%20RLHF%20More%20Difficult%20than%20Standard%20RL.md) #rl\n  9.", "start_char_idx": 13969, "end_char_idx": 16778, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f6221846-2f0b-4d27-b2f5-d4764f14f363": {"__data__": {"id_": "f6221846-2f0b-4d27-b2f5-d4764f14f363", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "63e78434-4316-43fc-98b4-bb5a102b5a82", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ece52e8c6d99749c09809342916d234324ca6644080fc7eab80c9816b2da3e15", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f50b83d7-83c4-4364-b9fb-c2c54c13a5d0", "node_type": "1", "metadata": {}, "hash": "c87067fb46885a37c2aeb8b39b5ef8d1e15713e85f0438406ca3ffdffd5de420", "class_name": "RelatedNodeInfo"}}, "text": "[230529 Direct Preference Optimization](/rosinality/ml-papers/blob/main/papers/2023/230529%20Direct%20Preference%20Optimization.md)\n  7. [230607 How Far Can Camels Go](/rosinality/ml-papers/blob/main/papers/2023/230607%20How%20Far%20Can%20Camels%20Go.md)\n  8. [230625 Is RLHF More Difficult than Standard RL](/rosinality/ml-papers/blob/main/papers/2023/230625%20Is%20RLHF%20More%20Difficult%20than%20Standard%20RL.md) #rl\n  9. [230628 Towards Measuring the Representation of Subjective Global Opinions in Language Models](/rosinality/ml-papers/blob/main/papers/2023/230628%20Towards%20Measuring%20the%20Representation%20of%20Subjective%20Global%20Opinions%20in%20Language%20Models.md)\n  10. [230630 Preference Ranking Optimization for Human Alignment](/rosinality/ml-papers/blob/main/papers/2023/230630%20Preference%20Ranking%20Optimization%20for%20Human%20Alignment.md)\n  11. [230705 Jailbroken](/rosinality/ml-papers/blob/main/papers/2023/230705%20Jailbroken.md)\n  12. [230711 Secrets of RLHF in Large Language Models Part I](/rosinality/ml-papers/blob/main/papers/2023/230711%20Secrets%20of%20RLHF%20in%20Large%20Language%20Models%20Part%20I.md) #reinforcement_learning\n  13. [230717 AlpaGasus](/rosinality/ml-papers/blob/main/papers/2023/230717%20AlpaGasus.md)\n  14. [230720 FLASK](/rosinality/ml-papers/blob/main/papers/2023/230720%20FLASK.md) #benchmark\n  15. [230727 Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback](/rosinality/ml-papers/blob/main/papers/2023/230727%20Open%20Problems%20and%20Fundamental%20Limitations%20of%20Reinforcement%20Learning%20from%20Human%20Feedback.md)\n  16. [230727 PanGu-Coder2](/rosinality/ml-papers/blob/main/papers/2023/230727%20PanGu-Coder2.md)\n  17. [230731 ToolLLM](/rosinality/ml-papers/blob/main/papers/2023/230731%20ToolLLM.md)\n  18. [230801 Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230801%20Tool%20Documentation%20Enables%20Zero-Shot%20Tool-Usage%20with%20Large%20Language%20Models.md)\n  19. [230807 TPTU](/rosinality/ml-papers/blob/main/papers/2023/230807%20TPTU.md)\n  20. [230808 Shepherd](/rosinality/ml-papers/blob/main/papers/2023/230808%20Shepherd.md)\n\n## antialiasing\n\n  1. [201120 An Effective Anti-Aliasing Approach for Residual Networks](/rosinality/ml-papers/blob/main/papers/2020/201120%20An%20Effective%20Anti-Aliasing%20Approach%20for%20Residual%20Networks.md)\n  2. [201128 Truly shift-invariant convolutional neural networks](/rosinality/ml-papers/blob/main/papers/2020/201128%20Truly%20shift-invariant%20convolutional%20neural%20networks.md)\n\n## asr\n\n  1. [200220 Imputer](/rosinality/ml-papers/blob/main/papers/2020/200220%20Imputer.md) #non-autoregressive #ctc\n  2.", "start_char_idx": 16352, "end_char_idx": 19101, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f50b83d7-83c4-4364-b9fb-c2c54c13a5d0": {"__data__": {"id_": "f50b83d7-83c4-4364-b9fb-c2c54c13a5d0", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f6221846-2f0b-4d27-b2f5-d4764f14f363", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "721e262400a7828f1ebdb767a50d089f95e2a5dea92f388046e42ddeee5eaa37", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "29a3955f-1eec-4f21-b111-4a930a04fc57", "node_type": "1", "metadata": {}, "hash": "2c933583db559b05fe456b7f23255d962802ced9b65707eb9d1e5f1e057daea2", "class_name": "RelatedNodeInfo"}}, "text": "[201120 An Effective Anti-Aliasing Approach for Residual Networks](/rosinality/ml-papers/blob/main/papers/2020/201120%20An%20Effective%20Anti-Aliasing%20Approach%20for%20Residual%20Networks.md)\n  2. [201128 Truly shift-invariant convolutional neural networks](/rosinality/ml-papers/blob/main/papers/2020/201128%20Truly%20shift-invariant%20convolutional%20neural%20networks.md)\n\n## asr\n\n  1. [200220 Imputer](/rosinality/ml-papers/blob/main/papers/2020/200220%20Imputer.md) #non-autoregressive #ctc\n  2. [200506 RNN-T Models Fail to Generalize to Out-of-Domain Audio](/rosinality/ml-papers/blob/main/papers/2020/200506%20RNN-T%20Models%20Fail%20to%20Generalize%20to%20Out-of-Domain%20Audio.md) #transducer #out_of_distribution #domain #regularization\n  3. [200510 Listen Attentively, and Spell Once](/rosinality/ml-papers/blob/main/papers/2020/200510%20Listen%20Attentively%2C%20and%20Spell%20Once.md) #non-autoregressive\n  4. [200516 Large scale weakly and semi-supervised learning for low-resource video ASR](/rosinality/ml-papers/blob/main/papers/2020/200516%20Large%20scale%20weakly%20and%20semi-supervised%20learning%20for%20low-resource%20video%20ASR.md) #weak_supervision #semi_supervised_learning\n  5. [200516 Reducing Spelling Inconsistencies in Code-Switching ASR using](/rosinality/ml-papers/blob/main/papers/2020/200516%20Reducing%20Spelling%20Inconsistencies%20in%20Code-Switching%20ASR%20using.md) #ctc\n  6. [200516 Spike-Triggered Non-Autoregressive Transformer for End-to-End Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/200516%20Spike-Triggered%20Non-Autoregressive%20Transformer%20for%20End-to-End%20Speech%20Recognition.md) #non-autoregressive\n  7. [200518 Attention-based Transducer for Online Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/200518%20Attention-based%20Transducer%20for%20Online%20Speech%20Recognition.md) #transducer\n  8. [200518 Iterative Pseudo-Labeling for Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/200518%20Iterative%20Pseudo-Labeling%20for%20Speech%20Recognition.md)\n  9. [200519 Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention End-to-End Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/200519%20Distilling%20Knowledge%20from%20Ensembles%20of%20Acoustic%20Models%20for%20Joint%20CTC-Attention%20End-to-End%20Speech%20Recognition.md) #ctc\n  10. [200519 Improved Noisy Student Training for Automatic Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/200519%20Improved%20Noisy%20Student%20Training%20for%20Automatic%20Speech%20Recognition.md) #semi_supervised_learning\n  11. [200729 Developing RNN-T Models Surpassing High-Performance Hybrid Models with](/rosinality/ml-papers/blob/main/papers/2020/200729%20Developing%20RNN-T%20Models%20Surpassing%20High-Performance%20Hybrid%20Models%20with.md) #rnn_t\n  12. [201021 FastEmit](/rosinality/ml-papers/blob/main/papers/2020/201021%20FastEmit.md) #transducer #decoding\n  13.", "start_char_idx": 18599, "end_char_idx": 21576, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "29a3955f-1eec-4f21-b111-4a930a04fc57": {"__data__": {"id_": "29a3955f-1eec-4f21-b111-4a930a04fc57", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f50b83d7-83c4-4364-b9fb-c2c54c13a5d0", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "be08c546ea2936891d942ce108a583e1091a4f010192e6ffbaa8169903a6aff0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "69e42855-2b5b-4a27-ae9a-c7a7a9b6a80e", "node_type": "1", "metadata": {}, "hash": "5c202e6349157bcd5e8d1c25409844e812496847fe59e26902139e68c2c3f1dc", "class_name": "RelatedNodeInfo"}}, "text": "[200519 Improved Noisy Student Training for Automatic Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/200519%20Improved%20Noisy%20Student%20Training%20for%20Automatic%20Speech%20Recognition.md) #semi_supervised_learning\n  11. [200729 Developing RNN-T Models Surpassing High-Performance Hybrid Models with](/rosinality/ml-papers/blob/main/papers/2020/200729%20Developing%20RNN-T%20Models%20Surpassing%20High-Performance%20Hybrid%20Models%20with.md) #rnn_t\n  12. [201021 FastEmit](/rosinality/ml-papers/blob/main/papers/2020/201021%20FastEmit.md) #transducer #decoding\n  13. [201027 CASS-NAT](/rosinality/ml-papers/blob/main/papers/2020/201027%20CASS-NAT.md) #non-autoregressive\n  14. [201125 Streaming end-to-end multi-talker speech recognition](/rosinality/ml-papers/blob/main/papers/2020/201125%20Streaming%20end-to-end%20multi-talker%20speech%20recognition.md) #transducer\n  15. [210524 Unsupervised Speech Recognition](/rosinality/ml-papers/blob/main/papers/2021/210524%20Unsupervised%20Speech%20Recognition.md) #unsupervised_training\n  16. [210608 SpeechBrain](/rosinality/ml-papers/blob/main/papers/2021/210608%20SpeechBrain.md)\n  17. [211012 Word Order Does Not Matter For Speech Recognition](/rosinality/ml-papers/blob/main/papers/2021/211012%20Word%20Order%20Does%20Not%20Matter%20For%20Speech%20Recognition.md) #weak_supervision\n  18. [211030 Pseudo-Labeling for Massively Multilingual Speech Recognition](/rosinality/ml-papers/blob/main/papers/2021/211030%20Pseudo-Labeling%20for%20Massively%20Multilingual%20Speech%20Recognition.md) #semi_supervised_learning #multilingual\n  19. [211210 Building a great multi-lingual teacher with sparsely-gated mixture of experts for speech recognition](/rosinality/ml-papers/blob/main/papers/2021/211210%20Building%20a%20great%20multi-lingual%20teacher%20with%20sparsely-gated%20mixture%20of%20experts%20for%20speech%20recognition.md) #moe\n  20. [220829 A Language Agnostic Multilingual Streaming On-Device ASR System](/rosinality/ml-papers/blob/main/papers/2022/220829%20A%20Language%20Agnostic%20Multilingual%20Streaming%20On-Device%20ASR%20System.md) #multilingual\n  21. [220922 Whisper](/rosinality/ml-papers/blob/main/papers/2022/220922%20Whisper.md)\n  22. [230302 Google USM](/rosinality/ml-papers/blob/main/papers/2023/230302%20Google%20USM.md) #multilingual\n\n## attention\n\n  1. [200122 Object Contextual Representations](/rosinality/ml-papers/blob/main/papers/2020/200122%20Object%20Contextual%20Representations.md) #semantic_segmentation\n  2. [200129 Empirical Attention](/rosinality/ml-papers/blob/main/papers/2020/200129%20Empirical%20Attention.md)\n  3. [200130 Axial Attention](/rosinality/ml-papers/blob/main/papers/2020/200130%20Axial%20Attention.md) #generative_model\n  4. [200130 Criss-Cross Attention](/rosinality/ml-papers/blob/main/papers/2020/200130%20Criss-Cross%20Attention.md) #semantic_segmentation\n  5. [200212 Capsules with Inverted Dot-Product Attention Routing](/rosinality/ml-papers/blob/main/papers/2020/200212%20Capsules%20with%20Inverted%20Dot-Product%20Attention%20Routing.md) #capsule\n  6.", "start_char_idx": 20988, "end_char_idx": 24074, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "69e42855-2b5b-4a27-ae9a-c7a7a9b6a80e": {"__data__": {"id_": "69e42855-2b5b-4a27-ae9a-c7a7a9b6a80e", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "29a3955f-1eec-4f21-b111-4a930a04fc57", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "a045e90f30cdbf03120bc308d4f41ced98c617f90eb8d2d040a3eb8bd64c7185", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "09e07a31-cbf9-4575-871f-82c65c439d4d", "node_type": "1", "metadata": {}, "hash": "5deda563b347cdcaa2a433b5fed0750c6aee008305d65dad15ba05b230491400", "class_name": "RelatedNodeInfo"}}, "text": "[200129 Empirical Attention](/rosinality/ml-papers/blob/main/papers/2020/200129%20Empirical%20Attention.md)\n  3. [200130 Axial Attention](/rosinality/ml-papers/blob/main/papers/2020/200130%20Axial%20Attention.md) #generative_model\n  4. [200130 Criss-Cross Attention](/rosinality/ml-papers/blob/main/papers/2020/200130%20Criss-Cross%20Attention.md) #semantic_segmentation\n  5. [200212 Capsules with Inverted Dot-Product Attention Routing](/rosinality/ml-papers/blob/main/papers/2020/200212%20Capsules%20with%20Inverted%20Dot-Product%20Attention%20Routing.md) #capsule\n  6. [200219 Tree-structured Attention with Hierarchical Accumulation](/rosinality/ml-papers/blob/main/papers/2020/200219%20Tree-structured%20Attention%20with%20Hierarchical%20Accumulation.md) #parse\n  7. [200226 Sparse Sinkhorn Attention](/rosinality/ml-papers/blob/main/papers/2020/200226%20Sparse%20Sinkhorn%20Attention.md) #sparse_attention\n  8. [200317 Axial-DeepLab](/rosinality/ml-papers/blob/main/papers/2020/200317%20Axial-DeepLab.md) #panoptic_segmentation\n  9. [200404 Neural Architecture Search for Lightweight Non-Local Networks](/rosinality/ml-papers/blob/main/papers/2020/200404%20Neural%20Architecture%20Search%20for%20Lightweight%20Non-Local%20Networks.md)\n  10. [200421 Attention is Not Only a Weight](/rosinality/ml-papers/blob/main/papers/2020/200421%20Attention%20is%20Not%20Only%20a%20Weight.md) #bert\n  11. [200423 Self-Attention Attribution](/rosinality/ml-papers/blob/main/papers/2020/200423%20Self-Attention%20Attribution.md) #bert\n  12. [200428 Exploring Self-attention for Image Recognition](/rosinality/ml-papers/blob/main/papers/2020/200428%20Exploring%20Self-attention%20for%20Image%20Recognition.md)\n  13. [200510 CTC-synchronous Training for Monotonic Attention Model](/rosinality/ml-papers/blob/main/papers/2020/200510%20CTC-synchronous%20Training%20for%20Monotonic%20Attention%20Model.md) #asr #ctc\n  14. [200516 Streaming Transformer-based Acoustic Models Using Self-attention with Augmented Memory](/rosinality/ml-papers/blob/main/papers/2020/200516%20Streaming%20Transformer-based%20Acoustic%20Models%20Using%20Self-attention%20with%20Augmented%20Memory.md) #asr #memory\n  15. [200519 Normalized Attention Without Probability Cage](/rosinality/ml-papers/blob/main/papers/2020/200519%20Normalized%20Attention%20Without%20Probability%20Cage.md)\n  16. [200519 Staying True to Your Word](/rosinality/ml-papers/blob/main/papers/2020/200519%20Staying%20True%20to%20Your%20Word.md)\n  17. [200626 Object-Centric Learning with Slot Attention](/rosinality/ml-papers/blob/main/papers/2020/200626%20Object-Centric%20Learning%20with%20Slot%20Attention.md)\n  18. [201119 On the Dynamics of Training Attention Models](/rosinality/ml-papers/blob/main/papers/2020/201119%20On%20the%20Dynamics%20of%20Training%20Attention%20Models.md) #training\n  19. [210223 Linear Transformers Are Secretly Fast Weight Memory Systems](/rosinality/ml-papers/blob/main/papers/2021/210223%20Linear%20Transformers%20Are%20Secretly%20Fast%20Weight%20Memory%20Systems.md) #linear_attention #efficient_attention\n  20.", "start_char_idx": 23503, "end_char_idx": 26585, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "09e07a31-cbf9-4575-871f-82c65c439d4d": {"__data__": {"id_": "09e07a31-cbf9-4575-871f-82c65c439d4d", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "69e42855-2b5b-4a27-ae9a-c7a7a9b6a80e", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "21c802016c667d46960e8514164d5cb3e2d1d08e7b5c23407b0751324a66b047", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7cc687bb-5bbf-4d3a-884a-b6d51734215d", "node_type": "1", "metadata": {}, "hash": "fa83faf1a0cf39a03f21e67c00dc3dfb17107d93dac04894fbc11055d05a7e31", "class_name": "RelatedNodeInfo"}}, "text": "[200626 Object-Centric Learning with Slot Attention](/rosinality/ml-papers/blob/main/papers/2020/200626%20Object-Centric%20Learning%20with%20Slot%20Attention.md)\n  18. [201119 On the Dynamics of Training Attention Models](/rosinality/ml-papers/blob/main/papers/2020/201119%20On%20the%20Dynamics%20of%20Training%20Attention%20Models.md) #training\n  19. [210223 Linear Transformers Are Secretly Fast Weight Memory Systems](/rosinality/ml-papers/blob/main/papers/2021/210223%20Linear%20Transformers%20Are%20Secretly%20Fast%20Weight%20Memory%20Systems.md) #linear_attention #efficient_attention\n  20. [210225 LazyFormer](/rosinality/ml-papers/blob/main/papers/2021/210225%20LazyFormer.md) #bert\n  21. [210517 Pay Attention to MLPs](/rosinality/ml-papers/blob/main/papers/2021/210517%20Pay%20Attention%20to%20MLPs.md) #mlp\n  22. [210524 Self-Attention Networks Can Process Bounded Hierarchical Languages](/rosinality/ml-papers/blob/main/papers/2021/210524%20Self-Attention%20Networks%20Can%20Process%20Bounded%20Hierarchical%20Languages.md) #nlp\n  23. [210826 Train Short, Test Long](/rosinality/ml-papers/blob/main/papers/2021/210826%20Train%20Short%2C%20Test%20Long.md) #positional_encoding\n\n## audio generation\n\n  1. [220220 It's Raw! Audio Generation with State-Space Models](/rosinality/ml-papers/blob/main/papers/2022/220220%20It%27s%20Raw%21%20Audio%20Generation%20with%20State-Space%20Models.md)\n  2. [230126 MusicLM](/rosinality/ml-papers/blob/main/papers/2023/230126%20MusicLM.md)\n  3. [230208 Noise2Music](/rosinality/ml-papers/blob/main/papers/2023/230208%20Noise2Music.md)\n\n## audio source separation\n\n  1. [211019 The Cocktail Fork Problem](/rosinality/ml-papers/blob/main/papers/2021/211019%20The%20Cocktail%20Fork%20Problem.md)\n\n## augmentation\n\n  1. [200122 FixMatch](/rosinality/ml-papers/blob/main/papers/2020/200122%20FixMatch.md) #semi_supervised_learning #manifold #mixup\n  2. [200220 Affinity and Diversity](/rosinality/ml-papers/blob/main/papers/2020/200220%20Affinity%20and%20Diversity.md)\n  3. [200621 AdvAug](/rosinality/ml-papers/blob/main/papers/2020/200621%20AdvAug.md) #mixup #nlp #adversarial_training\n  4. [200710 Meta-Learning Requires Meta-Augmentation](/rosinality/ml-papers/blob/main/papers/2020/200710%20Meta-Learning%20Requires%20Meta-Augmentation.md) #metalearning\n  5. [201117 Sequence-Level Mixed Sample Data Augmentation](/rosinality/ml-papers/blob/main/papers/2020/201117%20Sequence-Level%20Mixed%20Sample%20Data%20Augmentation.md) #nlp\n  6. [201213 Simple Copy-Paste is a Strong Data Augmentation Method for Instance](/rosinality/ml-papers/blob/main/papers/2020/201213%20Simple%20Copy-Paste%20is%20a%20Strong%20Data%20Augmentation%20Method%20for%20Instance.md) #instance_segmentation\n  7. [201214 Improving Panoptic Segmentation at All Scales](/rosinality/ml-papers/blob/main/papers/2020/201214%20Improving%20Panoptic%20Segmentation%20at%20All%20Scales.md) #panoptic_segmentation\n  8. [210318 AlignMix](/rosinality/ml-papers/blob/main/papers/2021/210318%20AlignMix.md) #mixup\n  9.", "start_char_idx": 25989, "end_char_idx": 29009, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7cc687bb-5bbf-4d3a-884a-b6d51734215d": {"__data__": {"id_": "7cc687bb-5bbf-4d3a-884a-b6d51734215d", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09e07a31-cbf9-4575-871f-82c65c439d4d", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "14f0ac8e5bd81afb8ff3981135997b8aba3a09a4ae79d5552e07d715d5bc83eb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1796d83a-5be7-42b6-87ec-24399b21afa3", "node_type": "1", "metadata": {}, "hash": "5328b3e7cfcacc4091397382ed1dabc8755e6351f4b4e4a59f6954fc19f62364", "class_name": "RelatedNodeInfo"}}, "text": "[201213 Simple Copy-Paste is a Strong Data Augmentation Method for Instance](/rosinality/ml-papers/blob/main/papers/2020/201213%20Simple%20Copy-Paste%20is%20a%20Strong%20Data%20Augmentation%20Method%20for%20Instance.md) #instance_segmentation\n  7. [201214 Improving Panoptic Segmentation at All Scales](/rosinality/ml-papers/blob/main/papers/2020/201214%20Improving%20Panoptic%20Segmentation%20at%20All%20Scales.md) #panoptic_segmentation\n  8. [210318 AlignMix](/rosinality/ml-papers/blob/main/papers/2021/210318%20AlignMix.md) #mixup\n  9. [210318 TrivialAugment](/rosinality/ml-papers/blob/main/papers/2021/210318%20TrivialAugment.md)\n  10. [210429 Ensembling with Deep Generative Views](/rosinality/ml-papers/blob/main/papers/2021/210429%20Ensembling%20with%20Deep%20Generative%20Views.md) #ensemble #gan_inversion\n  11. [220830 Augraphy](/rosinality/ml-papers/blob/main/papers/2022/220830%20Augraphy.md)\n\n## autoregressive model\n\n  1. [200129 Semi Autorgressive Training](/rosinality/ml-papers/blob/main/papers/2020/200129%20Semi%20Autorgressive%20Training.md)\n  2. [201027 Scaling Laws for Autoregressive Generative Modeling](/rosinality/ml-papers/blob/main/papers/2020/201027%20Scaling%20Laws%20for%20Autoregressive%20Generative%20Modeling.md) #scale\n  3. [211216 Characterizing and addressing the issue of oversmoothing in neural autoregressive sequence modeling](/rosinality/ml-papers/blob/main/papers/2021/211216%20Characterizing%20and%20addressing%20the%20issue%20of%20oversmoothing%20in%20neural%20autoregressive%20sequence%20modeling.md)\n  4. [220622 Scaling Autoregressive Models for Content-Rich Text-to-Image Generation](/rosinality/ml-papers/blob/main/papers/2022/220622%20Scaling%20Autoregressive%20Models%20for%20Content-Rich%20Text-to-Image%20Generation.md) #image_generation\n  5. [230202 Accelerating Large Language Model Decoding with Speculative Sampling](/rosinality/ml-papers/blob/main/papers/2023/230202%20Accelerating%20Large%20Language%20Model%20Decoding%20with%20Speculative%20Sampling.md) #decoding\n\n## backbone\n\n  1. [190724 MixNet](/rosinality/ml-papers/blob/main/papers/2019/190724%20MixNet.md) #convolution\n  2. [200123 Antialiasing](/rosinality/ml-papers/blob/main/papers/2020/200123%20Antialiasing.md) #invariance\n  3. [200128 Attentive Normalization](/rosinality/ml-papers/blob/main/papers/2020/200128%20Attentive%20Normalization.md)\n  4. [200128 IBN-Net](/rosinality/ml-papers/blob/main/papers/2020/200128%20IBN-Net.md)\n  5. [200128 Selective Kernel](/rosinality/ml-papers/blob/main/papers/2020/200128%20Selective%20Kernel.md)\n  6. [200128 SpineNet](/rosinality/ml-papers/blob/main/papers/2020/200128%20SpineNet.md)\n  7. [200128 Squeeze-Excitation](/rosinality/ml-papers/blob/main/papers/2020/200128%20Squeeze-Excitation.md)\n  8. [200128 Switchable Normalization](/rosinality/ml-papers/blob/main/papers/2020/200128%20Switchable%20Normalization.md)\n  9. [200128 Switchable Whitening](/rosinality/ml-papers/blob/main/papers/2020/200128%20Switchable%20Whitening.md)\n  10.", "start_char_idx": 28470, "end_char_idx": 31474, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1796d83a-5be7-42b6-87ec-24399b21afa3": {"__data__": {"id_": "1796d83a-5be7-42b6-87ec-24399b21afa3", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7cc687bb-5bbf-4d3a-884a-b6d51734215d", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "abec2387ae2bcc4c633e26eafaf69a562adb4da867e71e159ddde335cdaef783", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b4f63ef-c861-4800-9b23-19aa1867c6fc", "node_type": "1", "metadata": {}, "hash": "09b94f00ffd6bdd980f086948b6a22cebdb09055d4b0e6795e84fa2027594724", "class_name": "RelatedNodeInfo"}}, "text": "[200128 Selective Kernel](/rosinality/ml-papers/blob/main/papers/2020/200128%20Selective%20Kernel.md)\n  6. [200128 SpineNet](/rosinality/ml-papers/blob/main/papers/2020/200128%20SpineNet.md)\n  7. [200128 Squeeze-Excitation](/rosinality/ml-papers/blob/main/papers/2020/200128%20Squeeze-Excitation.md)\n  8. [200128 Switchable Normalization](/rosinality/ml-papers/blob/main/papers/2020/200128%20Switchable%20Normalization.md)\n  9. [200128 Switchable Whitening](/rosinality/ml-papers/blob/main/papers/2020/200128%20Switchable%20Whitening.md)\n  10. [200129 Assembled Techniques](/rosinality/ml-papers/blob/main/papers/2020/200129%20Assembled%20Techniques.md) #regularization\n  11. [200129 DenseNet](/rosinality/ml-papers/blob/main/papers/2020/200129%20DenseNet.md)\n  12. [200129 Dual Path Networks](/rosinality/ml-papers/blob/main/papers/2020/200129%20Dual%20Path%20Networks.md)\n  13. [200129 HarDNet](/rosinality/ml-papers/blob/main/papers/2020/200129%20HarDNet.md)\n  14. [200129 PyramidNet](/rosinality/ml-papers/blob/main/papers/2020/200129%20PyramidNet.md)\n  15. [200129 SelecSLS](/rosinality/ml-papers/blob/main/papers/2020/200129%20SelecSLS.md)\n  16. [200129 ShuffleNet V2](/rosinality/ml-papers/blob/main/papers/2020/200129%20ShuffleNet%20V2.md) #efficiency\n  17. [200129 VoVNet](/rosinality/ml-papers/blob/main/papers/2020/200129%20VoVNet.md)\n  18. [200130 FishNet](/rosinality/ml-papers/blob/main/papers/2020/200130%20FishNet.md)\n  19. [200130 HRNet](/rosinality/ml-papers/blob/main/papers/2020/200130%20HRNet.md)\n  20. [200130 MixConv](/rosinality/ml-papers/blob/main/papers/2020/200130%20MixConv.md) #convolution\n  21. [200330 Designing Network Design Spaces](/rosinality/ml-papers/blob/main/papers/2020/200330%20Designing%20Network%20Design%20Spaces.md) #hypernetwork\n  22. [200330 TResNet](/rosinality/ml-papers/blob/main/papers/2020/200330%20TResNet.md) #antialiasing\n  23. [200419 ResNeSt](/rosinality/ml-papers/blob/main/papers/2020/200419%20ResNeSt.md)\n  24. [200630 Deep Isometric Learning for Visual Recognition](/rosinality/ml-papers/blob/main/papers/2020/200630%20Deep%20Isometric%20Learning%20for%20Visual%20Recognition.md) #normalization #resnet #cnn #norm_free\n  25. [200712 PSConv](/rosinality/ml-papers/blob/main/papers/2020/200712%20PSConv.md) #cnn #multiscale\n  26. [201015 HS-ResNet](/rosinality/ml-papers/blob/main/papers/2020/201015%20HS-ResNet.md) #multiscale\n  27. [201221 FcaNet](/rosinality/ml-papers/blob/main/papers/2020/201221%20FcaNet.md) #channel_attention\n  28. [210226 Transformer in Transformer](/rosinality/ml-papers/blob/main/papers/2021/210226%20Transformer%20in%20Transformer.md) #vision_transformer\n  29. [210304 Barlow Twins](/rosinality/ml-papers/blob/main/papers/2021/210304%20Barlow%20Twins.md) #self_supervised #contrastive_learning\n  30.", "start_char_idx": 30931, "end_char_idx": 33717, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b4f63ef-c861-4800-9b23-19aa1867c6fc": {"__data__": {"id_": "1b4f63ef-c861-4800-9b23-19aa1867c6fc", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1796d83a-5be7-42b6-87ec-24399b21afa3", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "0941370ad3e87c0f8191d2916fb50fe2248aef578f0da4c72c2452576a8421dc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "692dd480-b89f-44eb-bd18-a271fc308a31", "node_type": "1", "metadata": {}, "hash": "6e1809614deb0fbffbb5b8487ebd7afea55bc704ab204c9f4035245bbe1017e0", "class_name": "RelatedNodeInfo"}}, "text": "[201015 HS-ResNet](/rosinality/ml-papers/blob/main/papers/2020/201015%20HS-ResNet.md) #multiscale\n  27. [201221 FcaNet](/rosinality/ml-papers/blob/main/papers/2020/201221%20FcaNet.md) #channel_attention\n  28. [210226 Transformer in Transformer](/rosinality/ml-papers/blob/main/papers/2021/210226%20Transformer%20in%20Transformer.md) #vision_transformer\n  29. [210304 Barlow Twins](/rosinality/ml-papers/blob/main/papers/2021/210304%20Barlow%20Twins.md) #self_supervised #contrastive_learning\n  30. [210310 Involution](/rosinality/ml-papers/blob/main/papers/2021/210310%20Involution.md) #convolution #attention\n  31. [210312 Revisiting ResNets](/rosinality/ml-papers/blob/main/papers/2021/210312%20Revisiting%20ResNets.md) #resnet\n  32. [210317 Learning to Resize Images for Computer Vision Tasks](/rosinality/ml-papers/blob/main/papers/2021/210317%20Learning%20to%20Resize%20Images%20for%20Computer%20Vision%20Tasks.md) #resizing\n  33. [210331 EfficientNetV2](/rosinality/ml-papers/blob/main/papers/2021/210331%20EfficientNetV2.md)\n  34. [210408 SI-Score](/rosinality/ml-papers/blob/main/papers/2021/210408%20SI-Score.md) #robustness #vision_transformer\n  35. [210505 RepMLP](/rosinality/ml-papers/blob/main/papers/2021/210505%20RepMLP.md) #mlp\n  36. [210506 Do You Even Need Attention](/rosinality/ml-papers/blob/main/papers/2021/210506%20Do%20You%20Even%20Need%20Attention.md) #mlp\n  37. [210510 ResMLP](/rosinality/ml-papers/blob/main/papers/2021/210510%20ResMLP.md) #mlp\n  38. [210617 Layer Folding](/rosinality/ml-papers/blob/main/papers/2021/210617%20Layer%20Folding.md) #efficiency #pruning\n  39. [210628 Early Convolutions Help Transformers See Better](/rosinality/ml-papers/blob/main/papers/2021/210628%20Early%20Convolutions%20Help%20Transformers%20See%20Better.md) #cnn #vit\n  40. [210718 AS-MLP](/rosinality/ml-papers/blob/main/papers/2021/210718%20AS-MLP.md) #mlp\n  41. [210726 Contextual Transformer Networks for Visual Recognition](/rosinality/ml-papers/blob/main/papers/2021/210726%20Contextual%20Transformer%20Networks%20for%20Visual%20Recognition.md)\n  42. [211014 Non-deep Networks](/rosinality/ml-papers/blob/main/papers/2021/211014%20Non-deep%20Networks.md)\n  43. [211018 HRFormer](/rosinality/ml-papers/blob/main/papers/2021/211018%20HRFormer.md) #vit\n  44. [211227 Augmenting Convolutional networks with attention-based aggregation](/rosinality/ml-papers/blob/main/papers/2021/211227%20Augmenting%20Convolutional%20networks%20with%20attention-based%20aggregation.md) #vit #cnn\n  45. [220110 A ConvNet for the 2020s](/rosinality/ml-papers/blob/main/papers/2022/220110%20A%20ConvNet%20for%20the%202020s.md) #cnn #vit\n  46. [220313 Scaling Up Your Kernels to 31x31](/rosinality/ml-papers/blob/main/papers/2022/220313%20Scaling%20Up%20Your%20Kernels%20to%2031x31.md)\n  47.", "start_char_idx": 33220, "end_char_idx": 36011, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "692dd480-b89f-44eb-bd18-a271fc308a31": {"__data__": {"id_": "692dd480-b89f-44eb-bd18-a271fc308a31", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b4f63ef-c861-4800-9b23-19aa1867c6fc", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "5fc18e31536107f4b45a35b018434f8b426c62d7487baa3eb5c7927e37faafc2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7847cd41-6bf2-496d-b331-006630532bf6", "node_type": "1", "metadata": {}, "hash": "187005284042801cbd7fb96e362f46a8b3cebe3ab1be3c2c750d1ad5891a575e", "class_name": "RelatedNodeInfo"}}, "text": "[211227 Augmenting Convolutional networks with attention-based aggregation](/rosinality/ml-papers/blob/main/papers/2021/211227%20Augmenting%20Convolutional%20networks%20with%20attention-based%20aggregation.md) #vit #cnn\n  45. [220110 A ConvNet for the 2020s](/rosinality/ml-papers/blob/main/papers/2022/220110%20A%20ConvNet%20for%20the%202020s.md) #cnn #vit\n  46. [220313 Scaling Up Your Kernels to 31x31](/rosinality/ml-papers/blob/main/papers/2022/220313%20Scaling%20Up%20Your%20Kernels%20to%2031x31.md)\n  47. [220318 Three things everyone should know about Vision Transformers](/rosinality/ml-papers/blob/main/papers/2022/220318%20Three%20things%20everyone%20should%20know%20about%20Vision%20Transformers.md) #vit\n  48. [220728 HorNet](/rosinality/ml-papers/blob/main/papers/2022/220728%20HorNet.md) #cnn\n  49. [230302 Image as Set of Points](/rosinality/ml-papers/blob/main/papers/2023/230302%20Image%20as%20Set%20of%20Points.md)\n\n## bayesian\n\n  1. [200207 Bayes Posterior](/rosinality/ml-papers/blob/main/papers/2020/200207%20Bayes%20Posterior.md)\n  2. [200210 Liberty or Depth](/rosinality/ml-papers/blob/main/papers/2020/200210%20Liberty%20or%20Depth.md) #mean_field\n  3. [200514 Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors](/rosinality/ml-papers/blob/main/papers/2020/200514%20Efficient%20and%20Scalable%20Bayesian%20Neural%20Nets%20with%20Rank-1%20Factors.md) #ensemble #variational_inference\n\n## benchmark\n\n  1. [230720 SciBench](/rosinality/ml-papers/blob/main/papers/2023/230720%20SciBench.md)\n  2. [230807 AgentBench](/rosinality/ml-papers/blob/main/papers/2023/230807%20AgentBench.md)\n\n## bert\n\n  1. [200305 What the [MASK]](/rosinality/ml-papers/blob/main/papers/2020/200305%20What%20the%20%5BMASK%5D.md)\n  2. [200405 FastBERT](/rosinality/ml-papers/blob/main/papers/2020/200405%20FastBERT.md) #distillation #lightweight\n  3. [200408 DynaBERT](/rosinality/ml-papers/blob/main/papers/2020/200408%20DynaBERT.md) #distillation #pruning\n  4. [200412 XtremeDistil](/rosinality/ml-papers/blob/main/papers/2020/200412%20XtremeDistil.md) #distillation #lightweight\n  5. [200427 DeeBERT](/rosinality/ml-papers/blob/main/papers/2020/200427%20DeeBERT.md) #lightweight\n  6. [200518 Audio ALBERT](/rosinality/ml-papers/blob/main/papers/2020/200518%20Audio%20ALBERT.md) #audio #representation\n  7. [200601 Amnesic Probing](/rosinality/ml-papers/blob/main/papers/2020/200601%20Amnesic%20Probing.md)\n  8. [200608 On the Stability of Fine-tuning BERT](/rosinality/ml-papers/blob/main/papers/2020/200608%20On%20the%20Stability%20of%20Fine-tuning%20BERT.md) #finetuning\n  9. [200610 Revisiting Few-sample BERT Fine-tuning](/rosinality/ml-papers/blob/main/papers/2020/200610%20Revisiting%20Few-sample%20BERT%20Fine-tuning.md) #finetuning\n  10.", "start_char_idx": 35500, "end_char_idx": 38258, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7847cd41-6bf2-496d-b331-006630532bf6": {"__data__": {"id_": "7847cd41-6bf2-496d-b331-006630532bf6", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "692dd480-b89f-44eb-bd18-a271fc308a31", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "4b43cffb19c651203a32e11f03206cc827b225a6e999a9610ccbd8bff7929746", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48e7530b-4abb-43eb-ba42-8ed2c5d3d1f8", "node_type": "1", "metadata": {}, "hash": "eeecbbd28d01317a9caf223421f151e1b76cedae5f315f2a6c698ff3ce8c06b8", "class_name": "RelatedNodeInfo"}}, "text": "[200601 Amnesic Probing](/rosinality/ml-papers/blob/main/papers/2020/200601%20Amnesic%20Probing.md)\n  8. [200608 On the Stability of Fine-tuning BERT](/rosinality/ml-papers/blob/main/papers/2020/200608%20On%20the%20Stability%20of%20Fine-tuning%20BERT.md) #finetuning\n  9. [200610 Revisiting Few-sample BERT Fine-tuning](/rosinality/ml-papers/blob/main/papers/2020/200610%20Revisiting%20Few-sample%20BERT%20Fine-tuning.md) #finetuning\n  10. [210906 An Empirical Study on Few-shot Knowledge Probing for Pretrained Language Models](/rosinality/ml-papers/blob/main/papers/2021/210906%20An%20Empirical%20Study%20on%20Few-shot%20Knowledge%20Probing%20for%20Pretrained%20Language%20Models.md) #few_shot #knowledge_base #prompt\n  11. [210907 Beyond Preserved Accuracy](/rosinality/ml-papers/blob/main/papers/2021/210907%20Beyond%20Preserved%20Accuracy.md) #lightweight #distillation\n\n## bias\n\n  1. [200519 Identifying Statistical Bias in Dataset Replication](/rosinality/ml-papers/blob/main/papers/2020/200519%20Identifying%20Statistical%20Bias%20in%20Dataset%20Replication.md)\n  2. [201202 Learning from others' mistakes](/rosinality/ml-papers/blob/main/papers/2020/201202%20Learning%20from%20others%27%20mistakes.md) #product_of_experts\n  3. [220919 The Biased Artist](/rosinality/ml-papers/blob/main/papers/2022/220919%20The%20Biased%20Artist.md) #image_generation\n  4. [230731 KoBBQ](/rosinality/ml-papers/blob/main/papers/2023/230731%20KoBBQ.md)\n\n## calibration\n\n  1. [200221 Calibrating Deep Neural Networks using Focal Loss](/rosinality/ml-papers/blob/main/papers/2020/200221%20Calibrating%20Deep%20Neural%20Networks%20using%20Focal%20Loss.md) #loss\n  2. [200223 Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks](/rosinality/ml-papers/blob/main/papers/2020/200223%20Being%20Bayesian%2C%20Even%20Just%20a%20Bit%2C%20Fixes%20Overconfidence%20in%20ReLU%20Networks.md) #bayesian\n  3. [200620 Regression Prior Networks](/rosinality/ml-papers/blob/main/papers/2020/200620%20Regression%20Prior%20Networks.md)\n  4. [210730 Soft Calibration Objectives for Neural Networks](/rosinality/ml-papers/blob/main/papers/2021/210730%20Soft%20Calibration%20Objectives%20for%20Neural%20Networks.md)\n\n## causality\n\n  1. [200518 An Analysis of the Adaptation Speed of Causal Models](/rosinality/ml-papers/blob/main/papers/2020/200518%20An%20Analysis%20of%20the%20Adaptation%20Speed%20of%20Causal%20Models.md)\n\n## channel attention\n\n  1. [200129 GCNet](/rosinality/ml-papers/blob/main/papers/2020/200129%20GCNet.md)\n\n## chat\n\n  1. [200630 PLATO-2](/rosinality/ml-papers/blob/main/papers/2020/200630%20PLATO-2.md) #text_gen #chatbot\n\n## classificiation\n\n  1. [220107 Generalized Category Discovery](/rosinality/ml-papers/blob/main/papers/2022/220107%20Generalized%20Category%20Discovery.md) #open_set_recognition\n\n## clip\n\n  1.", "start_char_idx": 37819, "end_char_idx": 40643, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "48e7530b-4abb-43eb-ba42-8ed2c5d3d1f8": {"__data__": {"id_": "48e7530b-4abb-43eb-ba42-8ed2c5d3d1f8", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7847cd41-6bf2-496d-b331-006630532bf6", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "c44658ab724cb7cba6e9cd08ede21b9239bd7bfb5696151d93456f8ca740addf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f38f7c57-2595-4a26-a283-eac7b1493f8c", "node_type": "1", "metadata": {}, "hash": "913d0d26f06bf29b8aca959c98dc427fffcf5ea81274eb153b393611aa3e51ee", "class_name": "RelatedNodeInfo"}}, "text": "[200129 GCNet](/rosinality/ml-papers/blob/main/papers/2020/200129%20GCNet.md)\n\n## chat\n\n  1. [200630 PLATO-2](/rosinality/ml-papers/blob/main/papers/2020/200630%20PLATO-2.md) #text_gen #chatbot\n\n## classificiation\n\n  1. [220107 Generalized Category Discovery](/rosinality/ml-papers/blob/main/papers/2022/220107%20Generalized%20Category%20Discovery.md) #open_set_recognition\n\n## clip\n\n  1. [230515 Improved baselines for vision-language pre-training](/rosinality/ml-papers/blob/main/papers/2023/230515%20Improved%20baselines%20for%20vision-language%20pre-training.md)\n\n## computation\n\n  1. [200213 Training Large Neural Networks with Constant Memory using a New Execution Algorithm](/rosinality/ml-papers/blob/main/papers/2020/200213%20Training%20Large%20Neural%20Networks%20with%20Constant%20Memory%20using%20a%20New%20Execution%20Algorithm.md)\n  2. [201204 Nimble](/rosinality/ml-papers/blob/main/papers/2020/201204%20Nimble.md)\n\n## continual learning\n\n  1. [201124 Energy-Based Models for Continual Learning](/rosinality/ml-papers/blob/main/papers/2020/201124%20Energy-Based%20Models%20for%20Continual%20Learning.md) #energy_based_model\n  2. [211103 One Pass ImageNet](/rosinality/ml-papers/blob/main/papers/2021/211103%20One%20Pass%20ImageNet.md) #online_learning\n\n## contrastive learning\n\n  1. [200213 A Simple Framework for Contrastive Learning of Visual Representations](/rosinality/ml-papers/blob/main/papers/2020/200213%20A%20Simple%20Framework%20for%20Contrastive%20Learning%20of%20Visual%20Representations.md) #augmentation\n  2. [200309 Improved Baselines with Momentum Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2020/200309%20Improved%20Baselines%20with%20Momentum%20Contrastive%20Learning.md)\n  3. [200311 Improved Baselines with Momentum Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2020/200311%20Improved%20Baselines%20with%20Momentum%20Contrastive%20Learning.md) #review\n  4. [200423 Supervised Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2020/200423%20Supervised%20Contrastive%20Learning.md) #metric_learning\n  5. [200511 Prototypical Contrastive Learning of Unsupervised Representations](/rosinality/ml-papers/blob/main/papers/2020/200511%20Prototypical%20Contrastive%20Learning%20of%20Unsupervised%20Representations.md)\n  6. [200520 What Makes for Good Views for Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2020/200520%20What%20Makes%20for%20Good%20Views%20for%20Contrastive%20Learning.md)\n  7. [200613 Bootstrap your own latent](/rosinality/ml-papers/blob/main/papers/2020/200613%20Bootstrap%20your%20own%20latent.md)\n  8. [200630 Debiased Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2020/200630%20Debiased%20Contrastive%20Learning.md)\n  9. [200730 Contrastive Learning for Unpaired Image-to-Image Translation](/rosinality/ml-papers/blob/main/papers/2020/200730%20Contrastive%20Learning%20for%20Unpaired%20Image-to-Image%20Translation.md) #img2img\n  10. [200803 LoCo](/rosinality/ml-papers/blob/main/papers/2020/200803%20LoCo.md)\n  11.", "start_char_idx": 40255, "end_char_idx": 43294, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f38f7c57-2595-4a26-a283-eac7b1493f8c": {"__data__": {"id_": "f38f7c57-2595-4a26-a283-eac7b1493f8c", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48e7530b-4abb-43eb-ba42-8ed2c5d3d1f8", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "d029097e55233a955e39ef08c4cc7e60584667af9f3037edfef75d008fce1c3c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "de2f43e5-81a4-4b76-971b-09d56f830a0d", "node_type": "1", "metadata": {}, "hash": "61ea06a221202229d7537772f0ac28d81490bc25e5a8b8502b7bb6b8bca46abc", "class_name": "RelatedNodeInfo"}}, "text": "[200613 Bootstrap your own latent](/rosinality/ml-papers/blob/main/papers/2020/200613%20Bootstrap%20your%20own%20latent.md)\n  8. [200630 Debiased Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2020/200630%20Debiased%20Contrastive%20Learning.md)\n  9. [200730 Contrastive Learning for Unpaired Image-to-Image Translation](/rosinality/ml-papers/blob/main/papers/2020/200730%20Contrastive%20Learning%20for%20Unpaired%20Image-to-Image%20Translation.md) #img2img\n  10. [200803 LoCo](/rosinality/ml-papers/blob/main/papers/2020/200803%20LoCo.md)\n  11. [201020 BYOL works even without batch statistics](/rosinality/ml-papers/blob/main/papers/2020/201020%20BYOL%20works%20even%20without%20batch%20statistics.md)\n  12. [201109 Towards Domain-Agnostic Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2020/201109%20Towards%20Domain-Agnostic%20Contrastive%20Learning.md) #mixup #multimodal\n  13. [201116 AdCo](/rosinality/ml-papers/blob/main/papers/2020/201116%20AdCo.md) #adversarial_training\n  14. [201117 Dense Contrastive Learning for Self-Supervised Visual Pre-Training](/rosinality/ml-papers/blob/main/papers/2020/201117%20Dense%20Contrastive%20Learning%20for%20Self-Supervised%20Visual%20Pre-Training.md)\n  15. [201119 Heterogeneous Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2020/201119%20Heterogeneous%20Contrastive%20Learning.md)\n  16. [201119 Propagate Yourself](/rosinality/ml-papers/blob/main/papers/2020/201119%20Propagate%20Yourself.md)\n  17. [201121 Run Away From your Teacher](/rosinality/ml-papers/blob/main/papers/2020/201121%20Run%20Away%20From%20your%20Teacher.md)\n  18. [201123 Boosting Contrastive Self-Supervised Learning with False Negative](/rosinality/ml-papers/blob/main/papers/2020/201123%20Boosting%20Contrastive%20Self-Supervised%20Learning%20with%20False%20Negative.md)\n  19. [201126 Beyond Single Instance Multi-view Unsupervised Representation Learning](/rosinality/ml-papers/blob/main/papers/2020/201126%20Beyond%20Single%20Instance%20Multi-view%20Unsupervised%20Representation%20Learning.md) #self_supervised #mixup\n  20. [201126 How Well Do Self-Supervised Models Transfer](/rosinality/ml-papers/blob/main/papers/2020/201126%20How%20Well%20Do%20Self-Supervised%20Models%20Transfer.md) #self_supervised #transfer\n  21. [201127 Self-EMD](/rosinality/ml-papers/blob/main/papers/2020/201127%20Self-EMD.md)\n  22. [201201 Towards Good Practices in Self-supervised Representation Learning](/rosinality/ml-papers/blob/main/papers/2020/201201%20Towards%20Good%20Practices%20in%20Self-supervised%20Representation%20Learning.md) #self_supervised\n  23. [201204 Seed the Views](/rosinality/ml-papers/blob/main/papers/2020/201204%20Seed%20the%20Views.md) #mixup\n  24. [201212 Contrastive Learning for Label-Efficient Semantic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/201212%20Contrastive%20Learning%20for%20Label-Efficient%20Semantic%20Segmentation.md) #semantic_segmentation\n  25.", "start_char_idx": 42736, "end_char_idx": 45689, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "de2f43e5-81a4-4b76-971b-09d56f830a0d": {"__data__": {"id_": "de2f43e5-81a4-4b76-971b-09d56f830a0d", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f38f7c57-2595-4a26-a283-eac7b1493f8c", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "3d446ac2ad2036509c515138f792f1272c24f0a55d7c9a7b7b2482e5627bf3ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67d5a9f1-b98f-4918-a691-2f09cd39b52e", "node_type": "1", "metadata": {}, "hash": "bf91ea0e9dbc5440d2446a3a135be2c1f4dff7c1c648de91dd3e327b414b8720", "class_name": "RelatedNodeInfo"}}, "text": "[201201 Towards Good Practices in Self-supervised Representation Learning](/rosinality/ml-papers/blob/main/papers/2020/201201%20Towards%20Good%20Practices%20in%20Self-supervised%20Representation%20Learning.md) #self_supervised\n  23. [201204 Seed the Views](/rosinality/ml-papers/blob/main/papers/2020/201204%20Seed%20the%20Views.md) #mixup\n  24. [201212 Contrastive Learning for Label-Efficient Semantic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/201212%20Contrastive%20Learning%20for%20Label-Efficient%20Semantic%20Segmentation.md) #semantic_segmentation\n  25. [201221 Online Bag-of-Visual-Words Generation for Unsupervised Representation](/rosinality/ml-papers/blob/main/papers/2020/201221%20Online%20Bag-of-Visual-Words%20Generation%20for%20Unsupervised%20Representation.md) #self_supervised #discrete_vae\n  26. [201226 Spatial Contrastive Learning for Few-Shot Classification](/rosinality/ml-papers/blob/main/papers/2020/201226%20Spatial%20Contrastive%20Learning%20for%20Few-Shot%20Classification.md) #few_shot #attention\n  27. [210324 A Broad Study on the Transferability of Visual Representations with Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2021/210324%20A%20Broad%20Study%20on%20the%20Transferability%20of%20Visual%20Representations%20with%20Contrastive%20Learning.md) #review\n  28. [210325 Contrasting Contrastive Self-Supervised Representation Learning Models](/rosinality/ml-papers/blob/main/papers/2021/210325%20Contrasting%20Contrastive%20Self-Supervised%20Representation%20Learning%20Models.md) #review\n  29. [210325 Rethinking Self-Supervised Learning](/rosinality/ml-papers/blob/main/papers/2021/210325%20Rethinking%20Self-Supervised%20Learning.md) #training\n  30. [210405 An Empirical Study of Training Self-Supervised Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/210405%20An%20Empirical%20Study%20of%20Training%20Self-Supervised%20Vision%20Transformers.md) #vision_transformer\n  31. [210426 Multimodal Contrastive Training for Visual Representation Learning](/rosinality/ml-papers/blob/main/papers/2021/210426%20Multimodal%20Contrastive%20Training%20for%20Visual%20Representation%20Learning.md) #multimodal\n  32. [210429 A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning](/rosinality/ml-papers/blob/main/papers/2021/210429%20A%20Large-Scale%20Study%20on%20Unsupervised%20Spatiotemporal%20Representation%20Learning.md) #video\n  33. [210429 Emerging Properties in Self-Supervised Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/210429%20Emerging%20Properties%20in%20Self-Supervised%20Vision%20Transformers.md) #saliency #vision_transformer #representation\n  34. [210429 With a Little Help from My Friends](/rosinality/ml-papers/blob/main/papers/2021/210429%20With%20a%20Little%20Help%20from%20My%20Friends.md) #knn\n  35. [210510 Self-Supervised Learning with Swin Transformers](/rosinality/ml-papers/blob/main/papers/2021/210510%20Self-Supervised%20Learning%20with%20Swin%20Transformers.md) #vision_transformer\n  36. [210511 VICReg](/rosinality/ml-papers/blob/main/papers/2021/210511%20VICReg.md)\n  37.", "start_char_idx": 45113, "end_char_idx": 48229, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67d5a9f1-b98f-4918-a691-2f09cd39b52e": {"__data__": {"id_": "67d5a9f1-b98f-4918-a691-2f09cd39b52e", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "de2f43e5-81a4-4b76-971b-09d56f830a0d", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "db051858c884bc11d5d16ec51b6a0c34a14ef7f504df30ec1fef1c267b1bdc19", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3f17c214-7ce9-4dd6-b23c-397afe8e3301", "node_type": "1", "metadata": {}, "hash": "4c28e79030512ed835b78da1357e072036d03278d74366b71d11dc8f42b12471", "class_name": "RelatedNodeInfo"}}, "text": "[210429 With a Little Help from My Friends](/rosinality/ml-papers/blob/main/papers/2021/210429%20With%20a%20Little%20Help%20from%20My%20Friends.md) #knn\n  35. [210510 Self-Supervised Learning with Swin Transformers](/rosinality/ml-papers/blob/main/papers/2021/210510%20Self-Supervised%20Learning%20with%20Swin%20Transformers.md) #vision_transformer\n  36. [210511 VICReg](/rosinality/ml-papers/blob/main/papers/2021/210511%20VICReg.md)\n  37. [210512 When Does Contrastive Visual Representation Learning Work](/rosinality/ml-papers/blob/main/papers/2021/210512%20When%20Does%20Contrastive%20Visual%20Representation%20Learning%20Work.md) #self_supervised #transfer #review\n  38. [210517 Divide and Contrast](/rosinality/ml-papers/blob/main/papers/2021/210517%20Divide%20and%20Contrast.md) #self_supervised #dataset #distillation\n  39. [210601 Exploring the Diversity and Invariance in Yourself for Visual Pre-Training Task](/rosinality/ml-papers/blob/main/papers/2021/210601%20Exploring%20the%20Diversity%20and%20Invariance%20in%20Yourself%20for%20Visual%20Pre-Training%20Task.md)\n  40. [211018 Understanding Dimensional Collapse in Contrastive Self-supervised Learning](/rosinality/ml-papers/blob/main/papers/2021/211018%20Understanding%20Dimensional%20Collapse%20in%20Contrastive%20Self-supervised%20Learning.md)\n  41. [220701 e-CLIP](/rosinality/ml-papers/blob/main/papers/2022/220701%20e-CLIP.md) #vision-language #retrieval\n  42. [220727 Contrastive Masked Autoencoders are Stronger Vision Learners](/rosinality/ml-papers/blob/main/papers/2022/220727%20Contrastive%20Masked%20Autoencoders%20are%20Stronger%20Vision%20Learners.md) #self_supervised #mlm\n  43. [220804 Fine-Grained Semantically Aligned Vision-Language Pre-Training](/rosinality/ml-papers/blob/main/papers/2022/220804%20Fine-Grained%20Semantically%20Aligned%20Vision-Language%20Pre-Training.md) #vision-language\n  44. [221017 Non-Contrastive Learning Meets Language-Image Pre-Training](/rosinality/ml-papers/blob/main/papers/2022/221017%20Non-Contrastive%20Learning%20Meets%20Language-Image%20Pre-Training.md) #clip\n  45. [230327 Sigmoid Loss for Language Image Pre-Training](/rosinality/ml-papers/blob/main/papers/2023/230327%20Sigmoid%20Loss%20for%20Language%20Image%20Pre-Training.md) #clip\n  46. [230414 DINOv2](/rosinality/ml-papers/blob/main/papers/2023/230414%20DINOv2.md)\n  47. [230418 Hyperbolic Image-Text Representations](/rosinality/ml-papers/blob/main/papers/2023/230418%20Hyperbolic%20Image-Text%20Representations.md) #clip #vision-language\n  48. [230501 What Do Self-Supervised Vision Transformers Learn](/rosinality/ml-papers/blob/main/papers/2023/230501%20What%20Do%20Self-Supervised%20Vision%20Transformers%20Learn.md) #self_supervised #mlm\n  49. [230627 CLIPA-v2](/rosinality/ml-papers/blob/main/papers/2023/230627%20CLIPA-v2.md) #vision-language #multimodal\n\n## convolution\n\n  1. [200316 SlimConv](/rosinality/ml-papers/blob/main/papers/2020/200316%20SlimConv.md)\n  2.", "start_char_idx": 47789, "end_char_idx": 50742, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3f17c214-7ce9-4dd6-b23c-397afe8e3301": {"__data__": {"id_": "3f17c214-7ce9-4dd6-b23c-397afe8e3301", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67d5a9f1-b98f-4918-a691-2f09cd39b52e", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "4002781f3a254f10610aa38d7e4c8a8a2823eeaf6a1d02d498266eceafd8a806", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "841baa43-4d68-4b8a-ad99-515ea87d4970", "node_type": "1", "metadata": {}, "hash": "9ea850a7ffdb7b6a5cbb93b6a4263fa3768c0c844070f98280f129aeaed45055", "class_name": "RelatedNodeInfo"}}, "text": "[230501 What Do Self-Supervised Vision Transformers Learn](/rosinality/ml-papers/blob/main/papers/2023/230501%20What%20Do%20Self-Supervised%20Vision%20Transformers%20Learn.md) #self_supervised #mlm\n  49. [230627 CLIPA-v2](/rosinality/ml-papers/blob/main/papers/2023/230627%20CLIPA-v2.md) #vision-language #multimodal\n\n## convolution\n\n  1. [200316 SlimConv](/rosinality/ml-papers/blob/main/papers/2020/200316%20SlimConv.md)\n  2. [210429 Decoupled Dynamic Filter Networks](/rosinality/ml-papers/blob/main/papers/2021/210429%20Decoupled%20Dynamic%20Filter%20Networks.md)\n  3. [230221 Hyena Hierarchy](/rosinality/ml-papers/blob/main/papers/2023/230221%20Hyena%20Hierarchy.md) #state_space_model\n\n## dataset\n\n  1. [200218 DivideMix](/rosinality/ml-papers/blob/main/papers/2020/200218%20DivideMix.md) #mixup #noise #semi_supervised_learning\n  2. [200509 Building a Manga Dataset](/rosinality/ml-papers/blob/main/papers/2020/200509%20Building%20a%20Manga%20Dataset.md)\n  3. [201130 Image Quality Assessment for Perceptual Image Restoration](/rosinality/ml-papers/blob/main/papers/2020/201130%20Image%20Quality%20Assessment%20for%20Perceptual%20Image%20Restoration.md) #score\n  4. [201201 Weakly-Supervised Arbitrary-Shaped Text Detection with](/rosinality/ml-papers/blob/main/papers/2020/201201%20Weakly-Supervised%20Arbitrary-Shaped%20Text%20Detection%20with.md) #ocr #weak_supervision\n  5. [210601 Comparing Test Sets with Item Response Theory](/rosinality/ml-papers/blob/main/papers/2021/210601%20Comparing%20Test%20Sets%20with%20Item%20Response%20Theory.md)\n  6. [210907 Datasets](/rosinality/ml-papers/blob/main/papers/2021/210907%20Datasets.md)\n  7. [210927 PASS](/rosinality/ml-papers/blob/main/papers/2021/210927%20PASS.md)\n  8. [211103 LAION-400M](/rosinality/ml-papers/blob/main/papers/2021/211103%20LAION-400M.md)\n  9. [220704 How Much More Data Do I Need](/rosinality/ml-papers/blob/main/papers/2022/220704%20How%20Much%20More%20Data%20Do%20I%20Need.md)\n  10. [230220 Poisoning Web-Scale Training Datasets is Practical](/rosinality/ml-papers/blob/main/papers/2023/230220%20Poisoning%20Web-Scale%20Training%20Datasets%20is%20Practical.md)\n  11. [230317 On the De-duplication of LAION-2B](/rosinality/ml-papers/blob/main/papers/2023/230317%20On%20the%20De-duplication%20of%20LAION-2B.md) #clip\n  12. [230428 CCpdf](/rosinality/ml-papers/blob/main/papers/2023/230428%20CCpdf.md)\n\n## ddpm\n\n  1. [200619 Denoising Diffusion Probabilistic Models](/rosinality/ml-papers/blob/main/papers/2020/200619%20Denoising%20Diffusion%20Probabilistic%20Models.md)\n  2. [201126 Score-Based Generative Modeling through Stochastic Differential](/rosinality/ml-papers/blob/main/papers/2020/201126%20Score-Based%20Generative%20Modeling%20through%20Stochastic%20Differential.md) #generative_model\n  3.", "start_char_idx": 50315, "end_char_idx": 53097, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "841baa43-4d68-4b8a-ad99-515ea87d4970": {"__data__": {"id_": "841baa43-4d68-4b8a-ad99-515ea87d4970", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3f17c214-7ce9-4dd6-b23c-397afe8e3301", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b55a99c88b69fd99e53d5c71abde1f9b50c3aad95f593028b3fe3435982a45f7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b6938d8-518c-46ef-b824-4b68729c8e81", "node_type": "1", "metadata": {}, "hash": "dbdb8cb3567cb60add4048e106251cb7d50846965fe29e42554b44d84adaeb44", "class_name": "RelatedNodeInfo"}}, "text": "[230428 CCpdf](/rosinality/ml-papers/blob/main/papers/2023/230428%20CCpdf.md)\n\n## ddpm\n\n  1. [200619 Denoising Diffusion Probabilistic Models](/rosinality/ml-papers/blob/main/papers/2020/200619%20Denoising%20Diffusion%20Probabilistic%20Models.md)\n  2. [201126 Score-Based Generative Modeling through Stochastic Differential](/rosinality/ml-papers/blob/main/papers/2020/201126%20Score-Based%20Generative%20Modeling%20through%20Stochastic%20Differential.md) #generative_model\n  3. [201214 Learning Energy-Based Models by Diffusion Recovery Likelihood](/rosinality/ml-papers/blob/main/papers/2020/201214%20Learning%20Energy-Based%20Models%20by%20Diffusion%20Recovery%20Likelihood.md) #energy_based_model\n  4. [210302 Fixing Data Augmentation to Improve Adversarial Robustness](/rosinality/ml-papers/blob/main/papers/2021/210302%20Fixing%20Data%20Augmentation%20to%20Improve%20Adversarial%20Robustness.md) #augmentation #generative_model\n  5. [210305 Fixing Data Augmentation to Improve Adversarial Robustness 2](/rosinality/ml-papers/blob/main/papers/2021/210305%20Fixing%20Data%20Augmentation%20to%20Improve%20Adversarial%20Robustness%202.md) #robustness #augmentation #generative_model\n  6. [210506 DiffSinger](/rosinality/ml-papers/blob/main/papers/2021/210506%20DiffSinger.md) #singing_voice_synthesis\n  7. [210511 Diffusion Models Beat GANs on Image Synthesis](/rosinality/ml-papers/blob/main/papers/2021/210511%20Diffusion%20Models%20Beat%20GANs%20on%20Image%20Synthesis.md)\n  8. [210528 Gotta Go Fast When Generating Data with Score-Based Models](/rosinality/ml-papers/blob/main/papers/2021/210528%20Gotta%20Go%20Fast%20When%20Generating%20Data%20with%20Score-Based%20Models.md)\n  9. [210531 On Fast Sampling of Diffusion Probabilistic Models](/rosinality/ml-papers/blob/main/papers/2021/210531%20On%20Fast%20Sampling%20of%20Diffusion%20Probabilistic%20Models.md)\n  10. [210607 Learning to Efficiently Sample from Diffusion Probabilistic Models](/rosinality/ml-papers/blob/main/papers/2021/210607%20Learning%20to%20Efficiently%20Sample%20from%20Diffusion%20Probabilistic%20Models.md)\n  11. [210610 Cascaded Diffusion Models for High Fidelity Image Generation](/rosinality/ml-papers/blob/main/papers/2021/210610%20Cascaded%20Diffusion%20Models%20for%20High%20Fidelity%20Image%20Generation.md)\n  12. [210610 Score-based Generative Modeling in Latent Space](/rosinality/ml-papers/blob/main/papers/2021/210610%20Score-based%20Generative%20Modeling%20in%20Latent%20Space.md)\n  13. [210612 D2C](/rosinality/ml-papers/blob/main/papers/2021/210612%20D2C.md)\n  14. [210701 Variational Diffusion Models](/rosinality/ml-papers/blob/main/papers/2021/210701%20Variational%20Diffusion%20Models.md)\n  15. [210802 SDEdit](/rosinality/ml-papers/blob/main/papers/2021/210802%20SDEdit.md)\n  16. [210819 ImageBART](/rosinality/ml-papers/blob/main/papers/2021/210819%20ImageBART.md) #vq #autoregressive_model\n  17.", "start_char_idx": 52619, "end_char_idx": 55516, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b6938d8-518c-46ef-b824-4b68729c8e81": {"__data__": {"id_": "1b6938d8-518c-46ef-b824-4b68729c8e81", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "841baa43-4d68-4b8a-ad99-515ea87d4970", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "72e638ea493cdc3735f73b5bb3a65f57162135da4c3489a51230b9aca0ef40d9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f5cf9b75-38a5-4196-beb1-886352f4435f", "node_type": "1", "metadata": {}, "hash": "9fc8ce6c9ce8964ff72775d18247d586fd31881c44a7ecfda0dc3bd65004f025", "class_name": "RelatedNodeInfo"}}, "text": "[210612 D2C](/rosinality/ml-papers/blob/main/papers/2021/210612%20D2C.md)\n  14. [210701 Variational Diffusion Models](/rosinality/ml-papers/blob/main/papers/2021/210701%20Variational%20Diffusion%20Models.md)\n  15. [210802 SDEdit](/rosinality/ml-papers/blob/main/papers/2021/210802%20SDEdit.md)\n  16. [210819 ImageBART](/rosinality/ml-papers/blob/main/papers/2021/210819%20ImageBART.md) #vq #autoregressive_model\n  17. [211129 Blended Diffusion for Text-driven Editing of Natural Images](/rosinality/ml-papers/blob/main/papers/2021/211129%20Blended%20Diffusion%20for%20Text-driven%20Editing%20of%20Natural%20Images.md) #clip #image_editing\n  18. [211130 Diffusion Autoencoders](/rosinality/ml-papers/blob/main/papers/2021/211130%20Diffusion%20Autoencoders.md)\n  19. [211220 GLIDE](/rosinality/ml-papers/blob/main/papers/2021/211220%20GLIDE.md) #multimodal\n  20. [211220 High-Resolution Image Synthesis with Latent Diffusion Models](/rosinality/ml-papers/blob/main/papers/2021/211220%20High-Resolution%20Image%20Synthesis%20with%20Latent%20Diffusion%20Models.md) #vae #vq\n  21. [220201 Progressive Distillation for Fast Sampling of Diffusion Models](/rosinality/ml-papers/blob/main/papers/2022/220201%20Progressive%20Distillation%20for%20Fast%20Sampling%20of%20Diffusion%20Models.md) #distillation\n  22. [220316 Dual Diffusion Implicit Bridges for Image-to-Image Translation](/rosinality/ml-papers/blob/main/papers/2022/220316%20Dual%20Diffusion%20Implicit%20Bridges%20for%20Image-to-Image%20Translation.md)\n  23. [220524 Imagen](/rosinality/ml-papers/blob/main/papers/2022/220524%20Imagen.md) #conditional_generative_model\n  24. [220601 Elucidating the Design Space of Diffusion-Based Generative Models](/rosinality/ml-papers/blob/main/papers/2022/220601%20Elucidating%20the%20Design%20Space%20of%20Diffusion-Based%20Generative%20Models.md)\n  25. [220803 Pyramidal Denoising Diffusion Probabilistic Models](/rosinality/ml-papers/blob/main/papers/2022/220803%20Pyramidal%20Denoising%20Diffusion%20Probabilistic%20Models.md)\n  26. [220808 Analog Bits](/rosinality/ml-papers/blob/main/papers/2022/220808%20Analog%20Bits.md)\n  27. [220912 Blurring Diffusion Models](/rosinality/ml-papers/blob/main/papers/2022/220912%20Blurring%20Diffusion%20Models.md)\n  28. [220912 Soft Diffusion](/rosinality/ml-papers/blob/main/papers/2022/220912%20Soft%20Diffusion.md)\n  29. [220929 DreamFusion](/rosinality/ml-papers/blob/main/papers/2022/220929%20DreamFusion.md) #3d_generative_model\n  30. [221017 Imagic](/rosinality/ml-papers/blob/main/papers/2022/221017%20Imagic.md) #image_editing\n  31. [221018 Differentially Private Diffusion Models](/rosinality/ml-papers/blob/main/papers/2022/221018%20Differentially%20Private%20Diffusion%20Models.md)\n  32. [221102 eDiffi](/rosinality/ml-papers/blob/main/papers/2022/221102%20eDiffi.md) #text2img\n  33.", "start_char_idx": 55099, "end_char_idx": 57928, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f5cf9b75-38a5-4196-beb1-886352f4435f": {"__data__": {"id_": "f5cf9b75-38a5-4196-beb1-886352f4435f", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b6938d8-518c-46ef-b824-4b68729c8e81", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "a9bee1a93b24e0713f24f18424a57147bd3b6e2dfe375315f00615a9f9385447", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "be75c88e-a3e8-4369-8907-b2abcd783d9f", "node_type": "1", "metadata": {}, "hash": "f4cb31d1f3d39bd98d6eba91e67463bc2a9df8c63cce99224d5c7bab6f3e4e6c", "class_name": "RelatedNodeInfo"}}, "text": "[220929 DreamFusion](/rosinality/ml-papers/blob/main/papers/2022/220929%20DreamFusion.md) #3d_generative_model\n  30. [221017 Imagic](/rosinality/ml-papers/blob/main/papers/2022/221017%20Imagic.md) #image_editing\n  31. [221018 Differentially Private Diffusion Models](/rosinality/ml-papers/blob/main/papers/2022/221018%20Differentially%20Private%20Diffusion%20Models.md)\n  32. [221102 eDiffi](/rosinality/ml-papers/blob/main/papers/2022/221102%20eDiffi.md) #text2img\n  33. [221115 Versatile Diffusion](/rosinality/ml-papers/blob/main/papers/2022/221115%20Versatile%20Diffusion.md) #vae\n  34. [221117 Null-text Inversion for Editing Real Images using Guided Diffusion Models](/rosinality/ml-papers/blob/main/papers/2022/221117%20Null-text%20Inversion%20for%20Editing%20Real%20Images%20using%20Guided%20Diffusion%20Models.md) #image_editing\n  35. [221118 Magic3D](/rosinality/ml-papers/blob/main/papers/2022/221118%20Magic3D.md) #3d_generative_model #text2img #nerf\n  36. [221120 Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models](/rosinality/ml-papers/blob/main/papers/2022/221120%20Synthesizing%20Coherent%20Story%20with%20Auto-Regressive%20Latent%20Diffusion%20Models.md) #text2img\n  37. [221124 Fast Sampling of Diffusion Models via Operator Learning](/rosinality/ml-papers/blob/main/papers/2022/221124%20Fast%20Sampling%20of%20Diffusion%20Models%20via%20Operator%20Learning.md)\n  38. [230126 On the Importance of Noise Scheduling for Diffusion Models](/rosinality/ml-papers/blob/main/papers/2023/230126%20On%20the%20Importance%20of%20Noise%20Scheduling%20for%20Diffusion%20Models.md)\n  39. [230126 simple diffusion](/rosinality/ml-papers/blob/main/papers/2023/230126%20simple%20diffusion.md)\n  40. [230131 Attend-and-Excite](/rosinality/ml-papers/blob/main/papers/2023/230131%20Attend-and-Excite.md) #text2img\n  41. [230205 Design Booster](/rosinality/ml-papers/blob/main/papers/2023/230205%20Design%20Booster.md) #image_editing\n  42. [230206 Zero-shot Image-to-Image Translation](/rosinality/ml-papers/blob/main/papers/2023/230206%20Zero-shot%20Image-to-Image%20Translation.md) #image_editing\n  43. [230207 Long Horizon Temperature Scaling](/rosinality/ml-papers/blob/main/papers/2023/230207%20Long%20Horizon%20Temperature%20Scaling.md) #calibration #lm\n  44. [230208 Q-Diffusion](/rosinality/ml-papers/blob/main/papers/2023/230208%20Q-Diffusion.md) #quantization\n  45. [230212 I$^2$SB](/rosinality/ml-papers/blob/main/papers/2023/230212%20I%24%5E2%24SB.md) #sde #image_restoration\n  46. [230215 PRedItOR](/rosinality/ml-papers/blob/main/papers/2023/230215%20PRedItOR.md) #image_editing\n  47. [230216 MultiDiffusion](/rosinality/ml-papers/blob/main/papers/2023/230216%20MultiDiffusion.md) #image_editing\n  48. [230220 Composer](/rosinality/ml-papers/blob/main/papers/2023/230220%20Composer.md) #image_editing\n  49.", "start_char_idx": 57457, "end_char_idx": 60297, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "be75c88e-a3e8-4369-8907-b2abcd783d9f": {"__data__": {"id_": "be75c88e-a3e8-4369-8907-b2abcd783d9f", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f5cf9b75-38a5-4196-beb1-886352f4435f", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "24dda1d52599f263758e1762bcb65d6cca1a5df2918d8fd5a40027c8426879da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1a75e047-7241-4079-8bcf-e60eba7a861f", "node_type": "1", "metadata": {}, "hash": "c6ca70cf2025852725b0a0b0d9460a96e4739a2a004c03811fe29a50c51091e9", "class_name": "RelatedNodeInfo"}}, "text": "[230212 I$^2$SB](/rosinality/ml-papers/blob/main/papers/2023/230212%20I%24%5E2%24SB.md) #sde #image_restoration\n  46. [230215 PRedItOR](/rosinality/ml-papers/blob/main/papers/2023/230215%20PRedItOR.md) #image_editing\n  47. [230216 MultiDiffusion](/rosinality/ml-papers/blob/main/papers/2023/230216%20MultiDiffusion.md) #image_editing\n  48. [230220 Composer](/rosinality/ml-papers/blob/main/papers/2023/230220%20Composer.md) #image_editing\n  49. [230221 Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels](/rosinality/ml-papers/blob/main/papers/2023/230221%20Diffusion%20Models%20and%20Semi-Supervised%20Learners%20Benefit%20Mutually%20with%20Few%20Labels.md) #semi_supervised_learning #self_supervised\n  50. [230221 On Calibrating Diffusion Probabilistic Models](/rosinality/ml-papers/blob/main/papers/2023/230221%20On%20Calibrating%20Diffusion%20Probabilistic%20Models.md)\n  51. [230223 Controlled and Conditional Text to Image Generation with Diffusion Prior](/rosinality/ml-papers/blob/main/papers/2023/230223%20Controlled%20and%20Conditional%20Text%20to%20Image%20Generation%20with%20Diffusion%20Prior.md)\n  52. [230227 ELITE](/rosinality/ml-papers/blob/main/papers/2023/230227%20ELITE.md) #text2img\n  53. [230301 Unlimited-Size Diffusion Restoration](/rosinality/ml-papers/blob/main/papers/2023/230301%20Unlimited-Size%20Diffusion%20Restoration.md) #image_restoration\n  54. [230302 Consistency Models](/rosinality/ml-papers/blob/main/papers/2023/230302%20Consistency%20Models.md) #generative_model\n  55. [230307 TRACT](/rosinality/ml-papers/blob/main/papers/2023/230307%20TRACT.md) #distillation\n  56. [230309 Cones](/rosinality/ml-papers/blob/main/papers/2023/230309%20Cones.md) #image_editing\n  57. [230316 $P+$](/rosinality/ml-papers/blob/main/papers/2023/230316%20%24P%2B%24.md) #text2img\n  58. [230316 Efficient Diffusion Training via Min-SNR Weighting Strategy](/rosinality/ml-papers/blob/main/papers/2023/230316%20Efficient%20Diffusion%20Training%20via%20Min-SNR%20Weighting%20Strategy.md)\n  59. [230320 SVDiff](/rosinality/ml-papers/blob/main/papers/2023/230320%20SVDiff.md) #image_editing\n  60. [230405 Generative Novel View Synthesis with 3D-Aware Diffusion Models](/rosinality/ml-papers/blob/main/papers/2023/230405%20Generative%20Novel%20View%20Synthesis%20with%203D-Aware%20Diffusion%20Models.md) #nerf\n  61. [230405 Taming Encoder for Zero Fine-tuning Image Customization with Text-to-Image Diffusion Models](/rosinality/ml-papers/blob/main/papers/2023/230405%20Taming%20Encoder%20for%20Zero%20Fine-tuning%20Image%20Customization%20with%20Text-to-Image%20Diffusion%20Models.md)\n  62. [230406 Diffusion Models as Masked Autoencoders](/rosinality/ml-papers/blob/main/papers/2023/230406%20Diffusion%20Models%20as%20Masked%20Autoencoders.md) #representation\n  63.", "start_char_idx": 59853, "end_char_idx": 62659, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a75e047-7241-4079-8bcf-e60eba7a861f": {"__data__": {"id_": "1a75e047-7241-4079-8bcf-e60eba7a861f", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "be75c88e-a3e8-4369-8907-b2abcd783d9f", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "4fa559076c9482d17aa96dd6bf8c9b3c8e6b3af9e7fb83605dcba4299c7469e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "81bd2cd9-2848-402a-b315-83f383fbb36d", "node_type": "1", "metadata": {}, "hash": "3976231f1fda079238cd90de4d10b6ccea3fd2d4a26b3d6b51eb350e4b10b22b", "class_name": "RelatedNodeInfo"}}, "text": "[230405 Taming Encoder for Zero Fine-tuning Image Customization with Text-to-Image Diffusion Models](/rosinality/ml-papers/blob/main/papers/2023/230405%20Taming%20Encoder%20for%20Zero%20Fine-tuning%20Image%20Customization%20with%20Text-to-Image%20Diffusion%20Models.md)\n  62. [230406 Diffusion Models as Masked Autoencoders](/rosinality/ml-papers/blob/main/papers/2023/230406%20Diffusion%20Models%20as%20Masked%20Autoencoders.md) #representation\n  63. [230406 InstantBooth](/rosinality/ml-papers/blob/main/papers/2023/230406%20InstantBooth.md) #image_editing\n  64. [230501 In-Context Learning Unlocked for Diffusion Models](/rosinality/ml-papers/blob/main/papers/2023/230501%20In-Context%20Learning%20Unlocked%20for%20Diffusion%20Models.md) #few_shot #text2img\n  65. [230515 Common Diffusion Noise Schedules and Sample Steps are Flawed](/rosinality/ml-papers/blob/main/papers/2023/230515%20Common%20Diffusion%20Noise%20Schedules%20and%20Sample%20Steps%20are%20Flawed.md)\n  66. [230529 RAPHAEL](/rosinality/ml-papers/blob/main/papers/2023/230529%20RAPHAEL.md)\n  67. [230601 StyleDrop](/rosinality/ml-papers/blob/main/papers/2023/230601%20StyleDrop.md) #style_transfer\n  68. [230706 Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback](/rosinality/ml-papers/blob/main/papers/2023/230706%20Censored%20Sampling%20of%20Diffusion%20Models%20Using%203%20Minutes%20of%20Human%20Feedback.md)\n  69. [230707 SDXL](/rosinality/ml-papers/blob/main/papers/2023/230707%20SDXL.md) #text2img\n  70. [230710 AnimateDiff](/rosinality/ml-papers/blob/main/papers/2023/230710%20AnimateDiff.md)\n\n## decoding\n\n  1. [200516 Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning](/rosinality/ml-papers/blob/main/papers/2020/200516%20Layer-Wise%20Cross-View%20Decoding%20for%20Sequence-to-Sequence%20Learning.md)\n  2. [200601 Cascaded Text Generation with Markov Transformers](/rosinality/ml-papers/blob/main/papers/2020/200601%20Cascaded%20Text%20Generation%20with%20Markov%20Transformers.md) #text_generation\n  3. [210608 FastSeq](/rosinality/ml-papers/blob/main/papers/2021/210608%20FastSeq.md)\n\n## deep prior\n\n  1. [200408 Deep Manifold Prior](/rosinality/ml-papers/blob/main/papers/2020/200408%20Deep%20Manifold%20Prior.md)\n\n## detr\n\n  1. [201201 MaX-DeepLab](/rosinality/ml-papers/blob/main/papers/2020/201201%20MaX-DeepLab.md) #panoptic_segmentation #end2end\n  2. [210813 Conditional DETR for Fast Training Convergence](/rosinality/ml-papers/blob/main/papers/2021/210813%20Conditional%20DETR%20for%20Fast%20Training%20Convergence.md)\n  3. [211202 Masked-attention Mask Transformer for Universal Image Segmentation](/rosinality/ml-papers/blob/main/papers/2021/211202%20Masked-attention%20Mask%20Transformer%20for%20Universal%20Image%20Segmentation.md) #panoptic_segmentation\n  4. [220726 Group DETR](/rosinality/ml-papers/blob/main/papers/2022/220726%20Group%20DETR.md) #efficient_training\n  5.", "start_char_idx": 62208, "end_char_idx": 65111, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "81bd2cd9-2848-402a-b315-83f383fbb36d": {"__data__": {"id_": "81bd2cd9-2848-402a-b315-83f383fbb36d", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1a75e047-7241-4079-8bcf-e60eba7a861f", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "8f7ada7f67fba4d62c89e62d03954b6cd7dc5f42b747ac1a51d45d3aec675793", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b608a4ed-8b87-4a28-abf0-352e0c6686ef", "node_type": "1", "metadata": {}, "hash": "e4699f0d3d63fc5804d5579d62f62a2f2bb17cf3426633937ca3ef1d5e606e9d", "class_name": "RelatedNodeInfo"}}, "text": "[210813 Conditional DETR for Fast Training Convergence](/rosinality/ml-papers/blob/main/papers/2021/210813%20Conditional%20DETR%20for%20Fast%20Training%20Convergence.md)\n  3. [211202 Masked-attention Mask Transformer for Universal Image Segmentation](/rosinality/ml-papers/blob/main/papers/2021/211202%20Masked-attention%20Mask%20Transformer%20for%20Universal%20Image%20Segmentation.md) #panoptic_segmentation\n  4. [220726 Group DETR](/rosinality/ml-papers/blob/main/papers/2022/220726%20Group%20DETR.md) #efficient_training\n  5. [230803 DETR Doesn't Need Multi-Scale or Locality Design](/rosinality/ml-papers/blob/main/papers/2023/230803%20DETR%20Doesn%27t%20Need%20Multi-Scale%20or%20Locality%20Design.md) #multiscale\n\n## dewarping\n\n  1. [211025 DocTr](/rosinality/ml-papers/blob/main/papers/2021/211025%20DocTr.md)\n  2. [211028 DocScanner](/rosinality/ml-papers/blob/main/papers/2021/211028%20DocScanner.md)\n\n## dialog\n\n  1. [200129 Meena](/rosinality/ml-papers/blob/main/papers/2020/200129%20Meena.md) #NLP\n  2. [210715 Beyond Goldfish Memory](/rosinality/ml-papers/blob/main/papers/2021/210715%20Beyond%20Goldfish%20Memory.md)\n  3. [220120 LaMDA](/rosinality/ml-papers/blob/main/papers/2022/220120%20LaMDA.md)\n\n## differentiable operator\n\n  1. [200220 Fast Differentiable Sorting and Ranking](/rosinality/ml-papers/blob/main/papers/2020/200220%20Fast%20Differentiable%20Sorting%20and%20Ranking.md)\n\n## differentiable tree\n\n  1. [200218 The Tree Ensemble Layer](/rosinality/ml-papers/blob/main/papers/2020/200218%20The%20Tree%20Ensemble%20Layer.md)\n\n## discrete vae\n\n  1. [200518 Robust Training of Vector Quantized Bottleneck Models](/rosinality/ml-papers/blob/main/papers/2020/200518%20Robust%20Training%20of%20Vector%20Quantized%20Bottleneck%20Models.md)\n\n## disentangle\n\n  1. [200130 ID-GAN](/rosinality/ml-papers/blob/main/papers/2020/200130%20ID-GAN.md) #GAN\n  2. [200130 MixNMatch](/rosinality/ml-papers/blob/main/papers/2020/200130%20MixNMatch.md) #conditional_generative_model\n  3. [200515 Face Identity Disentanglement via Latent Space Mapping](/rosinality/ml-papers/blob/main/papers/2020/200515%20Face%20Identity%20Disentanglement%20via%20Latent%20Space%20Mapping.md)\n\n## distillation\n\n  1. [200129 Learning by Cheating](/rosinality/ml-papers/blob/main/papers/2020/200129%20Learning%20by%20Cheating.md)\n  2. [200209 Understanding and Improving Knowledge Distillation](/rosinality/ml-papers/blob/main/papers/2020/200209%20Understanding%20and%20Improving%20Knowledge%20Distillation.md)\n  3. [200210 Subclass Distillation](/rosinality/ml-papers/blob/main/papers/2020/200210%20Subclass%20Distillation.md)\n  4. [200219 Knapsack Pruning with Inner Distillation](/rosinality/ml-papers/blob/main/papers/2020/200219%20Knapsack%20Pruning%20with%20Inner%20Distillation.md) #pruning #lightweight\n  5. [200221 Residual Knowledge Distillation](/rosinality/ml-papers/blob/main/papers/2020/200221%20Residual%20Knowledge%20Distillation.md)\n  6.", "start_char_idx": 64582, "end_char_idx": 67524, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b608a4ed-8b87-4a28-abf0-352e0c6686ef": {"__data__": {"id_": "b608a4ed-8b87-4a28-abf0-352e0c6686ef", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "81bd2cd9-2848-402a-b315-83f383fbb36d", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "a6eff5e401235bd1a1c6600487f311788631eb9d42cd0ff5ceb5e28d9e8b8130", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a0491ea4-aae1-41e6-a26d-8b71db814d4c", "node_type": "1", "metadata": {}, "hash": "8687ab6de046274e60a19556d75d295c55a8c243cb53fe2de29fa579a740d934", "class_name": "RelatedNodeInfo"}}, "text": "[200209 Understanding and Improving Knowledge Distillation](/rosinality/ml-papers/blob/main/papers/2020/200209%20Understanding%20and%20Improving%20Knowledge%20Distillation.md)\n  3. [200210 Subclass Distillation](/rosinality/ml-papers/blob/main/papers/2020/200210%20Subclass%20Distillation.md)\n  4. [200219 Knapsack Pruning with Inner Distillation](/rosinality/ml-papers/blob/main/papers/2020/200219%20Knapsack%20Pruning%20with%20Inner%20Distillation.md) #pruning #lightweight\n  5. [200221 Residual Knowledge Distillation](/rosinality/ml-papers/blob/main/papers/2020/200221%20Residual%20Knowledge%20Distillation.md)\n  6. [200309 Knowledge distillation via adaptive instance normalization](/rosinality/ml-papers/blob/main/papers/2020/200309%20Knowledge%20distillation%20via%20adaptive%20instance%20normalization.md) #normalization\n  7. [200521 Why distillation helps](/rosinality/ml-papers/blob/main/papers/2020/200521%20Why%20distillation%20helps.md) #calibration\n  8. [200629 An EM Approach to Non-autoregressive Conditional Sequence Generation](/rosinality/ml-papers/blob/main/papers/2020/200629%20An%20EM%20Approach%20to%20Non-autoregressive%20Conditional%20Sequence%20Generation.md) #non-autoregressive\n  9. [200701 Go Wide, Then Narrow](/rosinality/ml-papers/blob/main/papers/2020/200701%20Go%20Wide%2C%20Then%20Narrow.md) #lightweight\n  10. [200702 Interactive Knowledge Distillation](/rosinality/ml-papers/blob/main/papers/2020/200702%20Interactive%20Knowledge%20Distillation.md)\n  11. [210726 Text is Text, No Matter What](/rosinality/ml-papers/blob/main/papers/2021/210726%20Text%20is%20Text%2C%20No%20Matter%20What.md) #multitask\n\n## distributed training\n\n  1. [210510 GSPMD](/rosinality/ml-papers/blob/main/papers/2021/210510%20GSPMD.md)\n  2. [230121 SuperScaler](/rosinality/ml-papers/blob/main/papers/2023/230121%20SuperScaler.md)\n\n## domain adaptation\n\n  1. [200526 Keep it Simple](/rosinality/ml-papers/blob/main/papers/2020/200526%20Keep%20it%20Simple.md)\n\n## dropout\n\n  1. [200701 On Dropout, Overfitting, and Interaction Effects in Deep Neural Networks](/rosinality/ml-papers/blob/main/papers/2020/200701%20On%20Dropout%2C%20Overfitting%2C%20and%20Interaction%20Effects%20in%20Deep%20Neural%20Networks.md)\n\n## efficiency\n\n  1. [230130 Alternating Updates for Efficient Transformers](/rosinality/ml-papers/blob/main/papers/2023/230130%20Alternating%20Updates%20for%20Efficient%20Transformers.md)\n  2. [230530 Blockwise Parallel Transformer for Long Context Large Models](/rosinality/ml-papers/blob/main/papers/2023/230530%20Blockwise%20Parallel%20Transformer%20for%20Long%20Context%20Large%20Models.md)\n  3. [230624 H$_2$O](/rosinality/ml-papers/blob/main/papers/2023/230624%20H%24_2%24O.md)\n  4. [230705 SkipDecode](/rosinality/ml-papers/blob/main/papers/2023/230705%20SkipDecode.md)\n  5. [230728 Skeleton-of-Thought](/rosinality/ml-papers/blob/main/papers/2023/230728%20Skeleton-of-Thought.md)\n\n## efficient attention\n\n  1. [200410 Longformer](/rosinality/ml-papers/blob/main/papers/2020/200410%20Longformer.md)\n  2.", "start_char_idx": 66905, "end_char_idx": 69939, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a0491ea4-aae1-41e6-a26d-8b71db814d4c": {"__data__": {"id_": "a0491ea4-aae1-41e6-a26d-8b71db814d4c", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b608a4ed-8b87-4a28-abf0-352e0c6686ef", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "47baa7da3f0d6b70b59d0bc08fafba37c6e2401fdc2713cfc43c7523019c7049", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67b9db09-81af-43d4-8965-df9d05d9f063", "node_type": "1", "metadata": {}, "hash": "24336cf92ed1e6f200a51f8c144cbbc53f513c81968fb88bcd3ad4c99f2dde81", "class_name": "RelatedNodeInfo"}}, "text": "[230624 H$_2$O](/rosinality/ml-papers/blob/main/papers/2023/230624%20H%24_2%24O.md)\n  4. [230705 SkipDecode](/rosinality/ml-papers/blob/main/papers/2023/230705%20SkipDecode.md)\n  5. [230728 Skeleton-of-Thought](/rosinality/ml-papers/blob/main/papers/2023/230728%20Skeleton-of-Thought.md)\n\n## efficient attention\n\n  1. [200410 Longformer](/rosinality/ml-papers/blob/main/papers/2020/200410%20Longformer.md)\n  2. [200412 ProFormer](/rosinality/ml-papers/blob/main/papers/2020/200412%20ProFormer.md)\n  3. [200605 Masked Language Modeling for Proteins via Linearly Scalable Long-Context](/rosinality/ml-papers/blob/main/papers/2020/200605%20Masked%20Language%20Modeling%20for%20Proteins%20via%20Linearly%20Scalable%20Long-Context.md)\n  4. [200608 Linformer](/rosinality/ml-papers/blob/main/papers/2020/200608%20Linformer.md)\n  5. [210324 Finetuning Pretrained Transformers into RNNs](/rosinality/ml-papers/blob/main/papers/2021/210324%20Finetuning%20Pretrained%20Transformers%20into%20RNNs.md)\n  6. [210505 Beyond Self-attention](/rosinality/ml-papers/blob/main/papers/2021/210505%20Beyond%20Self-attention.md)\n  7. [210510 Poolingformer](/rosinality/ml-papers/blob/main/papers/2021/210510%20Poolingformer.md)\n  8. [210603 Luna](/rosinality/ml-papers/blob/main/papers/2021/210603%20Luna.md)\n  9. [210623 Stable, Fast and Accurate](/rosinality/ml-papers/blob/main/papers/2021/210623%20Stable%2C%20Fast%20and%20Accurate.md)\n  10. [210705 Long-Short Transformer](/rosinality/ml-papers/blob/main/papers/2021/210705%20Long-Short%20Transformer.md) #local_attention\n  11. [210712 Combiner](/rosinality/ml-papers/blob/main/papers/2021/210712%20Combiner.md) #sparse_attention #local_attention\n  12. [210725 H-Transformer-1D](/rosinality/ml-papers/blob/main/papers/2021/210725%20H-Transformer-1D.md)\n  13. [211210 Self-attention Does Not Need $O(n^2)$ Memory](/rosinality/ml-papers/blob/main/papers/2021/211210%20Self-attention%20Does%20Not%20Need%20%24O%28n%5E2%29%24%20Memory.md)\n  14. [220527 FlashAttention](/rosinality/ml-papers/blob/main/papers/2022/220527%20FlashAttention.md)\n  15. [220726 DETRs with Hybrid Matching](/rosinality/ml-papers/blob/main/papers/2022/220726%20DETRs%20with%20Hybrid%20Matching.md) #detr\n  16. [220911 On The Computational Complexity of Self-Attention](/rosinality/ml-papers/blob/main/papers/2022/220911%20On%20The%20Computational%20Complexity%20of%20Self-Attention.md)\n  17. [220921 Mega](/rosinality/ml-papers/blob/main/papers/2022/220921%20Mega.md)\n  18. [230317 CoLT5](/rosinality/ml-papers/blob/main/papers/2023/230317%20CoLT5.md)\n  19. [230705 LongNet](/rosinality/ml-papers/blob/main/papers/2023/230705%20LongNet.md)\n  20. [230706 Focused Transformer](/rosinality/ml-papers/blob/main/papers/2023/230706%20Focused%20Transformer.md)\n\n## efficient training\n\n  1.", "start_char_idx": 69529, "end_char_idx": 72315, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67b9db09-81af-43d4-8965-df9d05d9f063": {"__data__": {"id_": "67b9db09-81af-43d4-8965-df9d05d9f063", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a0491ea4-aae1-41e6-a26d-8b71db814d4c", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b9f1063c0b78eebe1a1f0b0cd14f3f924fadfaa1c031c2136daa7796844efa3c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7bc9b8ba-5ded-4474-a89a-228102d65a56", "node_type": "1", "metadata": {}, "hash": "67ce6488f3629eee9c8b1c51a3fdd21db6ed437d808ba6ea15b3dfc1f4b0c58c", "class_name": "RelatedNodeInfo"}}, "text": "[220911 On The Computational Complexity of Self-Attention](/rosinality/ml-papers/blob/main/papers/2022/220911%20On%20The%20Computational%20Complexity%20of%20Self-Attention.md)\n  17. [220921 Mega](/rosinality/ml-papers/blob/main/papers/2022/220921%20Mega.md)\n  18. [230317 CoLT5](/rosinality/ml-papers/blob/main/papers/2023/230317%20CoLT5.md)\n  19. [230705 LongNet](/rosinality/ml-papers/blob/main/papers/2023/230705%20LongNet.md)\n  20. [230706 Focused Transformer](/rosinality/ml-papers/blob/main/papers/2023/230706%20Focused%20Transformer.md)\n\n## efficient training\n\n  1. [230216 Decoupled Model Schedule for Deep Learning Training](/rosinality/ml-papers/blob/main/papers/2023/230216%20Decoupled%20Model%20Schedule%20for%20Deep%20Learning%20Training.md) #distributed_training\n  2. [230711 Stack More Layers Differently](/rosinality/ml-papers/blob/main/papers/2023/230711%20Stack%20More%20Layers%20Differently.md)\n  3. [230712 No Train No Gain](/rosinality/ml-papers/blob/main/papers/2023/230712%20No%20Train%20No%20Gain.md)\n  4. [230807 LoRA-FA](/rosinality/ml-papers/blob/main/papers/2023/230807%20LoRA-FA.md)\n\n## embedding\n\n  1. [200424 All Word Embeddings from One Embedding](/rosinality/ml-papers/blob/main/papers/2020/200424%20All%20Word%20Embeddings%20from%20One%20Embedding.md)\n  2. [200717 A Unifying Perspective on Neighbor Embeddings along the](/rosinality/ml-papers/blob/main/papers/2020/200717%20A%20Unifying%20Perspective%20on%20Neighbor%20Embeddings%20along%20the.md)\n  3. [210907 Rare Words Degenerate All Words](/rosinality/ml-papers/blob/main/papers/2021/210907%20Rare%20Words%20Degenerate%20All%20Words.md)\n\n## end2end\n\n  1. [200605 End-to-End Adversarial Text-to-Speech](/rosinality/ml-papers/blob/main/papers/2020/200605%20End-to-End%20Adversarial%20Text-to-Speech.md) #tts\n  2. [200608 FastSpeech 2](/rosinality/ml-papers/blob/main/papers/2020/200608%20FastSpeech%202.md) #tts\n  3. [201106 Wave-Tacotron](/rosinality/ml-papers/blob/main/papers/2020/201106%20Wave-Tacotron.md) #tts\n  4. [210716 Autonomy 2.0](/rosinality/ml-papers/blob/main/papers/2021/210716%20Autonomy%202.0.md)\n  5. [211215 SPTS](/rosinality/ml-papers/blob/main/papers/2021/211215%20SPTS.md)\n\n## energy based model\n\n  1. [200504 How to Train Your Energy-Based Model for Regression](/rosinality/ml-papers/blob/main/papers/2020/200504%20How%20to%20Train%20Your%20Energy-Based%20Model%20for%20Regression.md)\n\n## ensemble\n\n  1. [200217 BatchEnsemble](/rosinality/ml-papers/blob/main/papers/2020/200217%20BatchEnsemble.md)\n\n## federated learning\n\n  1. [210415 See through Gradients](/rosinality/ml-papers/blob/main/papers/2021/210415%20See%20through%20Gradients.md)\n\n## few shot\n\n  1. [200228 AdarGCN](/rosinality/ml-papers/blob/main/papers/2020/200228%20AdarGCN.md) #graph\n  2.", "start_char_idx": 71743, "end_char_idx": 74507, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7bc9b8ba-5ded-4474-a89a-228102d65a56": {"__data__": {"id_": "7bc9b8ba-5ded-4474-a89a-228102d65a56", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67b9db09-81af-43d4-8965-df9d05d9f063", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "34bb70a895f76962d7e930ae9aef54b637ba9486e07e8efee94217d84a3b53a5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f4039ad2-a6cc-410a-9630-394c05fd647d", "node_type": "1", "metadata": {}, "hash": "5f1ee6331ba2f9fa10e9b9df72440babaf704107e9fd021704749ef058c26d2f", "class_name": "RelatedNodeInfo"}}, "text": "[200504 How to Train Your Energy-Based Model for Regression](/rosinality/ml-papers/blob/main/papers/2020/200504%20How%20to%20Train%20Your%20Energy-Based%20Model%20for%20Regression.md)\n\n## ensemble\n\n  1. [200217 BatchEnsemble](/rosinality/ml-papers/blob/main/papers/2020/200217%20BatchEnsemble.md)\n\n## federated learning\n\n  1. [210415 See through Gradients](/rosinality/ml-papers/blob/main/papers/2021/210415%20See%20through%20Gradients.md)\n\n## few shot\n\n  1. [200228 AdarGCN](/rosinality/ml-papers/blob/main/papers/2020/200228%20AdarGCN.md) #graph\n  2. [210608 Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks](/rosinality/ml-papers/blob/main/papers/2021/210608%20Parameter-efficient%20Multi-task%20Fine-tuning%20for%20Transformers%20via%20Shared%20Hypernetworks.md) #adapter #multitask\n  3. [210910 LibFewShot](/rosinality/ml-papers/blob/main/papers/2021/210910%20LibFewShot.md)\n  4. [220715 Plex](/rosinality/ml-papers/blob/main/papers/2022/220715%20Plex.md) #uncertainty #generalization\n\n## finetuning\n\n  1. [200214 AutoLR](/rosinality/ml-papers/blob/main/papers/2020/200214%20AutoLR.md) #pruning\n  2. [200426 Masking as an Efficient Alternative to Finetuning for Pretrained](/rosinality/ml-papers/blob/main/papers/2020/200426%20Masking%20as%20an%20Efficient%20Alternative%20to%20Finetuning%20for%20Pretrained.md)\n  3. [200709 Sample-based Regularization](/rosinality/ml-papers/blob/main/papers/2020/200709%20Sample-based%20Regularization.md) #transfer\n  4. [230428 Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs](/rosinality/ml-papers/blob/main/papers/2023/230428%20Empirical%20Analysis%20of%20the%20Strengths%20and%20Weaknesses%20of%20PEFT%20Techniques%20for%20LLMs.md)\n\n## flow\n\n  1. [200220 Regularized Autoencoders via Relaxed Injective Probability Flow](/rosinality/ml-papers/blob/main/papers/2020/200220%20Regularized%20Autoencoders%20via%20Relaxed%20Injective%20Probability%20Flow.md)\n  2. [200227 Woodbury Transformations for Deep Generative Flows](/rosinality/ml-papers/blob/main/papers/2020/200227%20Woodbury%20Transformations%20for%20Deep%20Generative%20Flows.md)\n\n## fpn\n\n  1. [200122 CARAFE](/rosinality/ml-papers/blob/main/papers/2020/200122%20CARAFE.md) #resampling\n  2. [200129 Mixture FPN](/rosinality/ml-papers/blob/main/papers/2020/200129%20Mixture%20FPN.md)\n  3. [200506 Scale-Equalizing Pyramid Convolution for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/200506%20Scale-Equalizing%20Pyramid%20Convolution%20for%20Object%20Detection.md)\n  4. [201201 Dynamic Feature Pyramid Networks for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/201201%20Dynamic%20Feature%20Pyramid%20Networks%20for%20Object%20Detection.md)\n  5. [201202 Dual Refinement Feature Pyramid Networks for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/201202%20Dual%20Refinement%20Feature%20Pyramid%20Networks%20for%20Object%20Detection.md)\n  6.", "start_char_idx": 73955, "end_char_idx": 76906, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f4039ad2-a6cc-410a-9630-394c05fd647d": {"__data__": {"id_": "f4039ad2-a6cc-410a-9630-394c05fd647d", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7bc9b8ba-5ded-4474-a89a-228102d65a56", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "8bd1af471b7b0f54d0accb658b1c34ec0b8dad19094bf1af297a3be443e8403b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "69a56a7b-a5e4-4b28-a043-c10cedbcc356", "node_type": "1", "metadata": {}, "hash": "8eb6ddf511785b121e92cfef61615c4531d30393d86be628236f98a47fc08666", "class_name": "RelatedNodeInfo"}}, "text": "[200506 Scale-Equalizing Pyramid Convolution for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/200506%20Scale-Equalizing%20Pyramid%20Convolution%20for%20Object%20Detection.md)\n  4. [201201 Dynamic Feature Pyramid Networks for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/201201%20Dynamic%20Feature%20Pyramid%20Networks%20for%20Object%20Detection.md)\n  5. [201202 Dual Refinement Feature Pyramid Networks for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/201202%20Dual%20Refinement%20Feature%20Pyramid%20Networks%20for%20Object%20Detection.md)\n  6. [201202 Parallel Residual Bi-Fusion Feature Pyramid Network for Accurate](/rosinality/ml-papers/blob/main/papers/2020/201202%20Parallel%20Residual%20Bi-Fusion%20Feature%20Pyramid%20Network%20for%20Accurate.md)\n  7. [201225 Implicit Feature Pyramid Network for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/201225%20Implicit%20Feature%20Pyramid%20Network%20for%20Object%20Detection.md) #equilibrium_model #implicit_model\n\n## gan\n\n  1. [170629 Do GANs actually learn the distribution](/rosinality/ml-papers/blob/main/papers/2017/170629%20Do%20GANs%20actually%20learn%20the%20distribution.md)\n  2. [191022 MelGAN](/rosinality/ml-papers/blob/main/papers/2019/191022%20MelGAN.md) #tts\n  3. [200129 Adversarial Lipschitz Regularization](/rosinality/ml-papers/blob/main/papers/2020/200129%20Adversarial%20Lipschitz%20Regularization.md)\n  4. [200129 GAN generalization metric](/rosinality/ml-papers/blob/main/papers/2020/200129%20GAN%20generalization%20metric.md)\n  5. [200129 OneGAN](/rosinality/ml-papers/blob/main/papers/2020/200129%20OneGAN.md)\n  6. [200130 AttentionGAN](/rosinality/ml-papers/blob/main/papers/2020/200130%20AttentionGAN.md) #attention #img2img\n  7. [200130 Evaluation metrics of GAN](/rosinality/ml-papers/blob/main/papers/2020/200130%20Evaluation%20metrics%20of%20GAN.md) #metric #evaluation #generative_model\n  8. [200130 Local GAN](/rosinality/ml-papers/blob/main/papers/2020/200130%20Local%20GAN.md) #attention\n  9. [200130 Noise Robust GAN](/rosinality/ml-papers/blob/main/papers/2020/200130%20Noise%20Robust%20GAN.md) #robustness\n  10. [200130 Small-GAN](/rosinality/ml-papers/blob/main/papers/2020/200130%20Small-GAN.md)\n  11. [200130 Smoothness and Stability in GANs](/rosinality/ml-papers/blob/main/papers/2020/200130%20Smoothness%20and%20Stability%20in%20GANs.md)\n  12. [200206 Unbalanced GANs](/rosinality/ml-papers/blob/main/papers/2020/200206%20Unbalanced%20GANs.md) #vae\n  13. [200210 Unsupervised Discovery of Interpretable Directions in the GAN Latent](/rosinality/ml-papers/blob/main/papers/2020/200210%20Unsupervised%20Discovery%20of%20Interpretable%20Directions%20in%20the%20GAN%20Latent.md) #semantic_factor\n  14. [200211 Improved Consistency Regularization for GANs](/rosinality/ml-papers/blob/main/papers/2020/200211%20Improved%20Consistency%20Regularization%20for%20GANs.md) #augmentation #consistency_regularization\n  15.", "start_char_idx": 76310, "end_char_idx": 79282, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "69a56a7b-a5e4-4b28-a043-c10cedbcc356": {"__data__": {"id_": "69a56a7b-a5e4-4b28-a043-c10cedbcc356", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f4039ad2-a6cc-410a-9630-394c05fd647d", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "aa902fee6b1c56b1f9eb01f96ec358ef6fb6002a6f5d1b5ce5504299348105b7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9436d80f-e285-41dd-a507-d4396bdf6e6a", "node_type": "1", "metadata": {}, "hash": "9dabe070212d81ce74e0636be4489ee77ce8e99e73f69b7024a551c8a8ba3a1a", "class_name": "RelatedNodeInfo"}}, "text": "[200206 Unbalanced GANs](/rosinality/ml-papers/blob/main/papers/2020/200206%20Unbalanced%20GANs.md) #vae\n  13. [200210 Unsupervised Discovery of Interpretable Directions in the GAN Latent](/rosinality/ml-papers/blob/main/papers/2020/200210%20Unsupervised%20Discovery%20of%20Interpretable%20Directions%20in%20the%20GAN%20Latent.md) #semantic_factor\n  14. [200211 Improved Consistency Regularization for GANs](/rosinality/ml-papers/blob/main/papers/2020/200211%20Improved%20Consistency%20Regularization%20for%20GANs.md) #augmentation #consistency_regularization\n  15. [200211 Smoothness and Stability in GANs](/rosinality/ml-papers/blob/main/papers/2020/200211%20Smoothness%20and%20Stability%20in%20GANs.md) #regularization\n  16. [200212 Image-to-Image Translation with Text Guidance](/rosinality/ml-papers/blob/main/papers/2020/200212%20Image-to-Image%20Translation%20with%20Text%20Guidance.md) #multimodal #multimodal_generation #img2img\n  17. [200212 Real or Not Real, that is the Question](/rosinality/ml-papers/blob/main/papers/2020/200212%20Real%20or%20Not%20Real%2C%20that%20is%20the%20Question.md)\n  18. [200214 Top-k Training of GANs](/rosinality/ml-papers/blob/main/papers/2020/200214%20Top-k%20Training%20of%20GANs.md) #regularization\n  19. [200220 The Benefits of Pairwise Discriminators for Adversarial Training](/rosinality/ml-papers/blob/main/papers/2020/200220%20The%20Benefits%20of%20Pairwise%20Discriminators%20for%20Adversarial%20Training.md) #regularization\n  20. [200223 GANHopper](/rosinality/ml-papers/blob/main/papers/2020/200223%20GANHopper.md) #img2img\n  21. [200224 When Relation Networks meet GANs](/rosinality/ml-papers/blob/main/papers/2020/200224%20When%20Relation%20Networks%20meet%20GANs.md) #regularization\n  22. [200225 Freeze the Discriminator](/rosinality/ml-papers/blob/main/papers/2020/200225%20Freeze%20the%20Discriminator.md) #finetuning #transfer\n  23. [200226 On Leveraging Pretrained GANs for Generation with Limited Data](/rosinality/ml-papers/blob/main/papers/2020/200226%20On%20Leveraging%20Pretrained%20GANs%20for%20Generation%20with%20Limited%20Data.md) #finetuning #transfer\n  24. [200227 Topology Distance](/rosinality/ml-papers/blob/main/papers/2020/200227%20Topology%20Distance.md) #topology #score\n  25. [200228 A U-Net Based Discriminator for Generative Adversarial Networks](/rosinality/ml-papers/blob/main/papers/2020/200228%20A%20U-Net%20Based%20Discriminator%20for%20Generative%20Adversarial%20Networks.md)\n  26. [200304 Creating High Resolution Images with a Latent Adversarial Generator](/rosinality/ml-papers/blob/main/papers/2020/200304%20Creating%20High%20Resolution%20Images%20with%20a%20Latent%20Adversarial%20Generator.md) #generative_model #super_resolution\n  27. [200308 Perceptual Image Super-Resolution with Progressive Adversarial Network](/rosinality/ml-papers/blob/main/papers/2020/200308%20Perceptual%20Image%20Super-Resolution%20with%20Progressive%20Adversarial%20Network.md) #super_resolution\n  28.", "start_char_idx": 78717, "end_char_idx": 81690, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9436d80f-e285-41dd-a507-d4396bdf6e6a": {"__data__": {"id_": "9436d80f-e285-41dd-a507-d4396bdf6e6a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "69a56a7b-a5e4-4b28-a043-c10cedbcc356", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ba1e3a0e34530ea783aadf568d068b59b91bbc1a48f5b500b5f42131e4dd73f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "817185e1-164a-486b-9b0e-9001d23dd401", "node_type": "1", "metadata": {}, "hash": "dcb525a57216d18e22cc93f81fc0f1cc0f3f1774c5f273f3025028321d5f9e24", "class_name": "RelatedNodeInfo"}}, "text": "[200304 Creating High Resolution Images with a Latent Adversarial Generator](/rosinality/ml-papers/blob/main/papers/2020/200304%20Creating%20High%20Resolution%20Images%20with%20a%20Latent%20Adversarial%20Generator.md) #generative_model #super_resolution\n  27. [200308 Perceptual Image Super-Resolution with Progressive Adversarial Network](/rosinality/ml-papers/blob/main/papers/2020/200308%20Perceptual%20Image%20Super-Resolution%20with%20Progressive%20Adversarial%20Network.md) #super_resolution\n  28. [200312 Your GAN is Secretly an Energy-based Model and You Should use Discriminator Driven Latent Sampling](/rosinality/ml-papers/blob/main/papers/2020/200312%20Your%20GAN%20is%20Secretly%20an%20Energy-based%20Model%20and%20You%20Should%20use%20Discriminator%20Driven%20Latent%20Sampling.md) #energy_based_model #sampling\n  29. [200317 Blur, Noise, and Compression Robust Generative Adversarial Networks](/rosinality/ml-papers/blob/main/papers/2020/200317%20Blur%2C%20Noise%2C%20and%20Compression%20Robust%20Generative%20Adversarial%20Networks.md) #noise\n  30. [200318 OpenGAN](/rosinality/ml-papers/blob/main/papers/2020/200318%20OpenGAN.md) #metric_learning\n  31. [200325 Improved Techniques for Training Single-Image GANs](/rosinality/ml-papers/blob/main/papers/2020/200325%20Improved%20Techniques%20for%20Training%20Single-Image%20GANs.md) #single_image\n  32. [200326 Image Generation Via Minimizing Fr\u00e9chet Distance in Discriminator Feature Space](/rosinality/ml-papers/blob/main/papers/2020/200326%20Image%20Generation%20Via%20Minimizing%20Fr%C3%A9chet%20Distance%20in%20Discriminator%20Feature%20Space.md)\n  33. [200402 Controllable Orthogonalization in Training DNNs](/rosinality/ml-papers/blob/main/papers/2020/200402%20Controllable%20Orthogonalization%20in%20Training%20DNNs.md) #regularization\n  34. [200404 Feature Quantization Improves GAN Training](/rosinality/ml-papers/blob/main/papers/2020/200404%20Feature%20Quantization%20Improves%20GAN%20Training.md) #discrete_vae\n  35. [200405 Discriminator Contrastive Divergence](/rosinality/ml-papers/blob/main/papers/2020/200405%20Discriminator%20Contrastive%20Divergence.md)\n  36. [200407 Inclusive GAN](/rosinality/ml-papers/blob/main/papers/2020/200407%20Inclusive%20GAN.md)\n  37. [200408 Attentive Normalization for Conditional Image Generation](/rosinality/ml-papers/blob/main/papers/2020/200408%20Attentive%20Normalization%20for%20Conditional%20Image%20Generation.md) #attention\n  38. [200504 Transforming and Projecting Images into Class-conditional Generative](/rosinality/ml-papers/blob/main/papers/2020/200504%20Transforming%20and%20Projecting%20Images%20into%20Class-conditional%20Generative.md) #generative_model\n  39. [200518 Unconditional Audio Generation with Generative Adversarial Networks and Cycle Regularization](/rosinality/ml-papers/blob/main/papers/2020/200518%20Unconditional%20Audio%20Generation%20with%20Generative%20Adversarial%20Networks%20and%20Cycle%20Regularization.md) #audio_generation\n  40. [200519 CIAGAN](/rosinality/ml-papers/blob/main/papers/2020/200519%20CIAGAN.md)\n  41.", "start_char_idx": 81187, "end_char_idx": 84260, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "817185e1-164a-486b-9b0e-9001d23dd401": {"__data__": {"id_": "817185e1-164a-486b-9b0e-9001d23dd401", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9436d80f-e285-41dd-a507-d4396bdf6e6a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "beff3c4005ea10cc12b78fe810ce62abb8cf854792cffca89ad58606478b7b8d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3a006d69-c3e2-4b2d-9506-549de80c388a", "node_type": "1", "metadata": {}, "hash": "e533691f6544e2b1b0d59b11184580c679f9faa6a7a82fde6f11d7e568e7221a", "class_name": "RelatedNodeInfo"}}, "text": "[200504 Transforming and Projecting Images into Class-conditional Generative](/rosinality/ml-papers/blob/main/papers/2020/200504%20Transforming%20and%20Projecting%20Images%20into%20Class-conditional%20Generative.md) #generative_model\n  39. [200518 Unconditional Audio Generation with Generative Adversarial Networks and Cycle Regularization](/rosinality/ml-papers/blob/main/papers/2020/200518%20Unconditional%20Audio%20Generation%20with%20Generative%20Adversarial%20Networks%20and%20Cycle%20Regularization.md) #audio_generation\n  40. [200519 CIAGAN](/rosinality/ml-papers/blob/main/papers/2020/200519%20CIAGAN.md)\n  41. [200519 Regularization Methods for Generative Adversarial Networks](/rosinality/ml-papers/blob/main/papers/2020/200519%20Regularization%20Methods%20for%20Generative%20Adversarial%20Networks.md) #review #regularization\n  42. [200604 Image Augmentations for GAN Training](/rosinality/ml-papers/blob/main/papers/2020/200604%20Image%20Augmentations%20for%20GAN%20Training.md) #augmentation\n  43. [200611 Training Generative Adversarial Networks with Limited Data](/rosinality/ml-papers/blob/main/papers/2020/200611%20Training%20Generative%20Adversarial%20Networks%20with%20Limited%20Data.md) #augmentation\n  44. [200618 Differentiable Augmentation for Data-Efficient GAN Training](/rosinality/ml-papers/blob/main/papers/2020/200618%20Differentiable%20Augmentation%20for%20Data-Efficient%20GAN%20Training.md) #augmentation\n  45. [200618 Diverse Image Generation via Self-Conditioned GANs](/rosinality/ml-papers/blob/main/papers/2020/200618%20Diverse%20Image%20Generation%20via%20Self-Conditioned%20GANs.md) #generative_model\n  46. [200630 PriorGAN](/rosinality/ml-papers/blob/main/papers/2020/200630%20PriorGAN.md)\n  47. [200708 InfoMax-GAN](/rosinality/ml-papers/blob/main/papers/2020/200708%20InfoMax-GAN.md) #regularization\n  48. [200713 Closed-Form Factorization of Latent Semantics in GANs](/rosinality/ml-papers/blob/main/papers/2020/200713%20Closed-Form%20Factorization%20of%20Latent%20Semantics%20in%20GANs.md) #semantic_factor\n  49. [200729 Instance Selection for GANs](/rosinality/ml-papers/blob/main/papers/2020/200729%20Instance%20Selection%20for%20GANs.md)\n  50. [200729 VocGAN](/rosinality/ml-papers/blob/main/papers/2020/200729%20VocGAN.md) #vocoder\n  51. [200730 Rewriting a Deep Generative Model](/rosinality/ml-papers/blob/main/papers/2020/200730%20Rewriting%20a%20Deep%20Generative%20Model.md)\n  52. [200804 Open-Edit](/rosinality/ml-papers/blob/main/papers/2020/200804%20Open-Edit.md) #image_editing\n  53. [200807 Improving the Speed and Quality of GAN by Adversarial Training](/rosinality/ml-papers/blob/main/papers/2020/200807%20Improving%20the%20Speed%20and%20Quality%20of%20GAN%20by%20Adversarial%20Training.md) #robustness\n  54. [201028 Training Generative Adversarial Networks by Solving Ordinary](/rosinality/ml-papers/blob/main/papers/2020/201028%20Training%20Generative%20Adversarial%20Networks%20by%20Solving%20Ordinary.md) #neural_ode\n  55.", "start_char_idx": 83641, "end_char_idx": 86627, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3a006d69-c3e2-4b2d-9506-549de80c388a": {"__data__": {"id_": "3a006d69-c3e2-4b2d-9506-549de80c388a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "817185e1-164a-486b-9b0e-9001d23dd401", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "468368f50070fc963e7c89f223b727fc65f1d8ca7ee90a1e515f4d187312657d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0518ea29-c4d0-4724-b871-7ef6d8871a87", "node_type": "1", "metadata": {}, "hash": "34131138bd36d6df06e643f3325ec2fb83c18d8e73403f7cbd13ba5b659de9d3", "class_name": "RelatedNodeInfo"}}, "text": "[200804 Open-Edit](/rosinality/ml-papers/blob/main/papers/2020/200804%20Open-Edit.md) #image_editing\n  53. [200807 Improving the Speed and Quality of GAN by Adversarial Training](/rosinality/ml-papers/blob/main/papers/2020/200807%20Improving%20the%20Speed%20and%20Quality%20of%20GAN%20by%20Adversarial%20Training.md) #robustness\n  54. [201028 Training Generative Adversarial Networks by Solving Ordinary](/rosinality/ml-papers/blob/main/papers/2020/201028%20Training%20Generative%20Adversarial%20Networks%20by%20Solving%20Ordinary.md) #neural_ode\n  55. [201109 Learning Semantic-aware Normalization for Generative Adversarial Networks](/rosinality/ml-papers/blob/main/papers/2020/201109%20Learning%20Semantic-aware%20Normalization%20for%20Generative%20Adversarial%20Networks.md) #normalization\n  56. [201109 Towards a Better Global Loss Landscape of GANs](/rosinality/ml-papers/blob/main/papers/2020/201109%20Towards%20a%20Better%20Global%20Loss%20Landscape%20of%20GANs.md) #training\n  57. [201118 Style Intervention](/rosinality/ml-papers/blob/main/papers/2020/201118%20Style%20Intervention.md) #semantic_factor\n  58. [201124 Adversarial Generation of Continuous Images](/rosinality/ml-papers/blob/main/papers/2020/201124%20Adversarial%20Generation%20of%20Continuous%20Images.md) #implicit_representation\n  59. [201125 How to train your conditional GAN](/rosinality/ml-papers/blob/main/papers/2020/201125%20How%20to%20train%20your%20conditional%20GAN.md) #img2img #generative_model\n  60. [201125 Omni-GAN](/rosinality/ml-papers/blob/main/papers/2020/201125%20Omni-GAN.md) #generative_model\n  61. [201127 Image Generators with Conditionally-Independent Pixel Synthesis](/rosinality/ml-papers/blob/main/papers/2020/201127%20Image%20Generators%20with%20Conditionally-Independent%20Pixel%20Synthesis.md) #implicit_representation\n  62. [201201 Refining Deep Generative Models via Discriminator Gradient Flow](/rosinality/ml-papers/blob/main/papers/2020/201201%20Refining%20Deep%20Generative%20Models%20via%20Discriminator%20Gradient%20Flow.md) #sampling\n  63. [201201 pi-GAN](/rosinality/ml-papers/blob/main/papers/2020/201201%20pi-GAN.md) #implicit_representation\n  64. [201203 Self-labeled Conditional GANs](/rosinality/ml-papers/blob/main/papers/2020/201203%20Self-labeled%20Conditional%20GANs.md) #unsupervised_training\n  65. [201204 A Note on Data Biases in Generative Models](/rosinality/ml-papers/blob/main/papers/2020/201204%20A%20Note%20on%20Data%20Biases%20in%20Generative%20Models.md) #bias #generative_model\n  66. [201208 You Only Need Adversarial Supervision for Semantic Image Synthesis](/rosinality/ml-papers/blob/main/papers/2020/201208%20You%20Only%20Need%20Adversarial%20Supervision%20for%20Semantic%20Image%20Synthesis.md) #img2img\n  67. [210227 Ultra-Data-Efficient GAN Training](/rosinality/ml-papers/blob/main/papers/2021/210227%20Ultra-Data-Efficient%20GAN%20Training.md) #augmentation #few_shot\n  68.", "start_char_idx": 86075, "end_char_idx": 88995, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0518ea29-c4d0-4724-b871-7ef6d8871a87": {"__data__": {"id_": "0518ea29-c4d0-4724-b871-7ef6d8871a87", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a006d69-c3e2-4b2d-9506-549de80c388a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "31fbe1a49e8abc6e1f3849dcedfbf534e1be63841730ed18e925a6441759dded", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5b6693e2-a5f7-4b04-86d6-eabe2d477c67", "node_type": "1", "metadata": {}, "hash": "39646902564ffd28a4f32801bc42c801362e4f5e6f4ef89f39bf27c1ca4c5efb", "class_name": "RelatedNodeInfo"}}, "text": "[201208 You Only Need Adversarial Supervision for Semantic Image Synthesis](/rosinality/ml-papers/blob/main/papers/2020/201208%20You%20Only%20Need%20Adversarial%20Supervision%20for%20Semantic%20Image%20Synthesis.md) #img2img\n  67. [210227 Ultra-Data-Efficient GAN Training](/rosinality/ml-papers/blob/main/papers/2021/210227%20Ultra-Data-Efficient%20GAN%20Training.md) #augmentation #few_shot\n  68. [210317 Training GANs with Stronger Augmentations via Contrastive Discriminator](/rosinality/ml-papers/blob/main/papers/2021/210317%20Training%20GANs%20with%20Stronger%20Augmentations%20via%20Contrastive%20Discriminator.md) #contrastive_learning #augmentation\n  69. [210318 Drop the GAN](/rosinality/ml-papers/blob/main/papers/2021/210318%20Drop%20the%20GAN.md) #single_image #generative_model #patch\n  70. [210330 Dual Contrastive Loss and Attention for GANs](/rosinality/ml-papers/blob/main/papers/2021/210330%20Dual%20Contrastive%20Loss%20and%20Attention%20for%20GANs.md) #contrastive_learning\n  71. [210401 Partition-Guided GANs](/rosinality/ml-papers/blob/main/papers/2021/210401%20Partition-Guided%20GANs.md)\n  72. [210407 Regularizing Generative Adversarial Networks under Limited Data](/rosinality/ml-papers/blob/main/papers/2021/210407%20Regularizing%20Generative%20Adversarial%20Networks%20under%20Limited%20Data.md) #regularization\n  73. [210408 InfinityGAN](/rosinality/ml-papers/blob/main/papers/2021/210408%20InfinityGAN.md)\n  74. [210413 DatasetGAN](/rosinality/ml-papers/blob/main/papers/2021/210413%20DatasetGAN.md) #few_shot\n  75. [210413 Few-shot Image Generation via Cross-domain Correspondence](/rosinality/ml-papers/blob/main/papers/2021/210413%20Few-shot%20Image%20Generation%20via%20Cross-domain%20Correspondence.md) #img2img #generative_model #few_shot\n  76. [210414 Aligning Latent and Image Spaces to Connect the Unconnectable](/rosinality/ml-papers/blob/main/papers/2021/210414%20Aligning%20Latent%20and%20Image%20Spaces%20to%20Connect%20the%20Unconnectable.md)\n  77. [210415 GANcraft](/rosinality/ml-papers/blob/main/papers/2021/210415%20GANcraft.md) #nerf\n  78. [210422 On Buggy Resizing Libraries and Surprising Subtleties in FID Calculation](/rosinality/ml-papers/blob/main/papers/2021/210422%20On%20Buggy%20Resizing%20Libraries%20and%20Surprising%20Subtleties%20in%20FID%20Calculation.md) #antialiasing\n  79. [210426 EigenGAN](/rosinality/ml-papers/blob/main/papers/2021/210426%20EigenGAN.md) #semantic_factor\n  80. [210608 Data-Efficient Instance Generation from Instance Discrimination](/rosinality/ml-papers/blob/main/papers/2021/210608%20Data-Efficient%20Instance%20Generation%20from%20Instance%20Discrimination.md) #contrastive_learning\n  81. [210614 Improved Transformer for High-Resolution GANs](/rosinality/ml-papers/blob/main/papers/2021/210614%20Improved%20Transformer%20for%20High-Resolution%20GANs.md) #transformer #efficient_training\n  82. [210623 Alias-Free Generative Adversarial Networks](/rosinality/ml-papers/blob/main/papers/2021/210623%20Alias-Free%20Generative%20Adversarial%20Networks.md) #antialiasing\n  83.", "start_char_idx": 88597, "end_char_idx": 91659, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b6693e2-a5f7-4b04-86d6-eabe2d477c67": {"__data__": {"id_": "5b6693e2-a5f7-4b04-86d6-eabe2d477c67", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0518ea29-c4d0-4724-b871-7ef6d8871a87", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ad38f82b0968d78b9c1629c94e231b819246da0697726d7a48f6bf7e44b47791", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "06d50fc6-c953-4536-bd20-2aac0f5a1f15", "node_type": "1", "metadata": {}, "hash": "671f9f432331b95b0f9332e5aeb4f2ce34053bbe2b9ff2f3f8c0517da9156abe", "class_name": "RelatedNodeInfo"}}, "text": "[210608 Data-Efficient Instance Generation from Instance Discrimination](/rosinality/ml-papers/blob/main/papers/2021/210608%20Data-Efficient%20Instance%20Generation%20from%20Instance%20Discrimination.md) #contrastive_learning\n  81. [210614 Improved Transformer for High-Resolution GANs](/rosinality/ml-papers/blob/main/papers/2021/210614%20Improved%20Transformer%20for%20High-Resolution%20GANs.md) #transformer #efficient_training\n  82. [210623 Alias-Free Generative Adversarial Networks](/rosinality/ml-papers/blob/main/papers/2021/210623%20Alias-Free%20Generative%20Adversarial%20Networks.md) #antialiasing\n  83. [210910 Instance-Conditioned GAN](/rosinality/ml-papers/blob/main/papers/2021/210910%20Instance-Conditioned%20GAN.md)\n  84. [210927 WarpedGANSpace](/rosinality/ml-papers/blob/main/papers/2021/210927%20WarpedGANSpace.md)\n  85. [211017 AE-StyleGAN](/rosinality/ml-papers/blob/main/papers/2021/211017%20AE-StyleGAN.md) #gan_inversion\n  86. [211101 Projected GANs Converge Faster](/rosinality/ml-papers/blob/main/papers/2021/211101%20Projected%20GANs%20Converge%20Faster.md)\n  87. [211215 Efficient Geometry-aware 3D Generative Adversarial Networks](/rosinality/ml-papers/blob/main/papers/2021/211215%20Efficient%20Geometry-aware%203D%20Generative%20Adversarial%20Networks.md) #nerf\n  88. [211216 GRAM](/rosinality/ml-papers/blob/main/papers/2021/211216%20GRAM.md) #3d_generative_model #nerf\n  89. [220201 StyleGAN-XL](/rosinality/ml-papers/blob/main/papers/2022/220201%20StyleGAN-XL.md)\n  90. [220219 Truncated Diffusion Probabilistic Models](/rosinality/ml-papers/blob/main/papers/2022/220219%20Truncated%20Diffusion%20Probabilistic%20Models.md) #generative_model #ddpm\n  91. [220224 Self-Distilled StyleGAN](/rosinality/ml-papers/blob/main/papers/2022/220224%20Self-Distilled%20StyleGAN.md)\n  92. [220311 The Role of ImageNet Classes in Fr\u00e9chet Inception Distance](/rosinality/ml-papers/blob/main/papers/2022/220311%20The%20Role%20of%20ImageNet%20Classes%20in%20Fr%C3%A9chet%20Inception%20Distance.md)\n  93. [220314 InsetGAN for Full-Body Image Generation](/rosinality/ml-papers/blob/main/papers/2022/220314%20InsetGAN%20for%20Full-Body%20Image%20Generation.md) #pose\n  94. [220414 Any-resolution Training for High-resolution Image Synthesis](/rosinality/ml-papers/blob/main/papers/2022/220414%20Any-resolution%20Training%20for%20High-resolution%20Image%20Synthesis.md)\n  95. [230123 StyleGAN-T](/rosinality/ml-papers/blob/main/papers/2023/230123%20StyleGAN-T.md) #text2img\n  96. [230309 Scaling up GANs for Text-to-Image Synthesis](/rosinality/ml-papers/blob/main/papers/2023/230309%20Scaling%20up%20GANs%20for%20Text-to-Image%20Synthesis.md) #text2img\n\n## gan inversion\n\n  1. [200330 Exploiting Deep Generative Prior for Versatile Image Restoration and](/rosinality/ml-papers/blob/main/papers/2020/200330%20Exploiting%20Deep%20Generative%20Prior%20for%20Versatile%20Image%20Restoration%20and.md) #perceptual_loss\n  2.", "start_char_idx": 91045, "end_char_idx": 93978, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "06d50fc6-c953-4536-bd20-2aac0f5a1f15": {"__data__": {"id_": "06d50fc6-c953-4536-bd20-2aac0f5a1f15", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5b6693e2-a5f7-4b04-86d6-eabe2d477c67", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "13c6bd6d1897a9a393fcb5751267a0c15775385bd004594936356845c9031c93", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8056d1a5-acb6-4b4a-8b6b-a230a1d06c92", "node_type": "1", "metadata": {}, "hash": "08ec80e8f6ed434e092b7b321e7c2bf11142cbfd083955e64e0d4c39917323c3", "class_name": "RelatedNodeInfo"}}, "text": "[230123 StyleGAN-T](/rosinality/ml-papers/blob/main/papers/2023/230123%20StyleGAN-T.md) #text2img\n  96. [230309 Scaling up GANs for Text-to-Image Synthesis](/rosinality/ml-papers/blob/main/papers/2023/230309%20Scaling%20up%20GANs%20for%20Text-to-Image%20Synthesis.md) #text2img\n\n## gan inversion\n\n  1. [200330 Exploiting Deep Generative Prior for Versatile Image Restoration and](/rosinality/ml-papers/blob/main/papers/2020/200330%20Exploiting%20Deep%20Generative%20Prior%20for%20Versatile%20Image%20Restoration%20and.md) #perceptual_loss\n  2. [200331 In-Domain GAN Inversion for Real Image Editing](/rosinality/ml-papers/blob/main/papers/2020/200331%20In-Domain%20GAN%20Inversion%20for%20Real%20Image%20Editing.md)\n  3. [200703 Collaborative Learning for Faster StyleGAN Embedding](/rosinality/ml-papers/blob/main/papers/2020/200703%20Collaborative%20Learning%20for%20Faster%20StyleGAN%20Embedding.md)\n  4. [200803 Encoding in Style](/rosinality/ml-papers/blob/main/papers/2020/200803%20Encoding%20in%20Style.md) #stylegan\n  5. [220223 Near Perfect GAN Inversion](/rosinality/ml-papers/blob/main/papers/2022/220223%20Near%20Perfect%20GAN%20Inversion.md)\n\n## generalization\n\n  1. [200130 Fantastic Generalization Measures](/rosinality/ml-papers/blob/main/papers/2020/200130%20Fantastic%20Generalization%20Measures.md)\n  2. [200225 Rethinking Bias-Variance Trade-off for Generalization of Neural Networks](/rosinality/ml-papers/blob/main/papers/2020/200225%20Rethinking%20Bias-Variance%20Trade-off%20for%20Generalization%20of%20Neural%20Networks.md)\n\n## generative model\n\n  1. [190325 Implicit Generative and Generalization in Energy-Based Models](/rosinality/ml-papers/blob/main/papers/2019/190325%20Implicit%20Generative%20and%20Generalization%20in%20Energy-Based%20Models.md) #energy_based_model\n  2. [200129 Controlling Generative Model](/rosinality/ml-papers/blob/main/papers/2020/200129%20Controlling%20Generative%20Model.md)\n  3. [200129 Deep Automodulator](/rosinality/ml-papers/blob/main/papers/2020/200129%20Deep%20Automodulator.md)\n  4. [200129 Frechet Joint Distance](/rosinality/ml-papers/blob/main/papers/2020/200129%20Frechet%20Joint%20Distance.md)\n  5. [200129 Spot CNN generated image](/rosinality/ml-papers/blob/main/papers/2020/200129%20Spot%20CNN%20generated%20image.md)\n  6. [200130 BIVA](/rosinality/ml-papers/blob/main/papers/2020/200130%20BIVA.md)\n  7. [200130 Glow](/rosinality/ml-papers/blob/main/papers/2020/200130%20Glow.md) #flow\n  8. [200130 IGEBM](/rosinality/ml-papers/blob/main/papers/2020/200130%20IGEBM.md) #energy_based_model\n  9. [200130 Neural Spline Flows](/rosinality/ml-papers/blob/main/papers/2020/200130%20Neural%20Spline%20Flows.md) #flow\n  10. [200130 VQ-VAE-2](/rosinality/ml-papers/blob/main/papers/2020/200130%20VQ-VAE-2.md) #autoregressive_model\n  11.", "start_char_idx": 93435, "end_char_idx": 96234, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8056d1a5-acb6-4b4a-8b6b-a230a1d06c92": {"__data__": {"id_": "8056d1a5-acb6-4b4a-8b6b-a230a1d06c92", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "06d50fc6-c953-4536-bd20-2aac0f5a1f15", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "fbfbd1434f3e600b85884ae5452e1d76c051cf55e28ada2a4761139e3d3c5cd5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b63f9e37-bec9-4009-89f1-2c806e26e0ef", "node_type": "1", "metadata": {}, "hash": "626b925f7a557aa5c20740b211270bcdb8b0f30ea60249d47d45a930b5c829bb", "class_name": "RelatedNodeInfo"}}, "text": "[200130 Glow](/rosinality/ml-papers/blob/main/papers/2020/200130%20Glow.md) #flow\n  8. [200130 IGEBM](/rosinality/ml-papers/blob/main/papers/2020/200130%20IGEBM.md) #energy_based_model\n  9. [200130 Neural Spline Flows](/rosinality/ml-papers/blob/main/papers/2020/200130%20Neural%20Spline%20Flows.md) #flow\n  10. [200130 VQ-VAE-2](/rosinality/ml-papers/blob/main/papers/2020/200130%20VQ-VAE-2.md) #autoregressive_model\n  11. [200217 Augmented Normalizing Flows](/rosinality/ml-papers/blob/main/papers/2020/200217%20Augmented%20Normalizing%20Flows.md) #flow\n  12. [200313 Semantic Pyramid for Image Generation](/rosinality/ml-papers/blob/main/papers/2020/200313%20Semantic%20Pyramid%20for%20Image%20Generation.md) #perceptual_loss #image_editing\n  13. [200616 Improved Techniques for Training Score-Based Generative Models](/rosinality/ml-papers/blob/main/papers/2020/200616%20Improved%20Techniques%20for%20Training%20Score-Based%20Generative%20Models.md) #ncsn\n  14. [201117 DeepNAG](/rosinality/ml-papers/blob/main/papers/2020/201117%20DeepNAG.md)\n  15. [201202 Improved Contrastive Divergence Training of Energy Based Models](/rosinality/ml-papers/blob/main/papers/2020/201202%20Improved%20Contrastive%20Divergence%20Training%20of%20Energy%20Based%20Models.md) #energy_based_model\n  16. [201204 Few-shot Image Generation with Elastic Weight Consolidation](/rosinality/ml-papers/blob/main/papers/2020/201204%20Few-shot%20Image%20Generation%20with%20Elastic%20Weight%20Consolidation.md) #few_shot #continual_learning\n  17. [201209 Positional Encoding as Spatial Inductive Bias in GANs](/rosinality/ml-papers/blob/main/papers/2020/201209%20Positional%20Encoding%20as%20Spatial%20Inductive%20Bias%20in%20GANs.md) #positional_encoding\n  18. [201224 Soft-IntroVAE](/rosinality/ml-papers/blob/main/papers/2020/201224%20Soft-IntroVAE.md) #vae\n  19. [210223 Zero-Shot Text-to-Image Generation](/rosinality/ml-papers/blob/main/papers/2021/210223%20Zero-Shot%20Text-to-Image%20Generation.md) #discrete_vae #autoregressive_model #multimodal\n  20. [210318 Few-shot Semantic Image Synthesis Using StyleGAN Prior](/rosinality/ml-papers/blob/main/papers/2021/210318%20Few-shot%20Semantic%20Image%20%20Synthesis%20Using%20StyleGAN%20Prior.md) #stylegan #few_shot\n  21. [210824 SimVLM](/rosinality/ml-papers/blob/main/papers/2021/210824%20SimVLM.md) #vision-language\n  22. [211015 MaGNET](/rosinality/ml-papers/blob/main/papers/2021/211015%20MaGNET.md) #sampling\n  23. [220208 MaskGIT](/rosinality/ml-papers/blob/main/papers/2022/220208%20MaskGIT.md) #autoregressive_model #non-autoregressive #vq\n\n## graph\n\n  1. [200129 Multi-Graph Transformer](/rosinality/ml-papers/blob/main/papers/2020/200129%20Multi-Graph%20Transformer.md)\n\n## hallucination\n\n  1.", "start_char_idx": 95811, "end_char_idx": 98546, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b63f9e37-bec9-4009-89f1-2c806e26e0ef": {"__data__": {"id_": "b63f9e37-bec9-4009-89f1-2c806e26e0ef", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8056d1a5-acb6-4b4a-8b6b-a230a1d06c92", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "130ef631415cb0abc9f55922be41fbce834f238856f0741bdfd8ed4b1d97468f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "034583f6-3a9c-4af9-a591-877e506b3c1c", "node_type": "1", "metadata": {}, "hash": "6d8babeb4dd42b14d04b336eb30dbdb069fe80dc7972bb91bcc1e445baf5567a", "class_name": "RelatedNodeInfo"}}, "text": "[210824 SimVLM](/rosinality/ml-papers/blob/main/papers/2021/210824%20SimVLM.md) #vision-language\n  22. [211015 MaGNET](/rosinality/ml-papers/blob/main/papers/2021/211015%20MaGNET.md) #sampling\n  23. [220208 MaskGIT](/rosinality/ml-papers/blob/main/papers/2022/220208%20MaskGIT.md) #autoregressive_model #non-autoregressive #vq\n\n## graph\n\n  1. [200129 Multi-Graph Transformer](/rosinality/ml-papers/blob/main/papers/2020/200129%20Multi-Graph%20Transformer.md)\n\n## hallucination\n\n  1. [210413 The Curious Case of Hallucinations in Neural Machine Translation](/rosinality/ml-papers/blob/main/papers/2021/210413%20The%20Curious%20Case%20of%20Hallucinations%20in%20Neural%20Machine%20Translation.md) #mt\n\n## hypernetwork\n\n  1. [200722 WeightNet](/rosinality/ml-papers/blob/main/papers/2020/200722%20WeightNet.md) #channel_attention\n\n## hyperparameter\n\n  1. [200425 Learning to Guide Random Search](/rosinality/ml-papers/blob/main/papers/2020/200425%20Learning%20to%20Guide%20Random%20Search.md)\n  2. [200521 HyperSTAR](/rosinality/ml-papers/blob/main/papers/2020/200521%20HyperSTAR.md)\n\n## identifiability\n\n  1. [200701 On Linear Identifiability of Learned Representations](/rosinality/ml-papers/blob/main/papers/2020/200701%20On%20Linear%20Identifiability%20of%20Learned%20Representations.md)\n\n## image editing\n\n  1. [200515 Semantic Photo Manipulation with a Generative Image Prior](/rosinality/ml-papers/blob/main/papers/2020/200515%20Semantic%20Photo%20Manipulation%20with%20a%20Generative%20Image%20Prior.md)\n  2. [200702 Deep Single Image Manipulation](/rosinality/ml-papers/blob/main/papers/2020/200702%20Deep%20Single%20Image%20Manipulation.md) #single_image #img2img\n  3. [201123 HistoGAN](/rosinality/ml-papers/blob/main/papers/2020/201123%20HistoGAN.md)\n  4. [201127 Navigating the GAN Parameter Space for Semantic Image Editing](/rosinality/ml-papers/blob/main/papers/2020/201127%20Navigating%20the%20GAN%20Parameter%20Space%20for%20Semantic%20Image%20Editing.md) #semantic_factor\n  5. [210318 Using latent space regression to analyze and leverage compositionality](/rosinality/ml-papers/blob/main/papers/2021/210318%20Using%20latent%20space%20regression%20to%20analyze%20and%20leverage%20compositionality.md)\n  6. [220531 IDE-3D](/rosinality/ml-papers/blob/main/papers/2022/220531%20IDE-3D.md) #3d_generative_model\n  7. [220802 An Image is Worth One Word](/rosinality/ml-papers/blob/main/papers/2022/220802%20An%20Image%20is%20Worth%20One%20Word.md)\n  8. [220802 Prompt-to-Prompt Image Editing with Cross Attention Control](/rosinality/ml-papers/blob/main/papers/2022/220802%20Prompt-to-Prompt%20Image%20Editing%20with%20Cross%20Attention%20Control.md)\n  9. [230202 Dreamix](/rosinality/ml-papers/blob/main/papers/2023/230202%20Dreamix.md) #video\n  10. [230213 3D-aware Blending with Generative NeRFs](/rosinality/ml-papers/blob/main/papers/2023/230213%203D-aware%20Blending%20with%20Generative%20NeRFs.md) #3d_generative_model\n  11.", "start_char_idx": 98064, "end_char_idx": 101005, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "034583f6-3a9c-4af9-a591-877e506b3c1c": {"__data__": {"id_": "034583f6-3a9c-4af9-a591-877e506b3c1c", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b63f9e37-bec9-4009-89f1-2c806e26e0ef", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "97dc936ddd7ad15a4fbb0a8573e94d7b8baf81315568fd38047a60df2e0682b7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c407867-9246-4b9e-9d39-f641013f4422", "node_type": "1", "metadata": {}, "hash": "3982e133f496f43ff4dc0ff6d37ae761cee6c01a79c48e913d33c85fdafdb7fa", "class_name": "RelatedNodeInfo"}}, "text": "[220802 Prompt-to-Prompt Image Editing with Cross Attention Control](/rosinality/ml-papers/blob/main/papers/2022/220802%20Prompt-to-Prompt%20Image%20Editing%20with%20Cross%20Attention%20Control.md)\n  9. [230202 Dreamix](/rosinality/ml-papers/blob/main/papers/2023/230202%20Dreamix.md) #video\n  10. [230213 3D-aware Blending with Generative NeRFs](/rosinality/ml-papers/blob/main/papers/2023/230213%203D-aware%20Blending%20with%20Generative%20NeRFs.md) #3d_generative_model\n  11. [230626 DragDiffusion](/rosinality/ml-papers/blob/main/papers/2023/230626%20DragDiffusion.md)\n  12. [230626 Localized Text-to-Image Generation for Free via Cross Attention Control](/rosinality/ml-papers/blob/main/papers/2023/230626%20Localized%20Text-to-Image%20Generation%20for%20Free%20via%20Cross%20Attention%20Control.md) #text2img\n  13. [230705 DragonDiffusion](/rosinality/ml-papers/blob/main/papers/2023/230705%20DragonDiffusion.md)\n\n## image generation\n\n  1. [200426 Disentangled Image Generation Through Structured Noise Injection](/rosinality/ml-papers/blob/main/papers/2020/200426%20Disentangled%20Image%20Generation%20Through%20Structured%20Noise%20Injection.md)\n\n## img2img\n\n  1. [200130 FUNIT](/rosinality/ml-papers/blob/main/papers/2020/200130%20FUNIT.md)\n  2. [200305 SketchyCOCO](/rosinality/ml-papers/blob/main/papers/2020/200305%20SketchyCOCO.md)\n  3. [200315 GMM-UNIT](/rosinality/ml-papers/blob/main/papers/2020/200315%20GMM-UNIT.md) #multimodal_generation\n  4. [200319 High-Resolution Daytime Translation Without Domain Labels](/rosinality/ml-papers/blob/main/papers/2020/200319%20High-Resolution%20Daytime%20Translation%20Without%20Domain%20Labels.md)\n  5. [200330 Semi-supervised Learning for Few-shot Image-to-Image Translation](/rosinality/ml-papers/blob/main/papers/2020/200330%20Semi-supervised%20Learning%20for%20Few-shot%20Image-to-Image%20Translation.md) #semi_supervised_learning #few_shot\n  6. [200406 Rethinking Spatially-Adaptive Normalization](/rosinality/ml-papers/blob/main/papers/2020/200406%20Rethinking%20Spatially-Adaptive%20Normalization.md) #lightweight\n  7. [200409 TuiGAN](/rosinality/ml-papers/blob/main/papers/2020/200409%20TuiGAN.md) #few_shot #single_image\n  8. [200419 TriGAN](/rosinality/ml-papers/blob/main/papers/2020/200419%20TriGAN.md) #domain_adaptation\n  9. [200709 Improving Style-Content Disentanglement in Image-to-Image Translation](/rosinality/ml-papers/blob/main/papers/2020/200709%20Improving%20Style-Content%20Disentanglement%20in%20Image-to-Image%20Translation.md) #disentangle\n  10. [200714 COCO-FUNIT](/rosinality/ml-papers/blob/main/papers/2020/200714%20COCO-FUNIT.md)\n  11. [200715 Transformation Consistency Regularization- A Semi-Supervised Paradigm](/rosinality/ml-papers/blob/main/papers/2020/200715%20Transformation%20Consistency%20Regularization-%20A%20Semi-Supervised%20Paradigm.md) #augmentation #semi_supervised_learning\n  12. [200723 TSIT](/rosinality/ml-papers/blob/main/papers/2020/200723%20TSIT.md)\n  13.", "start_char_idx": 100527, "end_char_idx": 103494, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8c407867-9246-4b9e-9d39-f641013f4422": {"__data__": {"id_": "8c407867-9246-4b9e-9d39-f641013f4422", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "034583f6-3a9c-4af9-a591-877e506b3c1c", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "a55fdf4f2aa4e2b4b5243c10c8ce927a4752c8a0251427786cf05ece28668ed3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c4cc42aa-331e-4ba2-aabd-b13525f0ef49", "node_type": "1", "metadata": {}, "hash": "d220f29edf37db28462ba851ff43025e5fce18c7381293dfd4f2c133dec0ef7d", "class_name": "RelatedNodeInfo"}}, "text": "[200714 COCO-FUNIT](/rosinality/ml-papers/blob/main/papers/2020/200714%20COCO-FUNIT.md)\n  11. [200715 Transformation Consistency Regularization- A Semi-Supervised Paradigm](/rosinality/ml-papers/blob/main/papers/2020/200715%20Transformation%20Consistency%20Regularization-%20A%20Semi-Supervised%20Paradigm.md) #augmentation #semi_supervised_learning\n  12. [200723 TSIT](/rosinality/ml-papers/blob/main/papers/2020/200723%20TSIT.md)\n  13. [200724 The Surprising Effectiveness of Linear Unsupervised Image-to-Image](/rosinality/ml-papers/blob/main/papers/2020/200724%20The%20Surprising%20Effectiveness%20of%20Linear%20Unsupervised%20Image-to-Image.md)\n  14. [201203 CoCosNet v2](/rosinality/ml-papers/blob/main/papers/2020/201203%20CoCosNet%20v2.md) #patch #pose\n  15. [201205 Spatially-Adaptive Pixelwise Networks for Fast Image Translation](/rosinality/ml-papers/blob/main/papers/2020/201205%20Spatially-Adaptive%20Pixelwise%20Networks%20for%20Fast%20Image%20Translation.md) #implicit_representation\n\n## implicit model\n\n  1. [200615 Multiscale Deep Equilibrium Models](/rosinality/ml-papers/blob/main/papers/2020/200615%20Multiscale%20Deep%20Equilibrium%20Models.md)\n\n## implicit representation\n\n  1. [211026 NeRV](/rosinality/ml-papers/blob/main/papers/2021/211026%20NeRV.md)\n  2. [211122 Neural Fields in Visual Computing and Beyond](/rosinality/ml-papers/blob/main/papers/2021/211122%20Neural%20Fields%20in%20Visual%20Computing%20and%20Beyond.md)\n  3. [220117 Instant Neural Graphics Primitives with a Multiresolution Hash Encoding](/rosinality/ml-papers/blob/main/papers/2022/220117%20Instant%20Neural%20Graphics%20Primitives%20with%20a%20Multiresolution%20Hash%20Encoding.md)\n  4. [220522 ReLU Fields](/rosinality/ml-papers/blob/main/papers/2022/220522%20ReLU%20Fields.md)\n  5. [230202 Factor Fields](/rosinality/ml-papers/blob/main/papers/2023/230202%20Factor%20Fields.md)\n\n## in context learning\n\n  1. [220520 Prototypical Calibration for Few-shot Learning of Language Models](/rosinality/ml-papers/blob/main/papers/2022/220520%20Prototypical%20Calibration%20for%20Few-shot%20Learning%20of%20Language%20Models.md)\n  2. [220522 Instruction Induction](/rosinality/ml-papers/blob/main/papers/2022/220522%20Instruction%20Induction.md)\n  3. [230613 TART](/rosinality/ml-papers/blob/main/papers/2023/230613%20TART.md)\n\n## instance segmentation\n\n  1. [200129 BlendMask](/rosinality/ml-papers/blob/main/papers/2020/200129%20BlendMask.md)\n  2. [200129 COCO 2018 Instance Segmentation](/rosinality/ml-papers/blob/main/papers/2020/200129%20COCO%202018%20Instance%20Segmentation.md) #challenge\n  3. [200129 Deep Snake](/rosinality/ml-papers/blob/main/papers/2020/200129%20Deep%20Snake.md)\n  4. [200130 PointRend](/rosinality/ml-papers/blob/main/papers/2020/200130%20PointRend.md)\n  5. [200311 Conditional Convolutions for Instance Segmentation](/rosinality/ml-papers/blob/main/papers/2020/200311%20Conditional%20Convolutions%20for%20Instance%20Segmentation.md)\n  6.", "start_char_idx": 103057, "end_char_idx": 106017, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c4cc42aa-331e-4ba2-aabd-b13525f0ef49": {"__data__": {"id_": "c4cc42aa-331e-4ba2-aabd-b13525f0ef49", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c407867-9246-4b9e-9d39-f641013f4422", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "82079e7484bb38a2cedb32696f06f2e0397867be779ba8c41ecd6f7b12f47b92", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f16f8843-d47c-4911-adda-d35456826266", "node_type": "1", "metadata": {}, "hash": "bd603a9dbe8a582ff9268d8adb372ced4b5746ef92017450a0e2238c1f83beb0", "class_name": "RelatedNodeInfo"}}, "text": "[200129 COCO 2018 Instance Segmentation](/rosinality/ml-papers/blob/main/papers/2020/200129%20COCO%202018%20Instance%20Segmentation.md) #challenge\n  3. [200129 Deep Snake](/rosinality/ml-papers/blob/main/papers/2020/200129%20Deep%20Snake.md)\n  4. [200130 PointRend](/rosinality/ml-papers/blob/main/papers/2020/200130%20PointRend.md)\n  5. [200311 Conditional Convolutions for Instance Segmentation](/rosinality/ml-papers/blob/main/papers/2020/200311%20Conditional%20Convolutions%20for%20Instance%20Segmentation.md)\n  6. [200313 PointINS](/rosinality/ml-papers/blob/main/papers/2020/200313%20PointINS.md) #dynamic_conv\n  7. [200722 Deep Variational Instance Segmentation](/rosinality/ml-papers/blob/main/papers/2020/200722%20Deep%20Variational%20Instance%20Segmentation.md)\n  8. [200730 LevelSet R-CNN](/rosinality/ml-papers/blob/main/papers/2020/200730%20LevelSet%20R-CNN.md)\n  9. [201119 DCT-Mask](/rosinality/ml-papers/blob/main/papers/2020/201119%20DCT-Mask.md)\n  10. [201119 Unifying Instance and Panoptic Segmentation with Dynamic Rank-1](/rosinality/ml-papers/blob/main/papers/2020/201119%20Unifying%20Instance%20and%20Panoptic%20Segmentation%20with%20Dynamic%20Rank-1.md) #panoptic_segmentation #dynamic_conv\n  11. [201126 The Devil is in the Boundary](/rosinality/ml-papers/blob/main/papers/2020/201126%20The%20Devil%20is%20in%20the%20Boundary.md)\n  12. [201129 End-to-End Video Instance Segmentation with Transformers](/rosinality/ml-papers/blob/main/papers/2020/201129%20End-to-End%20Video%20Instance%20Segmentation%20with%20Transformers.md) #end2end #detr #video\n  13. [201203 BoxInst](/rosinality/ml-papers/blob/main/papers/2020/201203%20BoxInst.md) #dataset #weak_supervision\n  14. [210503 ISTR](/rosinality/ml-papers/blob/main/papers/2021/210503%20ISTR.md) #end2end\n  15. [210505 QueryInst](/rosinality/ml-papers/blob/main/papers/2021/210505%20QueryInst.md) #end2end\n  16. [210604 SOLQ](/rosinality/ml-papers/blob/main/papers/2021/210604%20SOLQ.md)\n  17. [210713 Per-Pixel Classification is Not All You Need for Semantic Segmentation](/rosinality/ml-papers/blob/main/papers/2021/210713%20Per-Pixel%20Classification%20is%20Not%20All%20You%20Need%20for%20Semantic%20Segmentation.md) #panoptic_segmentation #semantic_segmentation #detr\n  18. [221110 OneFormer](/rosinality/ml-papers/blob/main/papers/2022/221110%20OneFormer.md) #semantic_segmentation #panoptic_segmentation #detr\n\n## instruct\n\n  1. [230131 The Flan Collection](/rosinality/ml-papers/blob/main/papers/2023/230131%20The%20Flan%20Collection.md)\n  2. [230210 The Wisdom of Hindsight Makes Language Models Better Instruction Followers](/rosinality/ml-papers/blob/main/papers/2023/230210%20The%20Wisdom%20of%20Hindsight%20Makes%20Language%20Models%20Better%20Instruction%20Followers.md) #reinforcement_learning\n  3. [230406 Instruction Tuning with GPT-4](/rosinality/ml-papers/blob/main/papers/2023/230406%20Instruction%20Tuning%20with%20GPT-4.md)\n  4.", "start_char_idx": 105499, "end_char_idx": 108422, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f16f8843-d47c-4911-adda-d35456826266": {"__data__": {"id_": "f16f8843-d47c-4911-adda-d35456826266", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c4cc42aa-331e-4ba2-aabd-b13525f0ef49", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "f01dc57defe04f0f88ddbc55009df3a7d32a5aa0c0c3ec7f7ef8a97d1e40bae3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8d20577f-cabf-4d27-97d3-579525727cda", "node_type": "1", "metadata": {}, "hash": "96efd047ba67b8000bbb05321aecd494be142646daa607c13e2c2b7b39141da1", "class_name": "RelatedNodeInfo"}}, "text": "[230131 The Flan Collection](/rosinality/ml-papers/blob/main/papers/2023/230131%20The%20Flan%20Collection.md)\n  2. [230210 The Wisdom of Hindsight Makes Language Models Better Instruction Followers](/rosinality/ml-papers/blob/main/papers/2023/230210%20The%20Wisdom%20of%20Hindsight%20Makes%20Language%20Models%20Better%20Instruction%20Followers.md) #reinforcement_learning\n  3. [230406 Instruction Tuning with GPT-4](/rosinality/ml-papers/blob/main/papers/2023/230406%20Instruction%20Tuning%20with%20GPT-4.md)\n  4. [230704 Instruction Tuning Review](/rosinality/ml-papers/blob/main/papers/2023/230704%20Instruction%20Tuning%20Review.md)\n\n## interpolation\n\n  1. [200804 Autoencoder Image Interpolation by Shaping the Latent Space](/rosinality/ml-papers/blob/main/papers/2020/200804%20Autoencoder%20Image%20Interpolation%20by%20Shaping%20the%20Latent%20Space.md)\n  2. [211018 Learning in High Dimension Always Amounts to Extrapolation](/rosinality/ml-papers/blob/main/papers/2021/211018%20Learning%20in%20High%20Dimension%20Always%20Amounts%20to%20Extrapolation.md) #extrapolation\n\n## knowledge base\n\n  1. [200214 Scalable Neural Methods for Reasoning With a Symbolic Knowledge Base](/rosinality/ml-papers/blob/main/papers/2020/200214%20Scalable%20Neural%20Methods%20for%20Reasoning%20With%20a%20Symbolic%20Knowledge%20Base.md)\n\n## language generation\n\n  1. [200712 Do You Have the Right Scissors](/rosinality/ml-papers/blob/main/papers/2020/200712%20Do%20You%20Have%20the%20Right%20Scissors.md)\n  2. [200729 Mirostat](/rosinality/ml-papers/blob/main/papers/2020/200729%20Mirostat.md)\n\n## language model\n\n  1. [200128 Scaling Laws for LM](/rosinality/ml-papers/blob/main/papers/2020/200128%20Scaling%20Laws%20for%20LM.md)\n  2. [200205 K-Adapter](/rosinality/ml-papers/blob/main/papers/2020/200205%20K-Adapter.md) #multitask #adapter\n  3. [200206 Consistency of a Recurrent Language Model With Respect to Incomplete](/rosinality/ml-papers/blob/main/papers/2020/200206%20Consistency%20of%20a%20Recurrent%20Language%20Model%20With%20Respect%20to%20Incomplete.md) #decoding #hallucination #language_generation\n  4. [200222 Training Question Answering Models From Synthetic Data](/rosinality/ml-papers/blob/main/papers/2020/200222%20Training%20Question%20Answering%20Models%20From%20Synthetic%20Data.md) #qa #bert\n  5. [200225 MiniLM](/rosinality/ml-papers/blob/main/papers/2020/200225%20MiniLM.md) #distillation #lightweight\n  6. [200406 Sparse Text Generation](/rosinality/ml-papers/blob/main/papers/2020/200406%20Sparse%20Text%20Generation.md) #language_generation #sampling\n  7. [200427 Recall and Learn](/rosinality/ml-papers/blob/main/papers/2020/200427%20Recall%20and%20Learn.md) #finetuning #continual_learning\n  8. [200505 Stolen Probability](/rosinality/ml-papers/blob/main/papers/2020/200505%20Stolen%20Probability.md)\n  9. [200516 MicroNet for Efficient Language Modeling](/rosinality/ml-papers/blob/main/papers/2020/200516%20MicroNet%20for%20Efficient%20Language%20Modeling.md) #lightweight\n  10.", "start_char_idx": 107908, "end_char_idx": 110910, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8d20577f-cabf-4d27-97d3-579525727cda": {"__data__": {"id_": "8d20577f-cabf-4d27-97d3-579525727cda", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f16f8843-d47c-4911-adda-d35456826266", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "8ed471e7164104f281b912ad4da1035bebd373e2a7281b1f889f32ec065c6254", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1a6a2f28-3e5d-4526-8f79-37c9003e6d86", "node_type": "1", "metadata": {}, "hash": "1ca56416551d04a97d982b0aa44670d36b245b58571fc5f1516127671eef274f", "class_name": "RelatedNodeInfo"}}, "text": "[200406 Sparse Text Generation](/rosinality/ml-papers/blob/main/papers/2020/200406%20Sparse%20Text%20Generation.md) #language_generation #sampling\n  7. [200427 Recall and Learn](/rosinality/ml-papers/blob/main/papers/2020/200427%20Recall%20and%20Learn.md) #finetuning #continual_learning\n  8. [200505 Stolen Probability](/rosinality/ml-papers/blob/main/papers/2020/200505%20Stolen%20Probability.md)\n  9. [200516 MicroNet for Efficient Language Modeling](/rosinality/ml-papers/blob/main/papers/2020/200516%20MicroNet%20for%20Efficient%20Language%20Modeling.md) #lightweight\n  10. [200518 Contextual Embeddings](/rosinality/ml-papers/blob/main/papers/2020/200518%20Contextual%20Embeddings.md)\n  11. [201015 Fine-Tuning Pre-trained Language Model with Weak Supervision](/rosinality/ml-papers/blob/main/papers/2020/201015%20Fine-Tuning%20Pre-trained%20Language%20Model%20with%20Weak%20Supervision.md) #transfer #weak_supervision\n  12. [201023 Rethinking embedding coupling in pre-trained language models](/rosinality/ml-papers/blob/main/papers/2020/201023%20Rethinking%20embedding%20coupling%20in%20pre-trained%20language%20models.md) #regularization\n  13. [201201 How Can We Know When Language Models Know](/rosinality/ml-papers/blob/main/papers/2020/201201%20How%20Can%20We%20Know%20When%20Language%20Models%20Know.md) #qa #calibration\n  14. [201228 Universal Sentence Representation Learning with Conditional Masked](/rosinality/ml-papers/blob/main/papers/2020/201228%20Universal%20Sentence%20Representation%20Learning%20with%20Conditional%20Masked.md) #sentence_embedding #mlm\n  15. [210216 Non-Autoregressive Text Generation with Pre-trained Language Models](/rosinality/ml-papers/blob/main/papers/2021/210216%20Non-Autoregressive%20Text%20Generation%20with%20Pre-trained%20Language%20Models.md) #non-autoregressive #text_generation\n  16. [210318 GPT Understands, Too](/rosinality/ml-papers/blob/main/papers/2021/210318%20GPT%20Understands%2C%20Too.md) #finetuning #prompt\n  17. [210407 Revisiting Simple Neural Probabilistic Language Models](/rosinality/ml-papers/blob/main/papers/2021/210407%20Revisiting%20Simple%20Neural%20Probabilistic%20Language%20Models.md)\n  18. [210420 Carbon Emissions and Large Neural Network Training](/rosinality/ml-papers/blob/main/papers/2021/210420%20Carbon%20Emissions%20and%20Large%20Neural%20Network%20Training.md) #nlp\n  19. [210922 Recursively Summarizing Books with Human Feedback](/rosinality/ml-papers/blob/main/papers/2021/210922%20Recursively%20Summarizing%20Books%20with%20Human%20Feedback.md) #summarization\n\n## layout\n\n  1. [210601 Incorporating Visual Layout Structures for Scientific Text Classification](/rosinality/ml-papers/blob/main/papers/2021/210601%20Incorporating%20Visual%20Layout%20Structures%20for%20Scientific%20Text%20Classification.md)\n  2. [210902 Skim-Attention](/rosinality/ml-papers/blob/main/papers/2021/210902%20Skim-Attention.md)\n  3. [220418 LayoutLMv3](/rosinality/ml-papers/blob/main/papers/2022/220418%20LayoutLMv3.md)\n  4.", "start_char_idx": 110332, "end_char_idx": 113329, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a6a2f28-3e5d-4526-8f79-37c9003e6d86": {"__data__": {"id_": "1a6a2f28-3e5d-4526-8f79-37c9003e6d86", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8d20577f-cabf-4d27-97d3-579525727cda", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "0ef994454593ce04b8e8cdd1fa69be57f78a923104edff6457d179841b541e90", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6835c55a-f229-43ab-bbd5-87a292013817", "node_type": "1", "metadata": {}, "hash": "e7796ca7f7e3f109fdd30be55225a312fe45fdcc0c26b12cbb3d0567faf173ea", "class_name": "RelatedNodeInfo"}}, "text": "[210601 Incorporating Visual Layout Structures for Scientific Text Classification](/rosinality/ml-papers/blob/main/papers/2021/210601%20Incorporating%20Visual%20Layout%20Structures%20for%20Scientific%20Text%20Classification.md)\n  2. [210902 Skim-Attention](/rosinality/ml-papers/blob/main/papers/2021/210902%20Skim-Attention.md)\n  3. [220418 LayoutLMv3](/rosinality/ml-papers/blob/main/papers/2022/220418%20LayoutLMv3.md)\n  4. [220517 MATrIX -- Modality-Aware Transformer for Information eXtraction](/rosinality/ml-papers/blob/main/papers/2022/220517%20MATrIX%20--%20Modality-Aware%20Transformer%20for%20Information%20eXtraction.md)\n  5. [220912 PreSTU](/rosinality/ml-papers/blob/main/papers/2022/220912%20PreSTU.md)\n  6. [220918 ERNIE-mmLayout](/rosinality/ml-papers/blob/main/papers/2022/220918%20ERNIE-mmLayout.md)\n\n## lightweight\n\n  1. [200624 Neural Architecture Design for GPU-Efficient Networks](/rosinality/ml-papers/blob/main/papers/2020/200624%20Neural%20Architecture%20Design%20for%20GPU-Efficient%20Networks.md)\n  2. [201124 MicroNet](/rosinality/ml-papers/blob/main/papers/2020/201124%20MicroNet.md)\n  3. [210507 Pareto-Optimal Quantized ResNet Is Mostly 4-bit](/rosinality/ml-papers/blob/main/papers/2021/210507%20Pareto-Optimal%20Quantized%20ResNet%20Is%20Mostly%204-bit.md) #quantization\n  4. [220409 Searching for Efficient Neural Architectures for On-Device ML on Edge TPUs](/rosinality/ml-papers/blob/main/papers/2022/220409%20Searching%20for%20Efficient%20Neural%20Architectures%20for%20On-Device%20ML%20on%20Edge%20TPUs.md)\n\n## line\n\n  1. [210601 Towards Real-time and Light-weight Line Segment Detection](/rosinality/ml-papers/blob/main/papers/2021/210601%20Towards%20Real-time%20and%20Light-weight%20Line%20Segment%20Detection.md)\n\n## linear attention\n\n  1. [230717 Retentive Network](/rosinality/ml-papers/blob/main/papers/2023/230717%20Retentive%20Network.md) #recurrent\n\n## llm\n\n  1. [220521 Scaling Laws and Interpretability of Learning from Repeated Data](/rosinality/ml-papers/blob/main/papers/2022/220521%20Scaling%20Laws%20and%20Interpretability%20of%20Learning%20from%20Repeated%20Data.md)\n  2. [220522 Memorization Without Overfitting](/rosinality/ml-papers/blob/main/papers/2022/220522%20Memorization%20Without%20Overfitting.md)\n  3. [220524 Large Language Models are Zero-Shot Reasoners](/rosinality/ml-papers/blob/main/papers/2022/220524%20Large%20Language%20Models%20are%20Zero-Shot%20Reasoners.md) #prompt\n  4. [220711 Exploring Length Generalization in Large Language Models](/rosinality/ml-papers/blob/main/papers/2022/220711%20Exploring%20Length%20Generalization%20in%20Large%20Language%20Models.md)\n  5. [220711 Language Models (Mostly) Know What They Know](/rosinality/ml-papers/blob/main/papers/2022/220711%20Language%20Models%20%28Mostly%29%20Know%20What%20They%20Know.md)\n  6. [220926 Can Large Language Models Truly Understand Prompts](/rosinality/ml-papers/blob/main/papers/2022/220926%20Can%20Large%20Language%20Models%20Truly%20Understand%20Prompts.md)\n  7.", "start_char_idx": 112903, "end_char_idx": 115911, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6835c55a-f229-43ab-bbd5-87a292013817": {"__data__": {"id_": "6835c55a-f229-43ab-bbd5-87a292013817", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1a6a2f28-3e5d-4526-8f79-37c9003e6d86", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "fb3c0497a6a32318a3b950eb5cff7bd90e833021d46e01c724091a9a19e20c33", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67b70369-c8bb-4188-bbc6-2d1e2fcf406a", "node_type": "1", "metadata": {}, "hash": "342f66c2d3b7b48ec45afba68cced0d8ec3c384d4fe44a65b22cd98cdc47961e", "class_name": "RelatedNodeInfo"}}, "text": "[220711 Exploring Length Generalization in Large Language Models](/rosinality/ml-papers/blob/main/papers/2022/220711%20Exploring%20Length%20Generalization%20in%20Large%20Language%20Models.md)\n  5. [220711 Language Models (Mostly) Know What They Know](/rosinality/ml-papers/blob/main/papers/2022/220711%20Language%20Models%20%28Mostly%29%20Know%20What%20They%20Know.md)\n  6. [220926 Can Large Language Models Truly Understand Prompts](/rosinality/ml-papers/blob/main/papers/2022/220926%20Can%20Large%20Language%20Models%20Truly%20Understand%20Prompts.md)\n  7. [220929 Compositional Semantic Parsing with Large Language Models](/rosinality/ml-papers/blob/main/papers/2022/220929%20Compositional%20Semantic%20Parsing%20with%20Large%20Language%20Models.md) #semantic_parsing\n  8. [221017 Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them](/rosinality/ml-papers/blob/main/papers/2022/221017%20Challenging%20BIG-Bench%20Tasks%20and%20Whether%20Chain-of-Thought%20Can%20Solve%20Them.md) #prompt #reasoning\n  9. [221020 Transcending Scaling Laws with 0.1% Extra Compute](/rosinality/ml-papers/blob/main/papers/2022/221020%20Transcending%20Scaling%20Laws%20with%200.1%25%20Extra%20Compute.md) #mlm\n  10. [221103 Inverse scaling can become U-shaped](/rosinality/ml-papers/blob/main/papers/2022/221103%20Inverse%20scaling%20can%20become%20U-shaped.md) #prompt\n  11. [221109 BLOOM](/rosinality/ml-papers/blob/main/papers/2022/221109%20BLOOM.md)\n  12. [221109 Efficiently Scaling Transformer Inference](/rosinality/ml-papers/blob/main/papers/2022/221109%20Efficiently%20Scaling%20Transformer%20Inference.md) #efficiency\n  13. [221118 PAL](/rosinality/ml-papers/blob/main/papers/2022/221118%20PAL.md) #prompt\n  14. [221118 SmoothQuant](/rosinality/ml-papers/blob/main/papers/2022/221118%20SmoothQuant.md) #quantization\n  15. [230124 A Watermark for Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230124%20A%20Watermark%20for%20Large%20Language%20Models.md)\n  16. [230126 DetectGPT](/rosinality/ml-papers/blob/main/papers/2023/230126%20DetectGPT.md)\n  17. [230131 Faithful Chain-of-Thought Reasoning](/rosinality/ml-papers/blob/main/papers/2023/230131%20Faithful%20Chain-of-Thought%20Reasoning.md) #prompt\n  18. [230131 Grounding Language Models to Images for Multimodal Generation](/rosinality/ml-papers/blob/main/papers/2023/230131%20Grounding%20Language%20Models%20to%20Images%20for%20Multimodal%20Generation.md) #multimodal_generation #vision-language\n  19. [230131 Large Language Models Can Be Easily Distracted by Irrelevant Context](/rosinality/ml-papers/blob/main/papers/2023/230131%20Large%20Language%20Models%20Can%20Be%20Easily%20Distracted%20by%20Irrelevant%20Context.md) #in_context_learning\n  20. [230206 Chain of Hindsight Aligns Language Models with Feedback](/rosinality/ml-papers/blob/main/papers/2023/230206%20Chain%20of%20Hindsight%20Aligns%20Language%20Models%20with%20Feedback.md) #alignment\n  21.", "start_char_idx": 115353, "end_char_idx": 118299, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67b70369-c8bb-4188-bbc6-2d1e2fcf406a": {"__data__": {"id_": "67b70369-c8bb-4188-bbc6-2d1e2fcf406a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6835c55a-f229-43ab-bbd5-87a292013817", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "730797bcb48c4f2682d514ef7039505f227f5811be50f10848e68d9e2eb07f99", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a552d385-eb25-4078-bcbe-a7fb7bbbe20d", "node_type": "1", "metadata": {}, "hash": "0265033a0eb07814e98db99901a60bfb2794dcc92eb44104fc85b3874ff3f74a", "class_name": "RelatedNodeInfo"}}, "text": "[230131 Large Language Models Can Be Easily Distracted by Irrelevant Context](/rosinality/ml-papers/blob/main/papers/2023/230131%20Large%20Language%20Models%20Can%20Be%20Easily%20Distracted%20by%20Irrelevant%20Context.md) #in_context_learning\n  20. [230206 Chain of Hindsight Aligns Language Models with Feedback](/rosinality/ml-papers/blob/main/papers/2023/230206%20Chain%20of%20Hindsight%20Aligns%20Language%20Models%20with%20Feedback.md) #alignment\n  21. [230209 Toolformer](/rosinality/ml-papers/blob/main/papers/2023/230209%20Toolformer.md)\n  22. [230211 Characterizing Attribution and Fluency Tradeoffs for Retrieval-Augmented Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230211%20Characterizing%20Attribution%20and%20Fluency%20Tradeoffs%20for%20Retrieval-Augmented%20Large%20Language%20Models.md) #retrieval\n  23. [230215 Learning Performance-Improving Code Edits](/rosinality/ml-papers/blob/main/papers/2023/230215%20Learning%20Performance-Improving%20Code%20Edits.md) #in_context_learning\n  24. [230215 The Capacity for Moral Self-Correction in Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230215%20The%20Capacity%20for%20Moral%20Self-Correction%20in%20Large%20Language%20Models.md) #instruct #ethics\n  25. [230216 Pretraining Language Models with Human Preferences](/rosinality/ml-papers/blob/main/papers/2023/230216%20Pretraining%20Language%20Models%20with%20Human%20Preferences.md) #instruct #alignment\n  26. [230219 Semantic Uncertainty](/rosinality/ml-papers/blob/main/papers/2023/230219%20Semantic%20Uncertainty.md) #uncertainty\n  27. [230221 ChatGPT](/rosinality/ml-papers/blob/main/papers/2023/230221%20ChatGPT.md) #instruct\n  28. [230224 Check Your Facts and Try Again](/rosinality/ml-papers/blob/main/papers/2023/230224%20Check%20Your%20Facts%20and%20Try%20Again.md) #retrieval\n  29. [230306 PaLM-E](/rosinality/ml-papers/blob/main/papers/2023/230306%20PaLM-E.md) #robotics #multimodal #3d\n  30. [230307 Flamingo](/rosinality/ml-papers/blob/main/papers/2023/230307%20Flamingo.md) #multimodal\n  31. [230307 Larger language models do in-context learning differently](/rosinality/ml-papers/blob/main/papers/2023/230307%20Larger%20language%20models%20do%20in-context%20learning%20differently.md) #in_context_learning\n  32. [230307 The BigScience ROOTS Corpus](/rosinality/ml-papers/blob/main/papers/2023/230307%20The%20BigScience%20ROOTS%20Corpus.md) #dataset\n  33. [230313 High-throughput Generative Inference of Large Language Models with a Single GPU](/rosinality/ml-papers/blob/main/papers/2023/230313%20High-throughput%20Generative%20Inference%20of%20Large%20Language%20Models%20with%20a%20Single%20GPU.md)\n  34. [230315 A Comprehensive Study on Post-Training Quantization for Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230315%20A%20Comprehensive%20Study%20on%20Post-Training%20Quantization%20for%20Large%20Language%20Models.md) #quantization\n  35. [230316 ART](/rosinality/ml-papers/blob/main/papers/2023/230316%20ART.md) #in_context_learning #prompt\n  36.", "start_char_idx": 117842, "end_char_idx": 120887, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a552d385-eb25-4078-bcbe-a7fb7bbbe20d": {"__data__": {"id_": "a552d385-eb25-4078-bcbe-a7fb7bbbe20d", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67b70369-c8bb-4188-bbc6-2d1e2fcf406a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "828c944ebfe8968d7be78d99c8e1a9d18153579ddc07f4f0dfb3a448e1fe3b91", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "90b5691f-a8e1-4ce0-a541-c616310beed0", "node_type": "1", "metadata": {}, "hash": "8e4bdd7f6e2c4eb48b689bf8b5a7b625c79b383f7d8f7b9fb7fdc75345c2d1bd", "class_name": "RelatedNodeInfo"}}, "text": "[230313 High-throughput Generative Inference of Large Language Models with a Single GPU](/rosinality/ml-papers/blob/main/papers/2023/230313%20High-throughput%20Generative%20Inference%20of%20Large%20Language%20Models%20with%20a%20Single%20GPU.md)\n  34. [230315 A Comprehensive Study on Post-Training Quantization for Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230315%20A%20Comprehensive%20Study%20on%20Post-Training%20Quantization%20for%20Large%20Language%20Models.md) #quantization\n  35. [230316 ART](/rosinality/ml-papers/blob/main/papers/2023/230316%20ART.md) #in_context_learning #prompt\n  36. [230317 GPTs are GPTs](/rosinality/ml-papers/blob/main/papers/2023/230317%20GPTs%20are%20GPTs.md)\n  37. [230322 MEGA](/rosinality/ml-papers/blob/main/papers/2023/230322%20MEGA.md) #multilingual\n  38. [230322 RepoCoder](/rosinality/ml-papers/blob/main/papers/2023/230322%20RepoCoder.md) #retrieval\n  39. [230322 Sparks of Artificial General Intelligence](/rosinality/ml-papers/blob/main/papers/2023/230322%20Sparks%20of%20Artificial%20General%20Intelligence.md)\n  40. [230407 Generative Agents](/rosinality/ml-papers/blob/main/papers/2023/230407%20Generative%20Agents.md)\n  41. [230410 Inference with Reference](/rosinality/ml-papers/blob/main/papers/2023/230410%20Inference%20with%20Reference.md) #efficiency\n  42. [230411 RRHF](/rosinality/ml-papers/blob/main/papers/2023/230411%20RRHF.md) #alignment\n  43. [230416 Sabi\u00e1](/rosinality/ml-papers/blob/main/papers/2023/230416%20Sabi%C3%A1.md) #multilingual\n  44. [230417 A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on Chinese Instruction Data for Instruction Following Large Language Model](/rosinality/ml-papers/blob/main/papers/2023/230417%20A%20Comparative%20Study%20between%20Full-Parameter%20and%20LoRA-based%20Fine-Tuning%20on%20Chinese%20Instruction%20Data%20for%20Instruction%20Following%20Large%20Language%20Model.md) #instruct\n  45. [230417 Low-code LLM](/rosinality/ml-papers/blob/main/papers/2023/230417%20Low-code%20LLM.md) #prompt\n  46. [230418 UniMax](/rosinality/ml-papers/blob/main/papers/2023/230418%20UniMax.md) #multilingual\n  47. [230419 A Theory on Adam Instability in Large-Scale Machine Learning](/rosinality/ml-papers/blob/main/papers/2023/230419%20A%20Theory%20on%20Adam%20Instability%20in%20Large-Scale%20Machine%20Learning.md) #optimizer\n  48. [230421 Can GPT-4 Perform Neural Architecture Search](/rosinality/ml-papers/blob/main/papers/2023/230421%20Can%20GPT-4%20Perform%20Neural%20Architecture%20Search.md) #nas\n  49. [230421 Inducing anxiety in large language models increases exploration and bias](/rosinality/ml-papers/blob/main/papers/2023/230421%20Inducing%20anxiety%20in%20large%20language%20models%20increases%20exploration%20and%20bias.md)\n  50. [230424 Why we need RLHF](/rosinality/ml-papers/blob/main/papers/2023/230424%20Why%20we%20need%20RLHF.md) #alignment #rl\n  51.", "start_char_idx": 120267, "end_char_idx": 123173, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "90b5691f-a8e1-4ce0-a541-c616310beed0": {"__data__": {"id_": "90b5691f-a8e1-4ce0-a541-c616310beed0", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a552d385-eb25-4078-bcbe-a7fb7bbbe20d", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b9d35a167d366123368ae68a2218f3897b16fe7008005057e993c253b379c6bf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef2eb7f5-10af-4cc0-90dd-d8ba6cb3a618", "node_type": "1", "metadata": {}, "hash": "f7bdfc802a901ad4dd8a3515d7cb1c019d126eecc25822b6c3c2379a51f8a399", "class_name": "RelatedNodeInfo"}}, "text": "[230421 Can GPT-4 Perform Neural Architecture Search](/rosinality/ml-papers/blob/main/papers/2023/230421%20Can%20GPT-4%20Perform%20Neural%20Architecture%20Search.md) #nas\n  49. [230421 Inducing anxiety in large language models increases exploration and bias](/rosinality/ml-papers/blob/main/papers/2023/230421%20Inducing%20anxiety%20in%20large%20language%20models%20increases%20exploration%20and%20bias.md)\n  50. [230424 Why we need RLHF](/rosinality/ml-papers/blob/main/papers/2023/230424%20Why%20we%20need%20RLHF.md) #alignment #rl\n  51. [230428 Causal Reasoning and Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230428%20Causal%20Reasoning%20and%20Large%20Language%20Models.md) #causality\n  52. [230428 Speak, Memory](/rosinality/ml-papers/blob/main/papers/2023/230428%20Speak%2C%20Memory.md)\n  53. [230503 Cheaply Evaluating Inference Efficiency Metrics for Autoregressive Transformer APIs](/rosinality/ml-papers/blob/main/papers/2023/230503%20Cheaply%20Evaluating%20Inference%20Efficiency%20Metrics%20for%20Autoregressive%20Transformer%20APIs.md) #efficiency\n  54. [230504 Can LLM Already Serve as A Database Interface](/rosinality/ml-papers/blob/main/papers/2023/230504%20Can%20LLM%20Already%20Serve%20as%20A%20Database%20Interface.md)\n  55. [230509 Large Language Model Programs](/rosinality/ml-papers/blob/main/papers/2023/230509%20Large%20Language%20Model%20Programs.md) #prompt\n  56. [230509 MoT](/rosinality/ml-papers/blob/main/papers/2023/230509%20MoT.md) #prompt\n  57. [230511 Chain-of-Dictionary Prompting Elicits Translation in Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230511%20Chain-of-Dictionary%20Prompting%20Elicits%20Translation%20in%20Large%20Language%20Models.md)\n  58. [230511 INGENIOUS](/rosinality/ml-papers/blob/main/papers/2023/230511%20INGENIOUS.md) #dataset\n  59. [230511 Not All Languages Are Created Equal in LLMs](/rosinality/ml-papers/blob/main/papers/2023/230511%20Not%20All%20Languages%20Are%20Created%20Equal%20in%20LLMs.md)\n  60. [230513 CodeT5+](/rosinality/ml-papers/blob/main/papers/2023/230513%20CodeT5%2B.md)\n  61. [230515 Symbol tuning improves in-context learning in language models](/rosinality/ml-papers/blob/main/papers/2023/230515%20Symbol%20tuning%20improves%20in-context%20learning%20in%20language%20models.md) #prompt\n  62. [230516 Towards Expert-Level Medical Question Answering with Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230516%20Towards%20Expert-Level%20Medical%20Question%20Answering%20with%20Large%20Language%20Models.md)\n  63. [230517 DoReMi](/rosinality/ml-papers/blob/main/papers/2023/230517%20DoReMi.md) #dataset #multitask #pretraining\n  64. [230517 Searching for Needles in a Haystack](/rosinality/ml-papers/blob/main/papers/2023/230517%20Searching%20for%20Needles%20in%20a%20Haystack.md) #nmt #multilingual\n  65.", "start_char_idx": 122634, "end_char_idx": 125485, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ef2eb7f5-10af-4cc0-90dd-d8ba6cb3a618": {"__data__": {"id_": "ef2eb7f5-10af-4cc0-90dd-d8ba6cb3a618", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "90b5691f-a8e1-4ce0-a541-c616310beed0", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "5c868e526eca737c459ad70a20588b8c75efd24a1a64aed2ab9274a15e10fa74", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "59212883-943f-4db3-ba9f-ff2a0a37b354", "node_type": "1", "metadata": {}, "hash": "f10b7a3b56915e2080d6dc2646cc2b2302118188533f8b43b13ba8d6fb7f0b35", "class_name": "RelatedNodeInfo"}}, "text": "[230516 Towards Expert-Level Medical Question Answering with Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230516%20Towards%20Expert-Level%20Medical%20Question%20Answering%20with%20Large%20Language%20Models.md)\n  63. [230517 DoReMi](/rosinality/ml-papers/blob/main/papers/2023/230517%20DoReMi.md) #dataset #multitask #pretraining\n  64. [230517 Searching for Needles in a Haystack](/rosinality/ml-papers/blob/main/papers/2023/230517%20Searching%20for%20Needles%20in%20a%20Haystack.md) #nmt #multilingual\n  65. [230519 Cross-Lingual Supervision improves Large Language Models Pre-training](/rosinality/ml-papers/blob/main/papers/2023/230519%20Cross-Lingual%20Supervision%20improves%20Large%20Language%20Models%20Pre-training.md) #nmt #multilingual\n  66. [230521 A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230521%20A%20PhD%20Student%27s%20Perspective%20on%20Research%20in%20NLP%20in%20the%20Era%20of%20Very%20Large%20Language%20Models.md) #nlp\n  67. [230522 How Language Model Hallucinations Can Snowball](/rosinality/ml-papers/blob/main/papers/2023/230522%20How%20Language%20Model%20Hallucinations%20Can%20Snowball.md) #alignment\n  68. [230522 To Repeat or Not To Repeat](/rosinality/ml-papers/blob/main/papers/2023/230522%20To%20Repeat%20or%20Not%20To%20Repeat.md)\n  69. [230523 Aligning Large Language Models through Synthetic Feedback](/rosinality/ml-papers/blob/main/papers/2023/230523%20Aligning%20Large%20Language%20Models%20through%20Synthetic%20Feedback.md) #alignment\n  70. [230523 Goat](/rosinality/ml-papers/blob/main/papers/2023/230523%20Goat.md)\n  71. [230523 QLoRA](/rosinality/ml-papers/blob/main/papers/2023/230523%20QLoRA.md) #quantization #alignment #finetuning\n  72. [230525 Scaling Data-Constrained Language Models](/rosinality/ml-papers/blob/main/papers/2023/230525%20Scaling%20Data-Constrained%20Language%20Models.md) #scaling\n  73. [230526 Large Language Models as Tool Makers](/rosinality/ml-papers/blob/main/papers/2023/230526%20Large%20Language%20Models%20as%20Tool%20Makers.md) #alignment\n  74. [230614 WizardCoder](/rosinality/ml-papers/blob/main/papers/2023/230614%20WizardCoder.md)\n  75. [230615 Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230615%20Exploring%20the%20MIT%20Mathematics%20and%20EECS%20Curriculum%20Using%20Large%20Language%20Models.md)\n  76. [230615 Inverse Scaling](/rosinality/ml-papers/blob/main/papers/2023/230615%20Inverse%20Scaling.md)\n  77. [230616 Demystifying GPT Self-Repair for Code Generation](/rosinality/ml-papers/blob/main/papers/2023/230616%20Demystifying%20GPT%20Self-Repair%20for%20Code%20Generation.md)\n  78. [230616 Full Parameter Fine-tuning for Large Language Models with Limited Resources](/rosinality/ml-papers/blob/main/papers/2023/230616%20Full%20Parameter%20Fine-tuning%20for%20Large%20Language%20Models%20with%20Limited%20Resources.md) #finetuning\n  79.", "start_char_idx": 124956, "end_char_idx": 127970, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "59212883-943f-4db3-ba9f-ff2a0a37b354": {"__data__": {"id_": "59212883-943f-4db3-ba9f-ff2a0a37b354", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef2eb7f5-10af-4cc0-90dd-d8ba6cb3a618", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "4b65cc579c9fa4ee36f3c70b3c14f0d17457d9a0d6b05a1675fff0c6bf24dba7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "395415da-c009-4a56-bf74-14767ffe2569", "node_type": "1", "metadata": {}, "hash": "8e9ead0f4e2dbe7ae32d4aebd7ca4245a689ac126b6448ac38da1e08d00e2513", "class_name": "RelatedNodeInfo"}}, "text": "[230615 Inverse Scaling](/rosinality/ml-papers/blob/main/papers/2023/230615%20Inverse%20Scaling.md)\n  77. [230616 Demystifying GPT Self-Repair for Code Generation](/rosinality/ml-papers/blob/main/papers/2023/230616%20Demystifying%20GPT%20Self-Repair%20for%20Code%20Generation.md)\n  78. [230616 Full Parameter Fine-tuning for Large Language Models with Limited Resources](/rosinality/ml-papers/blob/main/papers/2023/230616%20Full%20Parameter%20Fine-tuning%20for%20Large%20Language%20Models%20with%20Limited%20Resources.md) #finetuning\n  79. [230619 BayLing](/rosinality/ml-papers/blob/main/papers/2023/230619%20BayLing.md) #alignment\n  80. [230620 Learning to Generate Better Than Your LLM](/rosinality/ml-papers/blob/main/papers/2023/230620%20Learning%20to%20Generate%20Better%20Than%20Your%20LLM.md) #alignment\n  81. [230620 Textbooks Are All You Need](/rosinality/ml-papers/blob/main/papers/2023/230620%20Textbooks%20Are%20All%20You%20Need.md)\n  82. [230621 Deep Language Networks](/rosinality/ml-papers/blob/main/papers/2023/230621%20Deep%20Language%20Networks.md)\n  83. [230622 AudioPaLM](/rosinality/ml-papers/blob/main/papers/2023/230622%20AudioPaLM.md) #audio #speech\n  84. [230623 Bring Your Own Data! Self-Supervised Evaluation for Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230623%20Bring%20Your%20Own%20Data%21%20Self-Supervised%20Evaluation%20for%20Large%20Language%20Models.md) #evaluation\n  85. [230623 GKD](/rosinality/ml-papers/blob/main/papers/2023/230623%20GKD.md) #distillation\n  86. [230624 Beyond Scale](/rosinality/ml-papers/blob/main/papers/2023/230624%20Beyond%20Scale.md) #dataset\n  87. [230628 Towards Language Models That Can See](/rosinality/ml-papers/blob/main/papers/2023/230628%20Towards%20Language%20Models%20That%20Can%20See.md) #multimodal #vision-language\n  88. [230629 Benchmarking Large Language Model Capabilities for Conditional Generation](/rosinality/ml-papers/blob/main/papers/2023/230629%20Benchmarking%20Large%20Language%20Model%20Capabilities%20for%20Conditional%20Generation.md) #evaluation\n  89. [230630 Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting](/rosinality/ml-papers/blob/main/papers/2023/230630%20Large%20Language%20Models%20are%20Effective%20Text%20Rankers%20with%20Pairwise%20Ranking%20Prompting.md)\n  90. [230705 Reasoning or Reciting](/rosinality/ml-papers/blob/main/papers/2023/230705%20Reasoning%20or%20Reciting.md) #evaluation\n  91. [230706 Style Over Substance](/rosinality/ml-papers/blob/main/papers/2023/230706%20Style%20Over%20Substance.md) #evaluation\n  92. [230713 In-context Autoencoder for Context Compression in a Large Language Model](/rosinality/ml-papers/blob/main/papers/2023/230713%20In-context%20Autoencoder%20for%20Context%20Compression%20in%20a%20Large%20Language%20Model.md)\n  93. [230717 GEAR](/rosinality/ml-papers/blob/main/papers/2023/230717%20GEAR.md) #alignment\n  94.", "start_char_idx": 127431, "end_char_idx": 130342, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "395415da-c009-4a56-bf74-14767ffe2569": {"__data__": {"id_": "395415da-c009-4a56-bf74-14767ffe2569", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "59212883-943f-4db3-ba9f-ff2a0a37b354", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "6a33522f06e17bac00e084e6af20139be672563945723f31fb5b91152070bcb9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0dba4b81-ac5e-4ddb-a599-19d7d06e467f", "node_type": "1", "metadata": {}, "hash": "f54370b9507802c46e4e0f5a4ec14eb271dc44409c3eb38dcaaae1000fb37d53", "class_name": "RelatedNodeInfo"}}, "text": "[230705 Reasoning or Reciting](/rosinality/ml-papers/blob/main/papers/2023/230705%20Reasoning%20or%20Reciting.md) #evaluation\n  91. [230706 Style Over Substance](/rosinality/ml-papers/blob/main/papers/2023/230706%20Style%20Over%20Substance.md) #evaluation\n  92. [230713 In-context Autoencoder for Context Compression in a Large Language Model](/rosinality/ml-papers/blob/main/papers/2023/230713%20In-context%20Autoencoder%20for%20Context%20Compression%20in%20a%20Large%20Language%20Model.md)\n  93. [230717 GEAR](/rosinality/ml-papers/blob/main/papers/2023/230717%20GEAR.md) #alignment\n  94. [230803 Scaling Relationship on Learning Mathematical Reasoning with Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230803%20Scaling%20Relationship%20on%20Learning%20Mathematical%20Reasoning%20with%20Large%20Language%20Models.md)\n\n## lm\n\n  1. [210524 StructuralLM](/rosinality/ml-papers/blob/main/papers/2021/210524%20StructuralLM.md) #layout\n  2. [210524 True Few-Shot Learning with Language Models](/rosinality/ml-papers/blob/main/papers/2021/210524%20True%20Few-Shot%20Learning%20with%20Language%20Models.md) #few_shot\n  3. [210528 ByT5](/rosinality/ml-papers/blob/main/papers/2021/210528%20ByT5.md)\n  4. [210617 LoRA](/rosinality/ml-papers/blob/main/papers/2021/210617%20LoRA.md) #adapter #finetuning\n  5. [210623 Charformer](/rosinality/ml-papers/blob/main/papers/2021/210623%20Charformer.md) #tokenizer\n  6. [210714 Deduplicating Training Data Makes Language Models Better](/rosinality/ml-papers/blob/main/papers/2021/210714%20Deduplicating%20Training%20Data%20Makes%20Language%20Models%20Better.md) #corpus\n  7. [210714 HTLM](/rosinality/ml-papers/blob/main/papers/2021/210714%20HTLM.md)\n  8. [210811 DEMix Layers](/rosinality/ml-papers/blob/main/papers/2021/210811%20DEMix%20Layers.md) #mixture_of_experts\n  9. [210813 Curriculum Learning](/rosinality/ml-papers/blob/main/papers/2021/210813%20Curriculum%20Learning.md) #curriculum\n  10. [210816 On the Opportunities and Risks of Foundation Models](/rosinality/ml-papers/blob/main/papers/2021/210816%20On%20the%20Opportunities%20and%20Risks%20of%20Foundation%20Models.md)\n  11. [210902 Do Prompt-Based Models Really Understand the Meaning of their Prompts](/rosinality/ml-papers/blob/main/papers/2021/210902%20Do%20Prompt-Based%20Models%20Really%20Understand%20the%20Meaning%20of%20their%20Prompts.md) #prompt\n  12. [210903 Finetuned Language Models Are Zero-Shot Learners](/rosinality/ml-papers/blob/main/papers/2021/210903%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners.md) #zero-shot\n  13. [210908 A Recipe For Arbitrary Text Style Transfer with Large Language Models](/rosinality/ml-papers/blob/main/papers/2021/210908%20A%20Recipe%20For%20Arbitrary%20Text%20Style%20Transfer%20with%20Large%20Language%20Models.md) #prompt\n  14.", "start_char_idx": 129752, "end_char_idx": 132566, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0dba4b81-ac5e-4ddb-a599-19d7d06e467f": {"__data__": {"id_": "0dba4b81-ac5e-4ddb-a599-19d7d06e467f", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "395415da-c009-4a56-bf74-14767ffe2569", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "dab975311c417a75308c54c00ace5acee8abb67502f2450621467e56d728fc14", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b92b11b5-bc2f-44f1-b03e-6b6190be6468", "node_type": "1", "metadata": {}, "hash": "83dd9af0319ffd1f81ba686492247ff28e9694f3000e49bfe8d35745e0b67017", "class_name": "RelatedNodeInfo"}}, "text": "[210903 Finetuned Language Models Are Zero-Shot Learners](/rosinality/ml-papers/blob/main/papers/2021/210903%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners.md) #zero-shot\n  13. [210908 A Recipe For Arbitrary Text Style Transfer with Large Language Models](/rosinality/ml-papers/blob/main/papers/2021/210908%20A%20Recipe%20For%20Arbitrary%20Text%20Style%20Transfer%20with%20Large%20Language%20Models.md) #prompt\n  14. [211011 Unsupervised Neural Machine Translation with Generative Language Models Only](/rosinality/ml-papers/blob/main/papers/2021/211011%20Unsupervised%20Neural%20Machine%20Translation%20with%20Generative%20Language%20Models%20Only.md) #unsupervised_nmt\n  15. [211015 Multitask Prompted Training Enables Zero-Shot Task Generalization](/rosinality/ml-papers/blob/main/papers/2021/211015%20Multitask%20Prompted%20Training%20Enables%20Zero-Shot%20Task%20Generalization.md) #zero-shot\n  16. [211016 Invariant Language Modeling](/rosinality/ml-papers/blob/main/papers/2021/211016%20Invariant%20Language%20Modeling.md) #irm\n  17. [211016 MarkupLM](/rosinality/ml-papers/blob/main/papers/2021/211016%20MarkupLM.md) #layout\n  18. [211016 Sharpness-Aware Minimization Improves Language Model Generalization](/rosinality/ml-papers/blob/main/papers/2021/211016%20Sharpness-Aware%20Minimization%20Improves%20Language%20Model%20Generalization.md) #regularization\n  19. [211020 Shaking the foundations](/rosinality/ml-papers/blob/main/papers/2021/211020%20Shaking%20the%20foundations.md) #causality\n  20. [211027 Training Verifiers to Solve Math Word Problems](/rosinality/ml-papers/blob/main/papers/2021/211027%20Training%20Verifiers%20to%20Solve%20Math%20Word%20Problems.md)\n  21. [211213 GLaM](/rosinality/ml-papers/blob/main/papers/2021/211213%20GLaM.md) #moe\n  22. [211220 Efficient Large Scale Language Modeling with Mixtures of Experts](/rosinality/ml-papers/blob/main/papers/2021/211220%20Efficient%20Large%20Scale%20Language%20Modeling%20with%20Mixtures%20of%20Experts.md) #mixture_of_experts\n  23. [220210 Red Teaming Language Models with Language Models](/rosinality/ml-papers/blob/main/papers/2022/220210%20Red%20Teaming%20Language%20Models%20with%20Language%20Models.md) #safety\n  24. [220213 A Contrastive Framework for Neural Text Generation](/rosinality/ml-papers/blob/main/papers/2022/220213%20A%20Contrastive%20Framework%20for%20Neural%20Text%20Generation.md) #decoding\n  25. [220215 General-purpose, long-context autoregressive modeling with Perceiver AR](/rosinality/ml-papers/blob/main/papers/2022/220215%20General-purpose%2C%20long-context%20autoregressive%20modeling%20with%20Perceiver%20AR.md) #efficient_attention #autoregressive_model\n  26. [220314 Efficient Language Modeling with Sparse all-MLP](/rosinality/ml-papers/blob/main/papers/2022/220314%20Efficient%20Language%20Modeling%20with%20Sparse%20all-MLP.md) #mlp\n  27. [220329 Training Compute-Optimal Large Language Models](/rosinality/ml-papers/blob/main/papers/2022/220329%20Training%20Compute-Optimal%20Large%20Language%20Models.md)\n  28.", "start_char_idx": 132136, "end_char_idx": 135176, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b92b11b5-bc2f-44f1-b03e-6b6190be6468": {"__data__": {"id_": "b92b11b5-bc2f-44f1-b03e-6b6190be6468", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0dba4b81-ac5e-4ddb-a599-19d7d06e467f", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "d9a0d559e4415d98315b1936eeaf2bcfd81aedfd69e6e791bd11d35b49661025", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f3194d3d-ce89-4614-8cc8-8ca1ff19799e", "node_type": "1", "metadata": {}, "hash": "2d8ff1f21021d4e59b0694f8f4a844b5cf9a3a6a65f8c6048a35406c78673667", "class_name": "RelatedNodeInfo"}}, "text": "[220215 General-purpose, long-context autoregressive modeling with Perceiver AR](/rosinality/ml-papers/blob/main/papers/2022/220215%20General-purpose%2C%20long-context%20autoregressive%20modeling%20with%20Perceiver%20AR.md) #efficient_attention #autoregressive_model\n  26. [220314 Efficient Language Modeling with Sparse all-MLP](/rosinality/ml-papers/blob/main/papers/2022/220314%20Efficient%20Language%20Modeling%20with%20Sparse%20all-MLP.md) #mlp\n  27. [220329 Training Compute-Optimal Large Language Models](/rosinality/ml-papers/blob/main/papers/2022/220329%20Training%20Compute-Optimal%20Large%20Language%20Models.md)\n  28. [220413 METRO](/rosinality/ml-papers/blob/main/papers/2022/220413%20METRO.md)\n  29. [220414 GPT-NeoX-20B](/rosinality/ml-papers/blob/main/papers/2022/220414%20GPT-NeoX-20B.md)\n  30. [220502 OPT](/rosinality/ml-papers/blob/main/papers/2022/220502%20OPT.md)\n  31. [220524 On the Role of Bidirectionality in Language Model Pre-Training](/rosinality/ml-papers/blob/main/papers/2022/220524%20On%20the%20Role%20of%20Bidirectionality%20in%20Language%20Model%20Pre-Training.md) #bert\n  32. [220728 Efficient Training of Language Models to Fill in the Middle](/rosinality/ml-papers/blob/main/papers/2022/220728%20Efficient%20Training%20of%20Language%20Models%20to%20Fill%20in%20the%20Middle.md) #mlm\n  33. [220805 Branch-Train-Merge](/rosinality/ml-papers/blob/main/papers/2022/220805%20Branch-Train-Merge.md) #product_of_experts #ensemble\n  34. [220805 Few-shot Learning with Retrieval Augmented Language Model](/rosinality/ml-papers/blob/main/papers/2022/220805%20Few-shot%20Learning%20with%20Retrieval%20Augmented%20Language%20Model.md) #retrieval #few_shot\n  35. [221110 The CRINGE Loss](/rosinality/ml-papers/blob/main/papers/2022/221110%20The%20CRINGE%20Loss.md) #safety\n  36. [230131 In-Context Retrieval-Augmented Language Models](/rosinality/ml-papers/blob/main/papers/2023/230131%20In-Context%20Retrieval-Augmented%20Language%20Models.md) #retrieval\n  37. [230503 CodeGen2](/rosinality/ml-papers/blob/main/papers/2023/230503%20CodeGen2.md)\n  38. [230526 MixCE](/rosinality/ml-papers/blob/main/papers/2023/230526%20MixCE.md)\n  39. [230612 Gradient Ascent Post-training Enhances Language Model Generalization](/rosinality/ml-papers/blob/main/papers/2023/230612%20Gradient%20Ascent%20Post-training%20Enhances%20Language%20Model%20Generalization.md)\n\n## local attention\n\n  1. [210323 Scaling Local Self-Attention for Parameter Efficient Visual Backbones](/rosinality/ml-papers/blob/main/papers/2021/210323%20Scaling%20Local%20Self-Attention%20for%20Parameter%20Efficient%20Visual%20Backbones.md)\n\n## loss\n\n  1. [200712 It Is Likely That Your Loss Should be a Likelihood](/rosinality/ml-papers/blob/main/papers/2020/200712%20It%20Is%20Likely%20That%20Your%20Loss%20Should%20be%20a%20Likelihood.md)\n\n## loss surface\n\n  1.", "start_char_idx": 134547, "end_char_idx": 137393, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f3194d3d-ce89-4614-8cc8-8ca1ff19799e": {"__data__": {"id_": "f3194d3d-ce89-4614-8cc8-8ca1ff19799e", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b92b11b5-bc2f-44f1-b03e-6b6190be6468", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "e4b9fa36503db61f6c3d13badd8ab9e8130976cf33cfdbde510651b3c49d8451", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e4be4a19-c952-4fb3-a822-b74dc194db7a", "node_type": "1", "metadata": {}, "hash": "5b4d3096e858ecf4760c956fa7058692db87b2db230ecbec00b4bc5fb814fd04", "class_name": "RelatedNodeInfo"}}, "text": "[210323 Scaling Local Self-Attention for Parameter Efficient Visual Backbones](/rosinality/ml-papers/blob/main/papers/2021/210323%20Scaling%20Local%20Self-Attention%20for%20Parameter%20Efficient%20Visual%20Backbones.md)\n\n## loss\n\n  1. [200712 It Is Likely That Your Loss Should be a Likelihood](/rosinality/ml-papers/blob/main/papers/2020/200712%20It%20Is%20Likely%20That%20Your%20Loss%20Should%20be%20a%20Likelihood.md)\n\n## loss surface\n\n  1. [210225 Loss Surface Simplexes for Mode Connecting Volumes and Fast Ensembling](/rosinality/ml-papers/blob/main/papers/2021/210225%20Loss%20Surface%20Simplexes%20for%20Mode%20Connecting%20Volumes%20and%20Fast%20Ensembling.md)\n\n## matting\n\n  1. [200401 Background Matting](/rosinality/ml-papers/blob/main/papers/2020/200401%20Background%20Matting.md)\n  2. [201123 Is a Green Screen Really Necessary for Real-Time Portrait Matting](/rosinality/ml-papers/blob/main/papers/2020/201123%20Is%20a%20Green%20Screen%20Really%20Necessary%20for%20Real-Time%20Portrait%20Matting.md)\n\n## memory\n\n  1. [200206 Product Kanerva Machines](/rosinality/ml-papers/blob/main/papers/2020/200206%20Product%20Kanerva%20Machines.md)\n\n## meta learning\n\n  1. [200221 Learning to Continually Learn](/rosinality/ml-papers/blob/main/papers/2020/200221%20Learning%20to%20Continually%20Learn.md) #continual_learning\n  2. [200312 Online Fast Adaptation and Knowledge Accumulation](/rosinality/ml-papers/blob/main/papers/2020/200312%20Online%20Fast%20Adaptation%20and%20Knowledge%20Accumulation.md)\n  3. [200401 Editable Neural Networks](/rosinality/ml-papers/blob/main/papers/2020/200401%20Editable%20Neural%20Networks.md)\n  4. [200706 Meta-Learning Symmetries by Reparameterization](/rosinality/ml-papers/blob/main/papers/2020/200706%20Meta-Learning%20Symmetries%20by%20Reparameterization.md) #group_equivariance\n\n## metric\n\n  1. [211025 The Efficiency Misnomer](/rosinality/ml-papers/blob/main/papers/2021/211025%20The%20Efficiency%20Misnomer.md)\n  2. [230307 Is ChatGPT a Good NLG Evaluator](/rosinality/ml-papers/blob/main/papers/2023/230307%20Is%20ChatGPT%20a%20Good%20NLG%20Evaluator.md)\n\n## metric learning\n\n  1. [200319 A unifying mutual information view of metric learning](/rosinality/ml-papers/blob/main/papers/2020/200319%20A%20unifying%20mutual%20information%20view%20of%20metric%20learning.md)\n\n## mixture of experts\n\n  1. [220202 Unified Scaling Laws for Routed Language Models](/rosinality/ml-papers/blob/main/papers/2022/220202%20Unified%20Scaling%20Laws%20for%20Routed%20Language%20Models.md)\n  2. [230220 TA-MoE](/rosinality/ml-papers/blob/main/papers/2023/230220%20TA-MoE.md)\n  3. [230310 Towards MoE Deployment](/rosinality/ml-papers/blob/main/papers/2023/230310%20Towards%20MoE%20Deployment.md)\n  4. [230311 A Novel Tensor-Expert Hybrid Parallelism Approach to Scale Mixture-of-Experts Training](/rosinality/ml-papers/blob/main/papers/2023/230311%20A%20Novel%20Tensor-Expert%20Hybrid%20Parallelism%20Approach%20to%20Scale%20Mixture-of-Experts%20Training.md)\n  5.", "start_char_idx": 136950, "end_char_idx": 139945, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e4be4a19-c952-4fb3-a822-b74dc194db7a": {"__data__": {"id_": "e4be4a19-c952-4fb3-a822-b74dc194db7a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f3194d3d-ce89-4614-8cc8-8ca1ff19799e", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "50ca80645ab759ee56b492644b533ffe4bdbc0beb2e342ac7620d5834daecfc6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "081ddc23-9b68-47d7-97df-e6b8144e70a6", "node_type": "1", "metadata": {}, "hash": "d39102e6cdaa4319e0694326c161519f8691ebed9ad81709469f14e72693296f", "class_name": "RelatedNodeInfo"}}, "text": "[230220 TA-MoE](/rosinality/ml-papers/blob/main/papers/2023/230220%20TA-MoE.md)\n  3. [230310 Towards MoE Deployment](/rosinality/ml-papers/blob/main/papers/2023/230310%20Towards%20MoE%20Deployment.md)\n  4. [230311 A Novel Tensor-Expert Hybrid Parallelism Approach to Scale Mixture-of-Experts Training](/rosinality/ml-papers/blob/main/papers/2023/230311%20A%20Novel%20Tensor-Expert%20Hybrid%20Parallelism%20Approach%20to%20Scale%20Mixture-of-Experts%20Training.md)\n  5. [230324 Scaling Expert Language Models with Unsupervised Domain Discovery](/rosinality/ml-papers/blob/main/papers/2023/230324%20Scaling%20Expert%20Language%20Models%20with%20Unsupervised%20Domain%20Discovery.md)\n  6. [230524 Mixture-of-Experts Meets Instruction Tuning](/rosinality/ml-papers/blob/main/papers/2023/230524%20Mixture-of-Experts%20Meets%20Instruction%20Tuning.md)\n\n## mixup\n\n  1. [201220 ResizeMix](/rosinality/ml-papers/blob/main/papers/2020/201220%20ResizeMix.md)\n  2. [211228 LINDA](/rosinality/ml-papers/blob/main/papers/2021/211228%20LINDA.md) #interpolation\n\n## mlm\n\n  1. [200424 Probabilistically Masked Language Model Capable of Autoregressive Generation in Arbitrary Word Order](/rosinality/ml-papers/blob/main/papers/2020/200424%20Probabilistically%20Masked%20Language%20Model%20Capable%20of%20Autoregressive%20Generation%20in%20Arbitrary%20Word%20Order.md) #language_generation\n  2. [210502 Larger-Scale Transformers for Multilingual Masked Language Modeling](/rosinality/ml-papers/blob/main/papers/2021/210502%20Larger-Scale%20Transformers%20for%20Multilingual%20Masked%20Language%20Modeling.md) #multilingual #scale\n  3. [220216 Should You Mask 15% in Masked Language Modeling](/rosinality/ml-papers/blob/main/papers/2022/220216%20Should%20You%20Mask%2015%25%20in%20Masked%20Language%20Modeling.md)\n  4. [220715 Position Prediction as an Effective Pretraining Strategy](/rosinality/ml-papers/blob/main/papers/2022/220715%20Position%20Prediction%20as%20an%20Effective%20Pretraining%20Strategy.md) #unsupervised_training\n  5. [220929 Bidirectional Language Models Are Also Few-shot Learners](/rosinality/ml-papers/blob/main/papers/2022/220929%20Bidirectional%20Language%20Models%20Are%20Also%20Few-shot%20Learners.md) #in_context_learning\n  6. [221006 XDoc](/rosinality/ml-papers/blob/main/papers/2022/221006%20XDoc.md) #layoutlm\n  7. [221114 EVA](/rosinality/ml-papers/blob/main/papers/2022/221114%20EVA.md) #clip\n  8. [230204 Representation Deficiency in Masked Language Modeling](/rosinality/ml-papers/blob/main/papers/2023/230204%20Representation%20Deficiency%20in%20Masked%20Language%20Modeling.md)\n\n## mlops\n\n  1. [230203 PyGlove](/rosinality/ml-papers/blob/main/papers/2023/230203%20PyGlove.md)\n\n## moe\n\n  1. [230802 From Sparse to Soft Mixtures of Experts](/rosinality/ml-papers/blob/main/papers/2023/230802%20From%20Sparse%20to%20Soft%20Mixtures%20of%20Experts.md)\n\n## multilingual\n\n  1.", "start_char_idx": 139477, "end_char_idx": 142366, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "081ddc23-9b68-47d7-97df-e6b8144e70a6": {"__data__": {"id_": "081ddc23-9b68-47d7-97df-e6b8144e70a6", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e4be4a19-c952-4fb3-a822-b74dc194db7a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "1cbe499089c90c7d2afe4020ea347441b33cb84fcdd07214a8a34ba967992b5c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f792e19d-6df0-4c8e-9537-d1c8980950a1", "node_type": "1", "metadata": {}, "hash": "0de48c2112683f1868238f59699e2f26dccbf4b014b06ba64add8d1c9a63e988", "class_name": "RelatedNodeInfo"}}, "text": "[221114 EVA](/rosinality/ml-papers/blob/main/papers/2022/221114%20EVA.md) #clip\n  8. [230204 Representation Deficiency in Masked Language Modeling](/rosinality/ml-papers/blob/main/papers/2023/230204%20Representation%20Deficiency%20in%20Masked%20Language%20Modeling.md)\n\n## mlops\n\n  1. [230203 PyGlove](/rosinality/ml-papers/blob/main/papers/2023/230203%20PyGlove.md)\n\n## moe\n\n  1. [230802 From Sparse to Soft Mixtures of Experts](/rosinality/ml-papers/blob/main/papers/2023/230802%20From%20Sparse%20to%20Soft%20Mixtures%20of%20Experts.md)\n\n## multilingual\n\n  1. [200207 A Multilingual View of Unsupervised Machine Translation](/rosinality/ml-papers/blob/main/papers/2020/200207%20A%20Multilingual%20View%20of%20Unsupervised%20Machine%20Translation.md) #nmt\n  2. [211015 Breaking Down Multilingual Machine Translation](/rosinality/ml-papers/blob/main/papers/2021/211015%20Breaking%20Down%20Multilingual%20Machine%20Translation.md) #nmt\n  3. [220512 Lifting the Curse of Multilinguality by Pre-training Modular Transformers](/rosinality/ml-papers/blob/main/papers/2022/220512%20Lifting%20the%20Curse%20of%20Multilinguality%20by%20Pre-training%20Modular%20Transformers.md) #adapter #mixture_of_experts\n  4. [230219 Scaling Laws for Multilingual Neural Machine Translation](/rosinality/ml-papers/blob/main/papers/2023/230219%20Scaling%20Laws%20for%20Multilingual%20Neural%20Machine%20Translation.md) #nmt #scaling\n  5. [230406 On the Pareto Front of Multilingual Neural Machine Translation](/rosinality/ml-papers/blob/main/papers/2023/230406%20On%20the%20Pareto%20Front%20of%20Multilingual%20Neural%20Machine%20Translation.md) #multitask #scaling\n  6. [230611 Language Versatilists vs. Specialists](/rosinality/ml-papers/blob/main/papers/2023/230611%20Language%20Versatilists%20vs.%20Specialists.md)\n\n## multimodal\n\n  1. [200401 Pixel-BERT](/rosinality/ml-papers/blob/main/papers/2020/200401%20Pixel-BERT.md)\n  2. [200513 INFOTABS](/rosinality/ml-papers/blob/main/papers/2020/200513%20INFOTABS.md)\n  3. [200514 Behind the Scene](/rosinality/ml-papers/blob/main/papers/2020/200514%20Behind%20the%20Scene.md)\n  4. [201130 Multimodal Pretraining Unmasked](/rosinality/ml-papers/blob/main/papers/2020/201130%20Multimodal%20Pretraining%20Unmasked.md)\n  5. [210928 VideoCLIP](/rosinality/ml-papers/blob/main/papers/2021/210928%20VideoCLIP.md) #video_transformer #retrieval\n  6. [211103 An Empirical Study of Training End-to-End Vision-and-Language Transformers](/rosinality/ml-papers/blob/main/papers/2021/211103%20An%20Empirical%20Study%20of%20Training%20End-to-End%20Vision-and-Language%20Transformers.md) #vision-language\n  7. [220512 A Generalist Agent](/rosinality/ml-papers/blob/main/papers/2022/220512%20A%20Generalist%20Agent.md) #reinforcement_learning\n  8. [220527 GIT](/rosinality/ml-papers/blob/main/papers/2022/220527%20GIT.md)\n  9.", "start_char_idx": 141805, "end_char_idx": 144640, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f792e19d-6df0-4c8e-9537-d1c8980950a1": {"__data__": {"id_": "f792e19d-6df0-4c8e-9537-d1c8980950a1", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "081ddc23-9b68-47d7-97df-e6b8144e70a6", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "e5431a9cfe504994a4877ac7f6024a59f90e56a32a6a717c76ffcf17600df42d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "212c8633-e701-469a-b1f3-6a29b66ec871", "node_type": "1", "metadata": {}, "hash": "7e279c1b2b655b76365f5763ec983dc7a2ee015fa2acfdc0cfb4c1b7ffaaca5d", "class_name": "RelatedNodeInfo"}}, "text": "[210928 VideoCLIP](/rosinality/ml-papers/blob/main/papers/2021/210928%20VideoCLIP.md) #video_transformer #retrieval\n  6. [211103 An Empirical Study of Training End-to-End Vision-and-Language Transformers](/rosinality/ml-papers/blob/main/papers/2021/211103%20An%20Empirical%20Study%20of%20Training%20End-to-End%20Vision-and-Language%20Transformers.md) #vision-language\n  7. [220512 A Generalist Agent](/rosinality/ml-papers/blob/main/papers/2022/220512%20A%20Generalist%20Agent.md) #reinforcement_learning\n  8. [220527 GIT](/rosinality/ml-papers/blob/main/papers/2022/220527%20GIT.md)\n  9. [230110 Scaling Laws for Generative Mixed-Modal Language Models](/rosinality/ml-papers/blob/main/papers/2023/230110%20Scaling%20Laws%20for%20Generative%20Mixed-Modal%20Language%20Models.md)\n  10. [230123 Zorro](/rosinality/ml-papers/blob/main/papers/2023/230123%20Zorro.md) #video #audio\n  11. [230201 mPLUG-2](/rosinality/ml-papers/blob/main/papers/2023/230201%20mPLUG-2.md)\n  12. [230202 Multimodal Chain-of-Thought Reasoning in Language Models](/rosinality/ml-papers/blob/main/papers/2023/230202%20Multimodal%20Chain-of-Thought%20Reasoning%20in%20Language%20Models.md) #vision-language\n  13. [230304 Prismer](/rosinality/ml-papers/blob/main/papers/2023/230304%20Prismer.md) #vision-language\n  14. [230308 Visual ChatGPT](/rosinality/ml-papers/blob/main/papers/2023/230308%20Visual%20ChatGPT.md) #chatgpt\n  15. [230507 X-LLM](/rosinality/ml-papers/blob/main/papers/2023/230507%20X-LLM.md)\n  16. [230511 Musketeer (All for One, and One for All)](/rosinality/ml-papers/blob/main/papers/2023/230511%20Musketeer%20%28All%20for%20One%2C%20and%20One%20for%20All%29.md) #vision-language #multitask\n  17. [230513 On the Hidden Mystery of OCR in Large Multimodal Models](/rosinality/ml-papers/blob/main/papers/2023/230513%20On%20the%20Hidden%20Mystery%20of%20OCR%20in%20Large%20Multimodal%20Models.md) #vision-language\n  18. [230529 PaLI-X](/rosinality/ml-papers/blob/main/papers/2023/230529%20PaLI-X.md) #vision-language\n  19. [230613 Image Captioners Are Scalable Vision Learners Too](/rosinality/ml-papers/blob/main/papers/2023/230613%20Image%20Captioners%20Are%20Scalable%20Vision%20Learners%20Too.md) #vision-language\n  20. [230626 Kosmos-2](/rosinality/ml-papers/blob/main/papers/2023/230626%20Kosmos-2.md) #vision-language\n\n## multimodal generation\n\n  1. [211122 L-Verse](/rosinality/ml-papers/blob/main/papers/2021/211122%20L-Verse.md)\n  2. [211124 N\u00dcWA](/rosinality/ml-papers/blob/main/papers/2021/211124%20N%C3%9CWA.md)\n\n## multitask\n\n  1. [200508 Transforming task representations to perform novel tasks](/rosinality/ml-papers/blob/main/papers/2020/200508%20Transforming%20task%20representations%20to%20perform%20novel%20tasks.md) #continual_learning\n  2.", "start_char_idx": 144052, "end_char_idx": 146800, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "212c8633-e701-469a-b1f3-6a29b66ec871": {"__data__": {"id_": "212c8633-e701-469a-b1f3-6a29b66ec871", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f792e19d-6df0-4c8e-9537-d1c8980950a1", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "1972f8a836f9b0bbc74e5793878a829181062c0e3f2d53466ba264e6b6b179a2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aab985eb-59c5-45de-b0d9-e916a7c38a5a", "node_type": "1", "metadata": {}, "hash": "3e57dbc5c3b1db55cfadb22a94b3d63a0fef54f90a23f9c88c7ef4b2dd6abcbe", "class_name": "RelatedNodeInfo"}}, "text": "[230626 Kosmos-2](/rosinality/ml-papers/blob/main/papers/2023/230626%20Kosmos-2.md) #vision-language\n\n## multimodal generation\n\n  1. [211122 L-Verse](/rosinality/ml-papers/blob/main/papers/2021/211122%20L-Verse.md)\n  2. [211124 N\u00dcWA](/rosinality/ml-papers/blob/main/papers/2021/211124%20N%C3%9CWA.md)\n\n## multitask\n\n  1. [200508 Transforming task representations to perform novel tasks](/rosinality/ml-papers/blob/main/papers/2020/200508%20Transforming%20task%20representations%20to%20perform%20novel%20tasks.md) #continual_learning\n  2. [200625 MTAdam](/rosinality/ml-papers/blob/main/papers/2020/200625%20MTAdam.md)\n  3. [210825 Multi-Task Self-Training for Learning General Representations](/rosinality/ml-papers/blob/main/papers/2021/210825%20Multi-Task%20Self-Training%20for%20Learning%20General%20Representations.md)\n  4. [220520 UViM](/rosinality/ml-papers/blob/main/papers/2022/220520%20UViM.md)\n  5. [230207 Exploring the Benefits of Training Expert Language Models over Instruction Tuning](/rosinality/ml-papers/blob/main/papers/2023/230207%20Exploring%20the%20Benefits%20of%20Training%20Expert%20Language%20Models%20over%20Instruction%20Tuning.md) #instruct\n  6. [230705 Flacuna](/rosinality/ml-papers/blob/main/papers/2023/230705%20Flacuna.md)\n\n## nas\n\n  1. [200324 BigNAS](/rosinality/ml-papers/blob/main/papers/2020/200324%20BigNAS.md)\n  2. [200326 Are Labels Necessary for Neural Architecture Search](/rosinality/ml-papers/blob/main/papers/2020/200326%20Are%20Labels%20Necessary%20for%20Neural%20Architecture%20Search.md) #unsupervised_training\n  3. [200406 Network Adjustment](/rosinality/ml-papers/blob/main/papers/2020/200406%20Network%20Adjustment.md)\n  4. [200412 FBNetV2](/rosinality/ml-papers/blob/main/papers/2020/200412%20FBNetV2.md)\n  5. [200428 Angle-based Search Space Shrinking for Neural Architecture Search](/rosinality/ml-papers/blob/main/papers/2020/200428%20Angle-based%20Search%20Space%20Shrinking%20for%20Neural%20Architecture%20Search.md)\n  6. [200506 Local Search is State of the Art for Neural Architecture Search](/rosinality/ml-papers/blob/main/papers/2020/200506%20Local%20Search%20is%20State%20of%20the%20Art%20for%20Neural%20Architecture%20Search.md)\n  7. [200507 Noisy Differentiable Architecture Search](/rosinality/ml-papers/blob/main/papers/2020/200507%20Noisy%20Differentiable%20Architecture%20Search.md)\n  8. [200602 FBNetV3](/rosinality/ml-papers/blob/main/papers/2020/200602%20FBNetV3.md) #hyperparameter #training #swa\n  9. [200720 NSGANetV2](/rosinality/ml-papers/blob/main/papers/2020/200720%20NSGANetV2.md)\n  10. [220831 Efficient Sparsely Activated Transformers](/rosinality/ml-papers/blob/main/papers/2022/220831%20Efficient%20Sparsely%20Activated%20Transformers.md) #moe\n\n## nerf\n\n  1. [201014 NeRF++](/rosinality/ml-papers/blob/main/papers/2020/201014%20NeRF%2B%2B.md)\n  2.", "start_char_idx": 146263, "end_char_idx": 149095, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aab985eb-59c5-45de-b0d9-e916a7c38a5a": {"__data__": {"id_": "aab985eb-59c5-45de-b0d9-e916a7c38a5a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "212c8633-e701-469a-b1f3-6a29b66ec871", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "58c91bfcae9ca46066c517b510c3dbc833b4d93ed7c5531d32884fa10fa4491e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "01cce7b7-e903-49bd-b511-19b923474bf9", "node_type": "1", "metadata": {}, "hash": "1ce140d755701057906254366c944849a8fd4aa15d92049a0fd5268a0c01ab0d", "class_name": "RelatedNodeInfo"}}, "text": "[200602 FBNetV3](/rosinality/ml-papers/blob/main/papers/2020/200602%20FBNetV3.md) #hyperparameter #training #swa\n  9. [200720 NSGANetV2](/rosinality/ml-papers/blob/main/papers/2020/200720%20NSGANetV2.md)\n  10. [220831 Efficient Sparsely Activated Transformers](/rosinality/ml-papers/blob/main/papers/2022/220831%20Efficient%20Sparsely%20Activated%20Transformers.md) #moe\n\n## nerf\n\n  1. [201014 NeRF++](/rosinality/ml-papers/blob/main/papers/2020/201014%20NeRF%2B%2B.md)\n  2. [201125 Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes](/rosinality/ml-papers/blob/main/papers/2020/201125%20Neural%20Scene%20Flow%20Fields%20for%20Space-Time%20View%20Synthesis%20of%20Dynamic%20Scenes.md)\n  3. [201127 D-NeRF](/rosinality/ml-papers/blob/main/papers/2020/201127%20D-NeRF.md)\n  4. [201203 Learned Initializations for Optimizing Coordinate-Based Neural](/rosinality/ml-papers/blob/main/papers/2020/201203%20Learned%20Initializations%20for%20Optimizing%20Coordinate-Based%20Neural.md) #implicit_representation\n  5. [201203 pixelNeRF](/rosinality/ml-papers/blob/main/papers/2020/201203%20pixelNeRF.md)\n  6. [201215 Object-Centric Neural Scene Rendering](/rosinality/ml-papers/blob/main/papers/2020/201215%20Object-Centric%20Neural%20Scene%20Rendering.md)\n  7. [210225 IBRNet](/rosinality/ml-papers/blob/main/papers/2021/210225%20IBRNet.md)\n  8. [210318 FastNeRF](/rosinality/ml-papers/blob/main/papers/2021/210318%20FastNeRF.md)\n  9. [210318 GNeRF](/rosinality/ml-papers/blob/main/papers/2021/210318%20GNeRF.md)\n  10. [210318 MVSNeRF](/rosinality/ml-papers/blob/main/papers/2021/210318%20MVSNeRF.md)\n  11. [210318 NeMI](/rosinality/ml-papers/blob/main/papers/2021/210318%20NeMI.md)\n  12. [210324 Mip-NeRF](/rosinality/ml-papers/blob/main/papers/2021/210324%20Mip-NeRF.md)\n  13. [210325 KiloNeRF](/rosinality/ml-papers/blob/main/papers/2021/210325%20KiloNeRF.md)\n  14. [210325 PlenOctrees for Real-time Rendering of Neural Radiance Fields](/rosinality/ml-papers/blob/main/papers/2021/210325%20PlenOctrees%20for%20Real-time%20Rendering%20of%20Neural%20Radiance%20Fields.md)\n  15. [210706 Depth-supervised NeRF](/rosinality/ml-papers/blob/main/papers/2021/210706%20Depth-supervised%20NeRF.md)\n  16. [210809 NeuralMVS](/rosinality/ml-papers/blob/main/papers/2021/210809%20NeuralMVS.md)\n  17. [211019 CIPS-3D](/rosinality/ml-papers/blob/main/papers/2021/211019%20CIPS-3D.md) #stylegan\n  18. [211129 Deblur-NeRF](/rosinality/ml-papers/blob/main/papers/2021/211129%20Deblur-NeRF.md)\n  19. [211129 HDR-NeRF](/rosinality/ml-papers/blob/main/papers/2021/211129%20HDR-NeRF.md)\n  20. [211129 Urban Radiance Fields](/rosinality/ml-papers/blob/main/papers/2021/211129%20Urban%20Radiance%20Fields.md)\n  21.", "start_char_idx": 148621, "end_char_idx": 151325, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "01cce7b7-e903-49bd-b511-19b923474bf9": {"__data__": {"id_": "01cce7b7-e903-49bd-b511-19b923474bf9", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aab985eb-59c5-45de-b0d9-e916a7c38a5a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "17061d878a64d0c32b16a7126777f99997b2568048227cd061340dc1957521fd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "85c04fbd-1a96-476f-89e5-234d7c3eaeea", "node_type": "1", "metadata": {}, "hash": "ca21b9a82e063b7705b22ab9b896b8be4fdd831791bc38d7433820fa933a0a28", "class_name": "RelatedNodeInfo"}}, "text": "[210809 NeuralMVS](/rosinality/ml-papers/blob/main/papers/2021/210809%20NeuralMVS.md)\n  17. [211019 CIPS-3D](/rosinality/ml-papers/blob/main/papers/2021/211019%20CIPS-3D.md) #stylegan\n  18. [211129 Deblur-NeRF](/rosinality/ml-papers/blob/main/papers/2021/211129%20Deblur-NeRF.md)\n  19. [211129 HDR-NeRF](/rosinality/ml-papers/blob/main/papers/2021/211129%20HDR-NeRF.md)\n  20. [211129 Urban Radiance Fields](/rosinality/ml-papers/blob/main/papers/2021/211129%20Urban%20Radiance%20Fields.md)\n  21. [211210 CityNeRF](/rosinality/ml-papers/blob/main/papers/2021/211210%20CityNeRF.md)\n  22. [221010 NerfAcc](/rosinality/ml-papers/blob/main/papers/2022/221010%20NerfAcc.md)\n  23. [230204 AV-NeRF](/rosinality/ml-papers/blob/main/papers/2023/230204%20AV-NeRF.md)\n  24. [230208 Nerfstudio](/rosinality/ml-papers/blob/main/papers/2023/230208%20Nerfstudio.md)\n  25. [230413 Zip-NeRF](/rosinality/ml-papers/blob/main/papers/2023/230413%20Zip-NeRF.md) #antialiasing\n  26. [230503 3D Gaussian Splatting for Real-Time Radiance Field Rendering](/rosinality/ml-papers/blob/main/papers/2023/230503%203D%20Gaussian%20Splatting%20for%20Real-Time%20Radiance%20Field%20Rendering.md) #neural_rendering\n\n## neural computer\n\n  1. [200720 Distributed Associative Memory Network with Memory Refreshing Loss](/rosinality/ml-papers/blob/main/papers/2020/200720%20Distributed%20Associative%20Memory%20Network%20with%20Memory%20Refreshing%20Loss.md)\n  2. [211130 Show Your Work](/rosinality/ml-papers/blob/main/papers/2021/211130%20Show%20Your%20Work.md)\n\n## neural ode\n\n  1. [200207 How to train your neural ODE](/rosinality/ml-papers/blob/main/papers/2020/200207%20How%20to%20train%20your%20neural%20ODE.md)\n  2. [200520 Neural Controlled Differential Equations](/rosinality/ml-papers/blob/main/papers/2020/200520%20Neural%20Controlled%20Differential%20Equations.md)\n  3. [200708 Learning Differential Equations that are Easy to Solve](/rosinality/ml-papers/blob/main/papers/2020/200708%20Learning%20Differential%20Equations%20that%20are%20Easy%20to%20Solve.md)\n\n## neural rendering\n\n  1. [200226 Learning to Shadow Hand-drawn Sketches](/rosinality/ml-papers/blob/main/papers/2020/200226%20Learning%20to%20Shadow%20Hand-drawn%20Sketches.md)\n  2. [200427 Neural Hair Rendering](/rosinality/ml-papers/blob/main/papers/2020/200427%20Neural%20Hair%20Rendering.md)\n  3. [200506 CONFIG](/rosinality/ml-papers/blob/main/papers/2020/200506%20CONFIG.md)\n  4. [201116 Stylized Neural Painting](/rosinality/ml-papers/blob/main/papers/2020/201116%20Stylized%20Neural%20Painting.md)\n  5. [201119 Creative Sketch Generation](/rosinality/ml-papers/blob/main/papers/2020/201119%20Creative%20Sketch%20Generation.md)\n  6. [201130 Animating Pictures with Eulerian Motion Fields](/rosinality/ml-papers/blob/main/papers/2020/201130%20Animating%20Pictures%20with%20Eulerian%20Motion%20Fields.md) #single_image\n  7.", "start_char_idx": 150830, "end_char_idx": 153694, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "85c04fbd-1a96-476f-89e5-234d7c3eaeea": {"__data__": {"id_": "85c04fbd-1a96-476f-89e5-234d7c3eaeea", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "01cce7b7-e903-49bd-b511-19b923474bf9", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "3cace8ac72bb900387f0005a114d559570087652cc3ab0c87beaae1a520817b0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54945853-e802-4db1-b5a9-8ca6ebd8bfa6", "node_type": "1", "metadata": {}, "hash": "c1b21534feab41929c4e696113e8bdcff11e8e368a7fbdd2668745565f77d714", "class_name": "RelatedNodeInfo"}}, "text": "[200506 CONFIG](/rosinality/ml-papers/blob/main/papers/2020/200506%20CONFIG.md)\n  4. [201116 Stylized Neural Painting](/rosinality/ml-papers/blob/main/papers/2020/201116%20Stylized%20Neural%20Painting.md)\n  5. [201119 Creative Sketch Generation](/rosinality/ml-papers/blob/main/papers/2020/201119%20Creative%20Sketch%20Generation.md)\n  6. [201130 Animating Pictures with Eulerian Motion Fields](/rosinality/ml-papers/blob/main/papers/2020/201130%20Animating%20Pictures%20with%20Eulerian%20Motion%20Fields.md) #single_image\n  7. [210319 Paint by Word](/rosinality/ml-papers/blob/main/papers/2021/210319%20Paint%20by%20Word.md)\n  8. [210512 Enhancing Photorealism Enhancement](/rosinality/ml-papers/blob/main/papers/2021/210512%20Enhancing%20Photorealism%20Enhancement.md)\n  9. [211013 ADOP](/rosinality/ml-papers/blob/main/papers/2021/211013%20ADOP.md)\n  10. [220728 Neural Strands](/rosinality/ml-papers/blob/main/papers/2022/220728%20Neural%20Strands.md)\n\n## nlp\n\n  1. [200518 (Re)construing Meaning in NLP](/rosinality/ml-papers/blob/main/papers/2020/200518%20%28Re%29construing%20Meaning%20in%20NLP.md)\n  2. [200715 Towards Debiasing Sentence Representations](/rosinality/ml-papers/blob/main/papers/2020/200715%20Towards%20Debiasing%20Sentence%20Representations.md) #bias\n  3. [220826 What Do NLP Researchers Believe](/rosinality/ml-papers/blob/main/papers/2022/220826%20What%20Do%20NLP%20Researchers%20Believe.md)\n\n## nmt\n\n  1. [200427 Lexically Constrained Neural Machine Translation with Levenshtein Transformer](/rosinality/ml-papers/blob/main/papers/2020/200427%20Lexically%20Constrained%20Neural%20Machine%20Translation%20with%20Levenshtein%20Transformer.md)\n  2. [200710 Learn to Use Future Information in Simultaneous Translation](/rosinality/ml-papers/blob/main/papers/2020/200710%20Learn%20to%20Use%20Future%20Information%20in%20Simultaneous%20Translation.md) #simultaneous_translation\n  3. [201224 Why Neural Machine Translation Prefers Empty Outputs](/rosinality/ml-papers/blob/main/papers/2020/201224%20Why%20Neural%20Machine%20Translation%20Prefers%20Empty%20Outputs.md) #hallucination\n  4. [230120 Is ChatGPT A Good Translator](/rosinality/ml-papers/blob/main/papers/2023/230120%20Is%20ChatGPT%20A%20Good%20Translator.md) #chatgpt\n  5. [230228 Large Language Models Are State-of-the-Art Evaluators of Translation Quality](/rosinality/ml-papers/blob/main/papers/2023/230228%20Large%20Language%20Models%20Are%20State-of-the-Art%20Evaluators%20of%20Translation%20Quality.md) #metric\n\n## non autoregressive\n\n  1. [200403 Aligned Cross Entropy for Non-Autoregressive Machine Translation](/rosinality/ml-papers/blob/main/papers/2020/200403%20Aligned%20Cross%20Entropy%20for%20Non-Autoregressive%20Machine%20Translation.md)\n  2. [200415 Non-Autoregressive Machine Translation with Latent Alignments](/rosinality/ml-papers/blob/main/papers/2020/200415%20Non-Autoregressive%20Machine%20Translation%20with%20Latent%20Alignments.md) #nmt #ctc\n  3.", "start_char_idx": 153167, "end_char_idx": 156121, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "54945853-e802-4db1-b5a9-8ca6ebd8bfa6": {"__data__": {"id_": "54945853-e802-4db1-b5a9-8ca6ebd8bfa6", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "85c04fbd-1a96-476f-89e5-234d7c3eaeea", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "8cdf5ed91aadc8dc45edc7b3ca605698c76a706beff78803c64326bc7f786229", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fe10d0cc-74fd-4188-bbe8-d31fe21b3a24", "node_type": "1", "metadata": {}, "hash": "3748f2573423b415ef6008a988aab96e4a4afe87a91aff6d5516a0c538b188d9", "class_name": "RelatedNodeInfo"}}, "text": "[200403 Aligned Cross Entropy for Non-Autoregressive Machine Translation](/rosinality/ml-papers/blob/main/papers/2020/200403%20Aligned%20Cross%20Entropy%20for%20Non-Autoregressive%20Machine%20Translation.md)\n  2. [200415 Non-Autoregressive Machine Translation with Latent Alignments](/rosinality/ml-papers/blob/main/papers/2020/200415%20Non-Autoregressive%20Machine%20Translation%20with%20Latent%20Alignments.md) #nmt #ctc\n  3. [200422 A Study of Non-autoregressive Model for Sequence Generation](/rosinality/ml-papers/blob/main/papers/2020/200422%20A%20Study%20of%20Non-autoregressive%20Model%20for%20Sequence%20Generation.md)\n  4. [201022 Parallel Tacotron](/rosinality/ml-papers/blob/main/papers/2020/201022%20Parallel%20Tacotron.md) #vae\n  5. [201025 Improved Mask-CTC for Non-Autoregressive End-to-End ASR](/rosinality/ml-papers/blob/main/papers/2020/201025%20Improved%20Mask-CTC%20for%20Non-Autoregressive%20End-to-End%20ASR.md) #ctc\n  6. [201125 FBWave](/rosinality/ml-papers/blob/main/papers/2020/201125%20FBWave.md) #vocoder #lightweight\n  7. [201207 EfficientTTS](/rosinality/ml-papers/blob/main/papers/2020/201207%20EfficientTTS.md) #tts\n  8. [211213 Step-unrolled Denoising Autoencoders for Text Generation](/rosinality/ml-papers/blob/main/papers/2021/211213%20Step-unrolled%20Denoising%20Autoencoders%20for%20Text%20Generation.md)\n  9. [220520 Lossless Acceleration for Seq2seq Generation with Aggressive Decoding](/rosinality/ml-papers/blob/main/papers/2022/220520%20Lossless%20Acceleration%20for%20Seq2seq%20Generation%20with%20Aggressive%20Decoding.md) #efficiency\n  10. [220909 Improved Masked Image Generation with Token-Critic](/rosinality/ml-papers/blob/main/papers/2022/220909%20Improved%20Masked%20Image%20Generation%20with%20Token-Critic.md) #mlm\n  11. [230301 StraIT](/rosinality/ml-papers/blob/main/papers/2023/230301%20StraIT.md) #image_generation #vq\n  12. [230516 SoundStorm](/rosinality/ml-papers/blob/main/papers/2023/230516%20SoundStorm.md) #audio_generation\n\n## norm free\n\n  1. [200310 ReZero is All You Need](/rosinality/ml-papers/blob/main/papers/2020/200310%20ReZero%20is%20All%20You%20Need.md) #initialization\n\n## normalization\n\n  1. [200122 Group Norm, Weight Standardization](/rosinality/ml-papers/blob/main/papers/2020/200122%20Group%20Norm%2C%20Weight%20Standardization.md)\n  2. [200122 Moving Average Batch Normalization](/rosinality/ml-papers/blob/main/papers/2020/200122%20Moving%20Average%20Batch%20Normalization.md)\n  3. [200122 StyleGAN 2](/rosinality/ml-papers/blob/main/papers/2020/200122%20StyleGAN%202.md) #GAN\n  4. [200130 Rethinking Normalization](/rosinality/ml-papers/blob/main/papers/2020/200130%20Rethinking%20Normalization.md)\n  5. [200130 Weight Standardization](/rosinality/ml-papers/blob/main/papers/2020/200130%20Weight%20Standardization.md) #weight\n  6.", "start_char_idx": 155694, "end_char_idx": 158509, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fe10d0cc-74fd-4188-bbe8-d31fe21b3a24": {"__data__": {"id_": "fe10d0cc-74fd-4188-bbe8-d31fe21b3a24", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "54945853-e802-4db1-b5a9-8ca6ebd8bfa6", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "802117cf9fa7d9933eaa7f073a626f40901568c92482b7176e585506c98c208c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7c64e9df-1a27-4c83-ae90-0045725d26d7", "node_type": "1", "metadata": {}, "hash": "9213ed3183ca55497419c771509d382e20084f7449fbf6105809f4cc4132bcdb", "class_name": "RelatedNodeInfo"}}, "text": "[200122 Moving Average Batch Normalization](/rosinality/ml-papers/blob/main/papers/2020/200122%20Moving%20Average%20Batch%20Normalization.md)\n  3. [200122 StyleGAN 2](/rosinality/ml-papers/blob/main/papers/2020/200122%20StyleGAN%202.md) #GAN\n  4. [200130 Rethinking Normalization](/rosinality/ml-papers/blob/main/papers/2020/200130%20Rethinking%20Normalization.md)\n  5. [200130 Weight Standardization](/rosinality/ml-papers/blob/main/papers/2020/200130%20Weight%20Standardization.md) #weight\n  6. [200224 Batch Normalization Biases Residual Blocks Towards the Identity Function](/rosinality/ml-papers/blob/main/papers/2020/200224%20Batch%20Normalization%20Biases%20Residual%20Blocks%20Towards%20the%20Identity%20Function.md) #optimization #norm_free #initialization\n  7. [200306 TaskNorm](/rosinality/ml-papers/blob/main/papers/2020/200306%20TaskNorm.md) #meta_learning\n  8. [200406 Evolving Normalization-Activation Layers](/rosinality/ml-papers/blob/main/papers/2020/200406%20Evolving%20Normalization-Activation%20Layers.md) #nas #activation\n  9. [200427 A Batch Normalized Inference Network Keeps the KL Vanishing Away](/rosinality/ml-papers/blob/main/papers/2020/200427%20A%20Batch%20Normalized%20Inference%20Network%20Keeps%20the%20KL%20Vanishing%20Away.md)\n  10. [201128 Batch Normalization with Enhanced Linear Transformation](/rosinality/ml-papers/blob/main/papers/2020/201128%20Batch%20Normalization%20with%20Enhanced%20Linear%20Transformation.md)\n  11. [211026 Revisiting Batch Normalization](/rosinality/ml-papers/blob/main/papers/2021/211026%20Revisiting%20Batch%20Normalization.md)\n  12. [230516 Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation](/rosinality/ml-papers/blob/main/papers/2023/230516%20Exploring%20the%20Impact%20of%20Layer%20Normalization%20for%20Zero-shot%20Neural%20Machine%20Translation.md)\n\n## object detection\n\n  1. [191118 Anchor-Free](/rosinality/ml-papers/blob/main/papers/2019/191118%20Anchor-Free.md)\n  2. [191118 CenterMask](/rosinality/ml-papers/blob/main/papers/2019/191118%20CenterMask.md) #instance_segmentation #backbone #1stage\n  3. [191121 EfficientDet](/rosinality/ml-papers/blob/main/papers/2019/191121%20EfficientDet.md)\n  4. [200103 BlendMask](/rosinality/ml-papers/blob/main/papers/2020/200103%20BlendMask.md) #instance_segmentation #1stage\n  5. [200122 SABL](/rosinality/ml-papers/blob/main/papers/2020/200122%20SABL.md)\n  6. [200129 AP Loss](/rosinality/ml-papers/blob/main/papers/2020/200129%20AP%20Loss.md) #loss\n  7. [200129 Backbone Reallocation for Detection](/rosinality/ml-papers/blob/main/papers/2020/200129%20Backbone%20Reallocation%20for%20Detection.md) #backbone #nas\n  8. [200129 Dense RepPoints](/rosinality/ml-papers/blob/main/papers/2020/200129%20Dense%20RepPoints.md)\n  9. [200129 DetNAS](/rosinality/ml-papers/blob/main/papers/2020/200129%20DetNAS.md) #nas #backbone\n  10. [200129 IOU-aware single stage detector](/rosinality/ml-papers/blob/main/papers/2020/200129%20IOU-aware%20single%20stage%20detector.md) #1stage\n  11.", "start_char_idx": 158013, "end_char_idx": 161040, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7c64e9df-1a27-4c83-ae90-0045725d26d7": {"__data__": {"id_": "7c64e9df-1a27-4c83-ae90-0045725d26d7", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fe10d0cc-74fd-4188-bbe8-d31fe21b3a24", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "d89b70b475150d8133ca3476cab796230f2dd028c3518eb1108f392d850e7fbd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "017aad40-317b-4269-a124-46c7947efde7", "node_type": "1", "metadata": {}, "hash": "0debd137ba8c5f00d4dedf82332b6851facf05c94ae24ceeff15285363a3d643", "class_name": "RelatedNodeInfo"}}, "text": "[200129 Backbone Reallocation for Detection](/rosinality/ml-papers/blob/main/papers/2020/200129%20Backbone%20Reallocation%20for%20Detection.md) #backbone #nas\n  8. [200129 Dense RepPoints](/rosinality/ml-papers/blob/main/papers/2020/200129%20Dense%20RepPoints.md)\n  9. [200129 DetNAS](/rosinality/ml-papers/blob/main/papers/2020/200129%20DetNAS.md) #nas #backbone\n  10. [200129 IOU-aware single stage detector](/rosinality/ml-papers/blob/main/papers/2020/200129%20IOU-aware%20single%20stage%20detector.md) #1stage\n  11. [200130 ATSS](/rosinality/ml-papers/blob/main/papers/2020/200130%20ATSS.md) #anchor #retinanet #fcos\n  12. [200130 AutoAugment](/rosinality/ml-papers/blob/main/papers/2020/200130%20AutoAugment.md) #augmentation #search\n  13. [200130 EfficientDet](/rosinality/ml-papers/blob/main/papers/2020/200130%20EfficientDet.md) #fpn\n  14. [200130 Keypoint Triplet](/rosinality/ml-papers/blob/main/papers/2020/200130%20Keypoint%20Triplet.md) #keypoint\n  15. [200130 Learning from Noisy Anchors](/rosinality/ml-papers/blob/main/papers/2020/200130%20Learning%20from%20Noisy%20Anchors.md)\n  16. [200130 Multiple Anchor Learning](/rosinality/ml-papers/blob/main/papers/2020/200130%20Multiple%20Anchor%20Learning.md) #anchor\n  17. [200130 Objects as Points](/rosinality/ml-papers/blob/main/papers/2020/200130%20Objects%20as%20Points.md) #keypoint\n  18. [200130 Soft Anchor-Point](/rosinality/ml-papers/blob/main/papers/2020/200130%20Soft%20Anchor-Point.md) #anchor\n  19. [200211 Object Detection as a Positive-Unlabeled Problem](/rosinality/ml-papers/blob/main/papers/2020/200211%20Object%20Detection%20as%20a%20Positive-Unlabeled%20Problem.md) #positive_unlabled #dataset\n  20. [200212 Solving Missing-Annotation Object Detection with Background](/rosinality/ml-papers/blob/main/papers/2020/200212%20Solving%20Missing-Annotation%20Object%20Detection%20with%20Background.md) #dataset #noise\n  21. [200218 Universal-RCNN](/rosinality/ml-papers/blob/main/papers/2020/200218%20Universal-RCNN.md) #multi_dataset #graph\n  22. [200316 Frustratingly Simple Few-Shot Object Detection](/rosinality/ml-papers/blob/main/papers/2020/200316%20Frustratingly%20Simple%20Few-Shot%20Object%20Detection.md) #few_shot\n  23. [200317 Revisiting the Sibling Head in Object Detector](/rosinality/ml-papers/blob/main/papers/2020/200317%20Revisiting%20the%20Sibling%20Head%20in%20Object%20Detector.md)\n  24. [200319 Revisiting the Sibling Head in Object Detector](/rosinality/ml-papers/blob/main/papers/2020/200319%20Revisiting%20the%20Sibling%20Head%20in%20Object%20Detector.md) #review\n  25. [200320 CentripetalNet](/rosinality/ml-papers/blob/main/papers/2020/200320%20CentripetalNet.md) #keypoint\n  26. [200413 Dynamic R-CNN](/rosinality/ml-papers/blob/main/papers/2020/200413%20Dynamic%20R-CNN.md)\n  27. [200423 YOLOv4](/rosinality/ml-papers/blob/main/papers/2020/200423%20YOLOv4.md)\n  28.", "start_char_idx": 160521, "end_char_idx": 163392, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "017aad40-317b-4269-a124-46c7947efde7": {"__data__": {"id_": "017aad40-317b-4269-a124-46c7947efde7", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c64e9df-1a27-4c83-ae90-0045725d26d7", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "cc072975b3cf98650cee7c0b55c902fcf80af3e4a8ecddd35d21ea3089123157", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "184affb0-5e02-4812-a443-37cf2d3b126e", "node_type": "1", "metadata": {}, "hash": "8d98cbb31a7057a38a8bf806b5f97695cefc1aece175bf4c0fa0b64fd3b6728e", "class_name": "RelatedNodeInfo"}}, "text": "[200319 Revisiting the Sibling Head in Object Detector](/rosinality/ml-papers/blob/main/papers/2020/200319%20Revisiting%20the%20Sibling%20Head%20in%20Object%20Detector.md) #review\n  25. [200320 CentripetalNet](/rosinality/ml-papers/blob/main/papers/2020/200320%20CentripetalNet.md) #keypoint\n  26. [200413 Dynamic R-CNN](/rosinality/ml-papers/blob/main/papers/2020/200413%20Dynamic%20R-CNN.md)\n  27. [200423 YOLOv4](/rosinality/ml-papers/blob/main/papers/2020/200423%20YOLOv4.md)\n  28. [200511 Scope Head for Accurate Localization in Object Detection](/rosinality/ml-papers/blob/main/papers/2020/200511%20Scope%20Head%20for%20Accurate%20Localization%20in%20Object%20Detection.md)\n  29. [200526 End-to-End Object Detection with Transformers](/rosinality/ml-papers/blob/main/papers/2020/200526%20End-to-End%20Object%20Detection%20with%20Transformers.md) #end2end #matching\n  30. [200603 DetectoRS](/rosinality/ml-papers/blob/main/papers/2020/200603%20DetectoRS.md)\n  31. [200611 Rethinking Pre-training and Self-training](/rosinality/ml-papers/blob/main/papers/2020/200611%20Rethinking%20Pre-training%20and%20Self-training.md) #semi_supervised_learning #transfer\n  32. [200706 LabelEnc](/rosinality/ml-papers/blob/main/papers/2020/200706%20LabelEnc.md) #distillation\n  33. [200707 AutoAssign](/rosinality/ml-papers/blob/main/papers/2020/200707%20AutoAssign.md) #anchor_free\n  34. [200714 AQD](/rosinality/ml-papers/blob/main/papers/2020/200714%20AQD.md) #quantization\n  35. [200715 Probabilistic Anchor Assignment with IoU Prediction for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/200715%20Probabilistic%20Anchor%20Assignment%20with%20IoU%20Prediction%20for%20Object%20Detection.md) #anchor #1stage\n  36. [200716 RepPoints V2](/rosinality/ml-papers/blob/main/papers/2020/200716%20RepPoints%20V2.md) #1stage #anchor_free\n  37. [200723 PP-YOLO](/rosinality/ml-papers/blob/main/papers/2020/200723%20PP-YOLO.md) #tuning\n  38. [200723 The Devil is in Classification](/rosinality/ml-papers/blob/main/papers/2020/200723%20The%20Devil%20is%20in%20Classification.md) #longtail\n  39. [200727 Corner Proposal Network for Anchor-free, Two-stage Object Detection](/rosinality/ml-papers/blob/main/papers/2020/200727%20Corner%20Proposal%20Network%20for%20Anchor-free%2C%20Two-stage%20Object%20Detection.md) #anchor_free #2stage\n  40. [201116 Scaled-YOLOv4](/rosinality/ml-papers/blob/main/papers/2020/201116%20Scaled-YOLOv4.md)\n  41. [201118 End-to-End Object Detection with Adaptive Clustering Transformer](/rosinality/ml-papers/blob/main/papers/2020/201118%20End-to-End%20Object%20Detection%20with%20Adaptive%20Clustering%20Transformer.md) #detr #end2end #efficiency\n  42. [201121 Rethinking Transformer-based Set Prediction for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/201121%20Rethinking%20Transformer-based%20Set%20Prediction%20for%20Object%20Detection.md) #detr #end2end #efficiency\n  43.", "start_char_idx": 162907, "end_char_idx": 165824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "184affb0-5e02-4812-a443-37cf2d3b126e": {"__data__": {"id_": "184affb0-5e02-4812-a443-37cf2d3b126e", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "017aad40-317b-4269-a124-46c7947efde7", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "fd8714bc8dc4f6f7bea33e0fbe4ea97d3ea638bdf40c7971a59d698377b87057", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8bb03e2b-a7c8-47ed-aa3f-550a07cb0319", "node_type": "1", "metadata": {}, "hash": "aff1775bf7fece9d2db6bd723eb61fb61a35fa0dad54bd3d56eeac701a3f4c9b", "class_name": "RelatedNodeInfo"}}, "text": "[201116 Scaled-YOLOv4](/rosinality/ml-papers/blob/main/papers/2020/201116%20Scaled-YOLOv4.md)\n  41. [201118 End-to-End Object Detection with Adaptive Clustering Transformer](/rosinality/ml-papers/blob/main/papers/2020/201118%20End-to-End%20Object%20Detection%20with%20Adaptive%20Clustering%20Transformer.md) #detr #end2end #efficiency\n  42. [201121 Rethinking Transformer-based Set Prediction for Object Detection](/rosinality/ml-papers/blob/main/papers/2020/201121%20Rethinking%20Transformer-based%20Set%20Prediction%20for%20Object%20Detection.md) #detr #end2end #efficiency\n  43. [201124 Sparse R-CNN](/rosinality/ml-papers/blob/main/papers/2020/201124%20Sparse%20R-CNN.md)\n  44. [201128 Class-agnostic Object Detection](/rosinality/ml-papers/blob/main/papers/2020/201128%20Class-agnostic%20Object%20Detection.md)\n  45. [201207 End-to-End Object Detection with Fully Convolutional Network](/rosinality/ml-papers/blob/main/papers/2020/201207%20End-to-End%20Object%20Detection%20with%20Fully%20Convolutional%20Network.md) #end2end\n  46. [201223 SWA Object Detection](/rosinality/ml-papers/blob/main/papers/2020/201223%20SWA%20Object%20Detection.md) #swa\n  47. [201227 Towards A Category-extended Object Detector without Relabeling or](/rosinality/ml-papers/blob/main/papers/2020/201227%20Towards%20A%20Category-extended%20Object%20Detector%20without%20Relabeling%20or.md) #continual_learning\n  48. [210225 Simple multi-dataset detection](/rosinality/ml-papers/blob/main/papers/2021/210225%20Simple%20multi-dataset%20detection.md) #multi_dataset\n  49. [210316 You Only Look One-level Feature](/rosinality/ml-papers/blob/main/papers/2021/210316%20You%20Only%20Look%20One-level%20Feature.md)\n  50. [210325 USB](/rosinality/ml-papers/blob/main/papers/2021/210325%20USB.md) #dataset\n  51. [210417 TransVG](/rosinality/ml-papers/blob/main/papers/2021/210417%20TransVG.md) #visual_grounding\n  52. [210420 PP-YOLOv2](/rosinality/ml-papers/blob/main/papers/2021/210420%20PP-YOLOv2.md) #yolo\n  53. [210426 MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding](/rosinality/ml-papers/blob/main/papers/2021/210426%20MDETR%20--%20Modulated%20Detection%20for%20End-to-End%20Multi-Modal%20Understanding.md) #detr #visual_grounding\n  54. [210601 You Only Look at One Sequence](/rosinality/ml-papers/blob/main/papers/2021/210601%20You%20Only%20Look%20at%20One%20Sequence.md) #vit\n  55. [210615 Dynamic Head](/rosinality/ml-papers/blob/main/papers/2021/210615%20Dynamic%20Head.md) #attention\n  56. [210718 YOLOX](/rosinality/ml-papers/blob/main/papers/2021/210718%20YOLOX.md) #yolo\n  57. [210728 SimROD](/rosinality/ml-papers/blob/main/papers/2021/210728%20SimROD.md) #domain_adaptation #self_supervised\n  58. [210922 Pix2seq](/rosinality/ml-papers/blob/main/papers/2021/210922%20Pix2seq.md) #detr #autoregressive_model\n  59.", "start_char_idx": 165243, "end_char_idx": 168066, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8bb03e2b-a7c8-47ed-aa3f-550a07cb0319": {"__data__": {"id_": "8bb03e2b-a7c8-47ed-aa3f-550a07cb0319", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "184affb0-5e02-4812-a443-37cf2d3b126e", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "08cafd6de4eedbc0a6c387ec68822004d4c96cd5afd82c6852ae59fdbc63fbb1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "20bbdb7a-ea09-4232-9ae0-93ef74b0485f", "node_type": "1", "metadata": {}, "hash": "25d438421db697cdde1f9988fc47abe996a904848ceb0597674ea14e214772ca", "class_name": "RelatedNodeInfo"}}, "text": "[210615 Dynamic Head](/rosinality/ml-papers/blob/main/papers/2021/210615%20Dynamic%20Head.md) #attention\n  56. [210718 YOLOX](/rosinality/ml-papers/blob/main/papers/2021/210718%20YOLOX.md) #yolo\n  57. [210728 SimROD](/rosinality/ml-papers/blob/main/papers/2021/210728%20SimROD.md) #domain_adaptation #self_supervised\n  58. [210922 Pix2seq](/rosinality/ml-papers/blob/main/papers/2021/210922%20Pix2seq.md) #detr #autoregressive_model\n  59. [210929 Localizing Objects with Self-Supervised Transformers and no Labels](/rosinality/ml-papers/blob/main/papers/2021/210929%20Localizing%20Objects%20with%20Self-Supervised%20Transformers%20and%20no%20Labels.md) #self_supervised #self_supervised_discovery #salient_object_detection\n  60. [211101 PP-PicoDet](/rosinality/ml-papers/blob/main/papers/2021/211101%20PP-PicoDet.md) #lightweight\n  61. [211122 Benchmarking Detection Transfer Learning with Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/211122%20Benchmarking%20Detection%20Transfer%20Learning%20with%20Vision%20Transformers.md) #unsupervised_training #vit\n  62. [211123 Dynamic DETR](/rosinality/ml-papers/blob/main/papers/2021/211123%20Dynamic%20DETR.md)\n  63. [211129 Sparse DETR](/rosinality/ml-papers/blob/main/papers/2021/211129%20Sparse%20DETR.md) #detr\n  64. [220107 Detecting Twenty-thousand Classes using Image-level Supervision](/rosinality/ml-papers/blob/main/papers/2022/220107%20Detecting%20Twenty-thousand%20Classes%20using%20Image-level%20Supervision.md) #weak_supervision\n  65. [220330 Exploring Plain Vision Transformer Backbones for Object Detection](/rosinality/ml-papers/blob/main/papers/2022/220330%20Exploring%20Plain%20Vision%20Transformer%20Backbones%20for%20Object%20Detection.md) #vit #instance_segmentation\n  66. [220615 A Unified Sequence Interface for Vision Tasks](/rosinality/ml-papers/blob/main/papers/2022/220615%20A%20Unified%20Sequence%20Interface%20for%20Vision%20Tasks.md) #multitask #instance_segmentation #keypoint\n\n## ocr\n\n  1. [191231 LayoutLM](/rosinality/ml-papers/blob/main/papers/2019/191231%20LayoutLM.md)\n  2. [200217 Text Perceptron](/rosinality/ml-papers/blob/main/papers/2020/200217%20Text%20Perceptron.md)\n  3. [210415 Rethinking Text Line Recognition Models](/rosinality/ml-papers/blob/main/papers/2021/210415%20Rethinking%20Text%20Line%20Recognition%20Models.md)\n  4. [220107 Data-Efficient Information Extraction from Form-Like Documents](/rosinality/ml-papers/blob/main/papers/2022/220107%20Data-Efficient%20Information%20Extraction%20from%20Form-Like%20Documents.md) #information_extraction\n  5. [220328 Towards End-to-End Unified Scene Text Detection and Layout Analysis](/rosinality/ml-papers/blob/main/papers/2022/220328%20Towards%20End-to-End%20Unified%20Scene%20Text%20Detection%20and%20Layout%20Analysis.md)\n  6. [220416 Pushing the Performance Limit of Scene Text Recognizer without Human Annotation](/rosinality/ml-papers/blob/main/papers/2022/220416%20Pushing%20the%20Performance%20Limit%20of%20Scene%20Text%20Recognizer%20without%20Human%20Annotation.md)\n\n## open set recognition\n\n  1.", "start_char_idx": 167628, "end_char_idx": 170697, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20bbdb7a-ea09-4232-9ae0-93ef74b0485f": {"__data__": {"id_": "20bbdb7a-ea09-4232-9ae0-93ef74b0485f", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8bb03e2b-a7c8-47ed-aa3f-550a07cb0319", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "95429ff8c9d7d35a3744c5923f0d8836947f5c6dcd79b12c5931f3f86c8ec467", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6e29bc09-fd3d-432d-9621-09ca062d2689", "node_type": "1", "metadata": {}, "hash": "6cae9563f3c9b4ab0ba2331f71fd556fd81f8b6d76868d46b9397906211a8a13", "class_name": "RelatedNodeInfo"}}, "text": "[220328 Towards End-to-End Unified Scene Text Detection and Layout Analysis](/rosinality/ml-papers/blob/main/papers/2022/220328%20Towards%20End-to-End%20Unified%20Scene%20Text%20Detection%20and%20Layout%20Analysis.md)\n  6. [220416 Pushing the Performance Limit of Scene Text Recognizer without Human Annotation](/rosinality/ml-papers/blob/main/papers/2022/220416%20Pushing%20the%20Performance%20Limit%20of%20Scene%20Text%20Recognizer%20without%20Human%20Annotation.md)\n\n## open set recognition\n\n  1. [211012 Open-Set Recognition](/rosinality/ml-papers/blob/main/papers/2021/211012%20Open-Set%20Recognition.md)\n\n## optimization\n\n  1. [200221 The Break-Even Point on Optimization Trajectories of Deep Neural Networks](/rosinality/ml-papers/blob/main/papers/2020/200221%20The%20Break-Even%20Point%20on%20Optimization%20Trajectories%20of%20Deep%20Neural%20Networks.md) #loss #training\n  2. [200224 The Early Phase of Neural Network Training](/rosinality/ml-papers/blob/main/papers/2020/200224%20The%20Early%20Phase%20of%20Neural%20Network%20Training.md)\n  3. [200227 Using a thousand optimization tasks to learn hyperparameter search strategies](/rosinality/ml-papers/blob/main/papers/2020/200227%20Using%20a%20thousand%20optimization%20tasks%20to%20learn%20hyperparameter%20search%20strategies.md) #optimizer #hyperparameter\n  4. [200228 A Self-Tuning Actor-Critic Algorithm](/rosinality/ml-papers/blob/main/papers/2020/200228%20A%20Self-Tuning%20Actor-Critic%20Algorithm.md) #reinforcement_learning #hyperparameter #meta_learning\n  5. [200316 Weak and Strong Gradient Directions](/rosinality/ml-papers/blob/main/papers/2020/200316%20Weak%20and%20Strong%20Gradient%20Directions.md)\n  6. [200403 Gradient Centralization](/rosinality/ml-papers/blob/main/papers/2020/200403%20Gradient%20Centralization.md) #training\n  7. [200508 An Investigation of Why Overparameterization Exacerbates Spurious](/rosinality/ml-papers/blob/main/papers/2020/200508%20An%20Investigation%20of%20Why%20Overparameterization%20Exacerbates%20Spurious.md) #training\n  8. [200519 One Size Fits All](/rosinality/ml-papers/blob/main/papers/2020/200519%20One%20Size%20Fits%20All.md)\n\n## optimizer\n\n  1. [200130 LAMB](/rosinality/ml-papers/blob/main/papers/2020/200130%20LAMB.md) #large_batch\n  2. [211006 8-bit Optimizers via Block-wise Quantization](/rosinality/ml-papers/blob/main/papers/2021/211006%208-bit%20Optimizers%20via%20Block-wise%20Quantization.md)\n  3. [221117 VeLO](/rosinality/ml-papers/blob/main/papers/2022/221117%20VeLO.md)\n  4. [230118 Learning-Rate-Free Learning by D-Adaptation](/rosinality/ml-papers/blob/main/papers/2023/230118%20Learning-Rate-Free%20Learning%20by%20D-Adaptation.md)\n  5. [230213 Symbolic Discovery of Optimization Algorithms](/rosinality/ml-papers/blob/main/papers/2023/230213%20Symbolic%20Discovery%20of%20Optimization%20Algorithms.md) #search\n  6. [230523 Sophia](/rosinality/ml-papers/blob/main/papers/2023/230523%20Sophia.md)\n\n## oriented object detection\n\n  1. [200129 Modulated Loss](/rosinality/ml-papers/blob/main/papers/2020/200129%20Modulated%20Loss.md)\n  2.", "start_char_idx": 170198, "end_char_idx": 173272, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6e29bc09-fd3d-432d-9621-09ca062d2689": {"__data__": {"id_": "6e29bc09-fd3d-432d-9621-09ca062d2689", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "20bbdb7a-ea09-4232-9ae0-93ef74b0485f", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "2fbb03fdb329a83e316f5081169bb0f4e0e9f9bc3bc57bde18f241fb40ebe293", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "71697a0f-dcf8-4450-82e7-30355655667c", "node_type": "1", "metadata": {}, "hash": "3b1ab1dc994d16d53c46ae4b877bbfd74dbdda5f9b2fb05f4980803d331a1f8b", "class_name": "RelatedNodeInfo"}}, "text": "[230118 Learning-Rate-Free Learning by D-Adaptation](/rosinality/ml-papers/blob/main/papers/2023/230118%20Learning-Rate-Free%20Learning%20by%20D-Adaptation.md)\n  5. [230213 Symbolic Discovery of Optimization Algorithms](/rosinality/ml-papers/blob/main/papers/2023/230213%20Symbolic%20Discovery%20of%20Optimization%20Algorithms.md) #search\n  6. [230523 Sophia](/rosinality/ml-papers/blob/main/papers/2023/230523%20Sophia.md)\n\n## oriented object detection\n\n  1. [200129 Modulated Loss](/rosinality/ml-papers/blob/main/papers/2020/200129%20Modulated%20Loss.md)\n  2. [200129 Oriented Objects as Middle Lines](/rosinality/ml-papers/blob/main/papers/2020/200129%20Oriented%20Objects%20as%20Middle%20Lines.md)\n\n## out of distribution\n\n  1. [200509 Generalizing Outside the Training Set](/rosinality/ml-papers/blob/main/papers/2020/200509%20Generalizing%20Outside%20the%20Training%20Set.md)\n  2. [200519 Bridging the Gap Between Training and Inference for Spatio-Temporal Forecasting](/rosinality/ml-papers/blob/main/papers/2020/200519%20Bridging%20the%20Gap%20Between%20Training%20and%20Inference%20for%20Spatio-Temporal%20Forecasting.md)\n\n## panoptic segmentation\n\n  1. [200129 Bridge gap of traininfer Panoptic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/200129%20Bridge%20gap%20of%20traininfer%20Panoptic%20Segmentation.md)\n  2. [200130 Panoptic-DeepLab](/rosinality/ml-papers/blob/main/papers/2020/200130%20Panoptic-DeepLab.md)\n  3. [200218 Towards Bounding-Box Free Panoptic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/200218%20Towards%20Bounding-Box%20Free%20Panoptic%20Segmentation.md) #box_free\n  4. [200404 Pixel Consensus Voting for Panoptic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/200404%20Pixel%20Consensus%20Voting%20for%20Panoptic%20Segmentation.md)\n  5. [200421 Panoptic-based Image Synthesis](/rosinality/ml-papers/blob/main/papers/2020/200421%20Panoptic-based%20Image%20Synthesis.md) #neural_rendering\n  6. [201123 Scaling Wide Residual Networks for Panoptic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/201123%20Scaling%20Wide%20Residual%20Networks%20for%20Panoptic%20Segmentation.md) #scale\n  7. [201201 Fully Convolutional Networks for Panoptic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/201201%20Fully%20Convolutional%20Networks%20for%20Panoptic%20Segmentation.md) #dynamic_conv\n  8. [201202 Single-shot Path Integrated Panoptic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/201202%20Single-shot%20Path%20Integrated%20Panoptic%20Segmentation.md) #dynamic_conv\n  9. [210910 Panoptic Narrative Grounding](/rosinality/ml-papers/blob/main/papers/2021/210910%20Panoptic%20Narrative%20Grounding.md) #visual_grounding\n\n## perceptual loss\n\n  1. [200206 Image Fine-grained Inpainting](/rosinality/ml-papers/blob/main/papers/2020/200206%20Image%20Fine-grained%20Inpainting.md) #inpainting\n  2.", "start_char_idx": 172710, "end_char_idx": 175593, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "71697a0f-dcf8-4450-82e7-30355655667c": {"__data__": {"id_": "71697a0f-dcf8-4450-82e7-30355655667c", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6e29bc09-fd3d-432d-9621-09ca062d2689", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "8763f854ab6046df67fd7cc49159b3289c01877c4967b4cac0615f881dd1f96c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f3d15e56-a243-4c8b-a1b3-eec78b49523a", "node_type": "1", "metadata": {}, "hash": "e9eccdc017c8649108a86ee716c9bba6f6319ec4911ea1a158032cc97c1aae14", "class_name": "RelatedNodeInfo"}}, "text": "[201202 Single-shot Path Integrated Panoptic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/201202%20Single-shot%20Path%20Integrated%20Panoptic%20Segmentation.md) #dynamic_conv\n  9. [210910 Panoptic Narrative Grounding](/rosinality/ml-papers/blob/main/papers/2021/210910%20Panoptic%20Narrative%20Grounding.md) #visual_grounding\n\n## perceptual loss\n\n  1. [200206 Image Fine-grained Inpainting](/rosinality/ml-papers/blob/main/papers/2020/200206%20Image%20Fine-grained%20Inpainting.md) #inpainting\n  2. [200515 Enhancing Perceptual Loss with Adversarial Feature Matching for Super-Resolution](/rosinality/ml-papers/blob/main/papers/2020/200515%20Enhancing%20Perceptual%20Loss%20with%20Adversarial%20Feature%20Matching%20for%20Super-Resolution.md)\n  3. [200626 A Loss Function for Generative Neural Networks Based on Watson's](/rosinality/ml-papers/blob/main/papers/2020/200626%20A%20Loss%20Function%20for%20Generative%20Neural%20Networks%20Based%20on%20Watson%27s.md)\n  4. [201223 Focal Frequency Loss for Image Reconstruction and Synthesis](/rosinality/ml-papers/blob/main/papers/2020/201223%20Focal%20Frequency%20Loss%20for%20Image%20Reconstruction%20and%20Synthesis.md) #loss\n\n## point cloud\n\n  1. [220325 Point2Seq](/rosinality/ml-papers/blob/main/papers/2022/220325%20Point2Seq.md)\n\n## pooling\n\n  1. [200325 What Deep CNNs Benefit from Global Covariance Pooling](/rosinality/ml-papers/blob/main/papers/2020/200325%20What%20Deep%20CNNs%20Benefit%20from%20Global%20Covariance%20Pooling.md)\n  2. [200330 Strip Pooling](/rosinality/ml-papers/blob/main/papers/2020/200330%20Strip%20Pooling.md)\n\n## pose\n\n  1. [200729 Unselfie](/rosinality/ml-papers/blob/main/papers/2020/200729%20Unselfie.md) #inpainting\n  2. [210913 Pose with Style](/rosinality/ml-papers/blob/main/papers/2021/210913%20Pose%20with%20Style.md)\n\n## positional encoding\n\n  1. [200628 Rethinking Positional Encoding in Language Pre-training](/rosinality/ml-papers/blob/main/papers/2020/200628%20Rethinking%20Positional%20Encoding%20in%20Language%20Pre-training.md)\n  2. [210408 Modulated Periodic Activations for Generalizable Local Functional](/rosinality/ml-papers/blob/main/papers/2021/210408%20Modulated%20Periodic%20Activations%20for%20Generalizable%20Local%20Functional.md) #periodic_activation #implicit_representation\n  3. [210506 ACORN](/rosinality/ml-papers/blob/main/papers/2021/210506%20ACORN.md) #implicit_representation\n  4. [210706 Rethinking Positional Encoding](/rosinality/ml-papers/blob/main/papers/2021/210706%20Rethinking%20Positional%20Encoding.md)\n  5. [230531 The Impact of Positional Encoding on Length Generalization in Transformers](/rosinality/ml-papers/blob/main/papers/2023/230531%20The%20Impact%20of%20Positional%20Encoding%20on%20Length%20Generalization%20in%20Transformers.md)\n  6. [230627 Extending Context Window of Large Language Models via Positional Interpolation](/rosinality/ml-papers/blob/main/papers/2023/230627%20Extending%20Context%20Window%20of%20Large%20Language%20Models%20via%20Positional%20Interpolation.md)\n\n## practice\n\n  1.", "start_char_idx": 175082, "end_char_idx": 178131, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f3d15e56-a243-4c8b-a1b3-eec78b49523a": {"__data__": {"id_": "f3d15e56-a243-4c8b-a1b3-eec78b49523a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "71697a0f-dcf8-4450-82e7-30355655667c", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "8463596c4cf5be3953b28df7d8e52829f5d92dc28d97be0e5a2d2f680c986c44", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cbf26d84-2b36-463a-96f6-7b4bc7c975dc", "node_type": "1", "metadata": {}, "hash": "609d75acdf95e7386615ef212f64f1ab64c97d9f84c12db043136767fdb3343a", "class_name": "RelatedNodeInfo"}}, "text": "[210706 Rethinking Positional Encoding](/rosinality/ml-papers/blob/main/papers/2021/210706%20Rethinking%20Positional%20Encoding.md)\n  5. [230531 The Impact of Positional Encoding on Length Generalization in Transformers](/rosinality/ml-papers/blob/main/papers/2023/230531%20The%20Impact%20of%20Positional%20Encoding%20on%20Length%20Generalization%20in%20Transformers.md)\n  6. [230627 Extending Context Window of Large Language Models via Positional Interpolation](/rosinality/ml-papers/blob/main/papers/2023/230627%20Extending%20Context%20Window%20of%20Large%20Language%20Models%20via%20Positional%20Interpolation.md)\n\n## practice\n\n  1. [210630 Using AntiPatterns to avoid MLOps Mistakes](/rosinality/ml-papers/blob/main/papers/2021/210630%20Using%20AntiPatterns%20to%20avoid%20MLOps%20Mistakes.md)\n\n## pretraining\n\n  1. [190620 XLNet](/rosinality/ml-papers/blob/main/papers/2019/190620%20XLNet.md) #language_model\n  2. [190729 RoBERTa](/rosinality/ml-papers/blob/main/papers/2019/190729%20RoBERTa.md) #language_model\n  3. [200128 mBART](/rosinality/ml-papers/blob/main/papers/2020/200128%20mBART.md) #machine_translation #nlp\n  4. [200129 ImageBERT](/rosinality/ml-papers/blob/main/papers/2020/200129%20ImageBERT.md) #multimodal\n  5. [200129 LM Pretraining](/rosinality/ml-papers/blob/main/papers/2020/200129%20LM%20Pretraining.md) #nlp\n  6. [200129 oLMpics](/rosinality/ml-papers/blob/main/papers/2020/200129%20oLMpics.md) #language_model #nlp\n  7. [200130 ViLBERT](/rosinality/ml-papers/blob/main/papers/2020/200130%20ViLBERT.md) #multimodal\n  8. [200210 Pre-training Tasks for Embedding-based Large-scale Retrieval](/rosinality/ml-papers/blob/main/papers/2020/200210%20Pre-training%20Tasks%20for%20Embedding-based%20Large-scale%20Retrieval.md) #retrieval\n  9. [200217 Incorporating BERT into Neural Machine Translation](/rosinality/ml-papers/blob/main/papers/2020/200217%20Incorporating%20BERT%20into%20Neural%20Machine%20Translation.md) #language_model #bert #nmt\n  10. [200219 CodeBERT](/rosinality/ml-papers/blob/main/papers/2020/200219%20CodeBERT.md) #bert\n  11. [200228 UniLMv2](/rosinality/ml-papers/blob/main/papers/2020/200228%20UniLMv2.md) #language_model\n  12. [200317 Calibration of Pre-trained Transformers](/rosinality/ml-papers/blob/main/papers/2020/200317%20Calibration%20of%20Pre-trained%20Transformers.md) #calibration\n  13. [200405 Unsupervised Domain Clusters in Pretrained Language Models](/rosinality/ml-papers/blob/main/papers/2020/200405%20Unsupervised%20Domain%20Clusters%20in%20Pretrained%20Language%20Models.md) #domain\n  14. [200412 Pre-training Text Representations as Meta Learning](/rosinality/ml-papers/blob/main/papers/2020/200412%20Pre-training%20Text%20Representations%20as%20Meta%20Learning.md) #meta_learning #finetuning\n  15. [200413 Pretrained Transformers Improve Out-of-Distribution Robustness](/rosinality/ml-papers/blob/main/papers/2020/200413%20Pretrained%20Transformers%20Improve%20Out-of-Distribution%20Robustness.md) #out_of_distribution\n  16.", "start_char_idx": 177495, "end_char_idx": 180488, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cbf26d84-2b36-463a-96f6-7b4bc7c975dc": {"__data__": {"id_": "cbf26d84-2b36-463a-96f6-7b4bc7c975dc", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f3d15e56-a243-4c8b-a1b3-eec78b49523a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b8be30dda8b74be42c03cafcf5c18588ca3571cf1e5582445772f80321a2afea", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9fb52c0b-d599-4a2a-8ef9-fba163159f29", "node_type": "1", "metadata": {}, "hash": "575ea14a5972db7a430b38f00ad7813a89be96849315a735dbf00f4cd88554e7", "class_name": "RelatedNodeInfo"}}, "text": "[200405 Unsupervised Domain Clusters in Pretrained Language Models](/rosinality/ml-papers/blob/main/papers/2020/200405%20Unsupervised%20Domain%20Clusters%20in%20Pretrained%20Language%20Models.md) #domain\n  14. [200412 Pre-training Text Representations as Meta Learning](/rosinality/ml-papers/blob/main/papers/2020/200412%20Pre-training%20Text%20Representations%20as%20Meta%20Learning.md) #meta_learning #finetuning\n  15. [200413 Pretrained Transformers Improve Out-of-Distribution Robustness](/rosinality/ml-papers/blob/main/papers/2020/200413%20Pretrained%20Transformers%20Improve%20Out-of-Distribution%20Robustness.md) #out_of_distribution\n  16. [200419 Are we pretraining it right](/rosinality/ml-papers/blob/main/papers/2020/200419%20Are%20we%20pretraining%20it%20right.md) #multimodal\n  17. [200420 Adversarial Training for Large Neural Language Models](/rosinality/ml-papers/blob/main/papers/2020/200420%20Adversarial%20Training%20for%20Large%20Neural%20Language%20Models.md) #adversarial_training #language_model #finetuning\n  18. [200420 MPNet](/rosinality/ml-papers/blob/main/papers/2020/200420%20MPNet.md) #language_model\n  19. [200423 Don't Stop Pretraining](/rosinality/ml-papers/blob/main/papers/2020/200423%20Don%27t%20Stop%20Pretraining.md) #domain\n  20. [200427 LightPAFF](/rosinality/ml-papers/blob/main/papers/2020/200427%20LightPAFF.md) #distillation #finetuning\n  21. [200520 Pretraining with Contrastive Sentence Objectives Improves Discourse Performance of Language Models](/rosinality/ml-papers/blob/main/papers/2020/200520%20Pretraining%20with%20Contrastive%20Sentence%20Objectives%20Improves%20Discourse%20Performance%20of%20Language%20Models.md) #contrastive_learning #sentence_embedding\n  22. [200610 MC-BERT](/rosinality/ml-papers/blob/main/papers/2020/200610%20MC-BERT.md)\n  23. [200615 To Pretrain or Not to Pretrain](/rosinality/ml-papers/blob/main/papers/2020/200615%20To%20Pretrain%20or%20Not%20to%20Pretrain.md) #nlp #finetuning\n  24. [200626 Pre-training via Paraphrasing](/rosinality/ml-papers/blob/main/papers/2020/200626%20Pre-training%20via%20Paraphrasing.md) #retrieval\n  25. [200703 Language-agnostic BERT Sentence Embedding](/rosinality/ml-papers/blob/main/papers/2020/200703%20Language-agnostic%20BERT%20Sentence%20Embedding.md) #embedding #multilingual\n  26. [200713 An Empirical Study on Robustness to Spurious Correlations using](/rosinality/ml-papers/blob/main/papers/2020/200713%20An%20Empirical%20Study%20on%20Robustness%20to%20Spurious%20Correlations%20using.md) #nlp #multitask\n  27. [200715 InfoXLM](/rosinality/ml-papers/blob/main/papers/2020/200715%20InfoXLM.md) #nlp #cross_lingual\n  28. [200804 Taking Notes on the Fly Helps BERT Pre-training](/rosinality/ml-papers/blob/main/papers/2020/200804%20Taking%20Notes%20on%20the%20Fly%20Helps%20BERT%20Pre-training.md) #nlp\n  29.", "start_char_idx": 179841, "end_char_idx": 182670, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9fb52c0b-d599-4a2a-8ef9-fba163159f29": {"__data__": {"id_": "9fb52c0b-d599-4a2a-8ef9-fba163159f29", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cbf26d84-2b36-463a-96f6-7b4bc7c975dc", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "a0709175d6e94021752bd23ecef61a47a9279156c4a86744530350f6a4bf6504", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c578d8d-9d1f-425d-b9a7-87ed55410fe4", "node_type": "1", "metadata": {}, "hash": "0a7f75ade9af3d12ee60d1096ed39f89d29c14e0c2375e7ae0ad9fc7c9e4c7ff", "class_name": "RelatedNodeInfo"}}, "text": "[200713 An Empirical Study on Robustness to Spurious Correlations using](/rosinality/ml-papers/blob/main/papers/2020/200713%20An%20Empirical%20Study%20on%20Robustness%20to%20Spurious%20Correlations%20using.md) #nlp #multitask\n  27. [200715 InfoXLM](/rosinality/ml-papers/blob/main/papers/2020/200715%20InfoXLM.md) #nlp #cross_lingual\n  28. [200804 Taking Notes on the Fly Helps BERT Pre-training](/rosinality/ml-papers/blob/main/papers/2020/200804%20Taking%20Notes%20on%20the%20Fly%20Helps%20BERT%20Pre-training.md) #nlp\n  29. [201020 Pushing the Limits of Semi-Supervised Learning for Automatic Speech](/rosinality/ml-papers/blob/main/papers/2020/201020%20Pushing%20the%20Limits%20of%20Semi-Supervised%20Learning%20for%20Automatic%20Speech.md) #semi_supervised_learning #asr\n  30. [201021 Self-training and Pre-training are Complementary for Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/201021%20Self-training%20and%20Pre-training%20are%20Complementary%20for%20Speech%20Recognition.md) #self_supervised #asr\n  31. [201022 mT5](/rosinality/ml-papers/blob/main/papers/2020/201022%20mT5.md) #language_model #multilingual\n  32. [201109 When Do You Need Billions of Words of Pretraining Data](/rosinality/ml-papers/blob/main/papers/2020/201109%20When%20Do%20You%20Need%20Billions%20of%20Words%20of%20Pretraining%20Data.md) #language_model\n  33. [201117 UP-DETR](/rosinality/ml-papers/blob/main/papers/2020/201117%20UP-DETR.md) #detr #end2end #object_detection\n  34. [201127 Progressively Stacking 2.0](/rosinality/ml-papers/blob/main/papers/2020/201127%20Progressively%20Stacking%202.0.md) #efficiency\n  35. [201201 Pre-Trained Image Processing Transformer](/rosinality/ml-papers/blob/main/papers/2020/201201%20Pre-Trained%20Image%20Processing%20Transformer.md) #contrastive_learning #vision_transformer #restoration\n  36. [201201 StructFormer](/rosinality/ml-papers/blob/main/papers/2020/201201%20StructFormer.md) #parse #attention #mlm\n  37. [201227 Syntax-Enhanced Pre-trained Model](/rosinality/ml-papers/blob/main/papers/2020/201227%20Syntax-Enhanced%20Pre-trained%20Model.md) #language_model #syntax\n  38. [210225 SparseBERT](/rosinality/ml-papers/blob/main/papers/2021/210225%20SparseBERT.md) #attention #sparse_attention #bert\n  39. [210318 All NLP Tasks Are Generation Tasks](/rosinality/ml-papers/blob/main/papers/2021/210318%20All%20NLP%20Tasks%20Are%20Generation%20Tasks.md) #language_model\n  40. [210324 Can Vision Transformers Learn without Natural Images](/rosinality/ml-papers/blob/main/papers/2021/210324%20Can%20Vision%20Transformers%20Learn%20without%20Natural%20Images.md) #vision_transformer\n  41. [210402 Robust wav2vec 2.0](/rosinality/ml-papers/blob/main/papers/2021/210402%20Robust%20wav2vec%202.0.md) #asr\n  42.", "start_char_idx": 182144, "end_char_idx": 184896, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5c578d8d-9d1f-425d-b9a7-87ed55410fe4": {"__data__": {"id_": "5c578d8d-9d1f-425d-b9a7-87ed55410fe4", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9fb52c0b-d599-4a2a-8ef9-fba163159f29", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "22de1f89ea75ab7d1b1123ec7fadb0c826d03a27c88ba0ec36b75934efe8ad26", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ac0f355f-375b-470b-8436-d7c41c1f9043", "node_type": "1", "metadata": {}, "hash": "9c70753bf7770508e7fd2bc9bb32ede8896d5467d0284010a0443c0c7e57e0ea", "class_name": "RelatedNodeInfo"}}, "text": "[210318 All NLP Tasks Are Generation Tasks](/rosinality/ml-papers/blob/main/papers/2021/210318%20All%20NLP%20Tasks%20Are%20Generation%20Tasks.md) #language_model\n  40. [210324 Can Vision Transformers Learn without Natural Images](/rosinality/ml-papers/blob/main/papers/2021/210324%20Can%20Vision%20Transformers%20Learn%20without%20Natural%20Images.md) #vision_transformer\n  41. [210402 Robust wav2vec 2.0](/rosinality/ml-papers/blob/main/papers/2021/210402%20Robust%20wav2vec%202.0.md) #asr\n  42. [210407 Pushing the Limits of Non-Autoregressive Speech Recognition](/rosinality/ml-papers/blob/main/papers/2021/210407%20Pushing%20the%20Limits%20of%20Non-Autoregressive%20Speech%20Recognition.md) #non-autoregressive #asr #ctc\n  43. [210413 Masked Language Modeling and the Distributional Hypothesis](/rosinality/ml-papers/blob/main/papers/2021/210413%20Masked%20Language%20Modeling%20and%20the%20Distributional%20Hypothesis.md) #language_model #mlm\n  44. [210417 mT6](/rosinality/ml-papers/blob/main/papers/2021/210417%20mT6.md) #language_model\n  45. [210418 Data-Efficient Language-Supervised Zero-Shot Learning with](/rosinality/ml-papers/blob/main/papers/2021/210418%20Data-Efficient%20Language-Supervised%20Zero-Shot%20Learning%20with.md) #multimodal\n  46. [210422 ImageNet-21K Pretraining for the Masses](/rosinality/ml-papers/blob/main/papers/2021/210422%20ImageNet-21K%20Pretraining%20for%20the%20Masses.md) #backbone\n  47. [210606 On the Effectiveness of Adapter-based Tuning for Pretrained Language Model Adaptation](/rosinality/ml-papers/blob/main/papers/2021/210606%20On%20the%20Effectiveness%20of%20Adapter-based%20Tuning%20for%20Pretrained%20Language%20Model%20Adaptation.md) #finetuning #adapter\n  48. [210606 Rethinking Training from Scratch for Object Detection](/rosinality/ml-papers/blob/main/papers/2021/210606%20Rethinking%20Training%20from%20Scratch%20for%20Object%20Detection.md) #object_detection\n  49. [210608 DETReg](/rosinality/ml-papers/blob/main/papers/2021/210608%20DETReg.md) #detr\n  50. [210614 SAS](/rosinality/ml-papers/blob/main/papers/2021/210614%20SAS.md)\n  51. [210615 BEiT](/rosinality/ml-papers/blob/main/papers/2021/210615%20BEiT.md) #vit #bert\n  52. [210907 How much pretraining data do language models need to learn syntax](/rosinality/ml-papers/blob/main/papers/2021/210907%20How%20much%20pretraining%20data%20do%20language%20models%20need%20to%20learn%20syntax.md) #bert\n  53. [210910 ReasonBERT](/rosinality/ml-papers/blob/main/papers/2021/210910%20ReasonBERT.md) #bert #reasoning #qa\n  54. [210913 STraTA](/rosinality/ml-papers/blob/main/papers/2021/210913%20STraTA.md) #finetuning #semi_supervised_learning #few_shot\n  55. [210914 Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition](/rosinality/ml-papers/blob/main/papers/2021/210914%20Performance-Efficiency%20Trade-offs%20in%20Unsupervised%20Pre-training%20for%20Speech%20Recognition.md) #asr\n  56.", "start_char_idx": 184400, "end_char_idx": 187331, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ac0f355f-375b-470b-8436-d7c41c1f9043": {"__data__": {"id_": "ac0f355f-375b-470b-8436-d7c41c1f9043", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c578d8d-9d1f-425d-b9a7-87ed55410fe4", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "3e5a80bb7999b43aa1edd134b1949b4bc3233ab3a7b8224d359efb5dce1087aa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3c02b981-df4f-46ba-aeaa-9bfea91e9f5b", "node_type": "1", "metadata": {}, "hash": "7f6236dce30c53bfe8266a7a5ab98ad3d6a83788ecad3cf58c60ebe4ec64cf2c", "class_name": "RelatedNodeInfo"}}, "text": "[210910 ReasonBERT](/rosinality/ml-papers/blob/main/papers/2021/210910%20ReasonBERT.md) #bert #reasoning #qa\n  54. [210913 STraTA](/rosinality/ml-papers/blob/main/papers/2021/210913%20STraTA.md) #finetuning #semi_supervised_learning #few_shot\n  55. [210914 Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition](/rosinality/ml-papers/blob/main/papers/2021/210914%20Performance-Efficiency%20Trade-offs%20in%20Unsupervised%20Pre-training%20for%20Speech%20Recognition.md) #asr\n  56. [210914 Task-adaptive Pre-training and Self-training are Complementary for Natural Language Understanding](/rosinality/ml-papers/blob/main/papers/2021/210914%20Task-adaptive%20Pre-training%20and%20Self-training%20are%20Complementary%20for%20Natural%20Language%20Understanding.md) #finetuning #semi_supervised_learning #few_shot\n  57. [210927 BigSSL](/rosinality/ml-papers/blob/main/papers/2021/210927%20BigSSL.md) #asr #semi_supervised_learning #unsupervised_training\n  58. [211005 Exploring the Limits of Large Scale Pre-training](/rosinality/ml-papers/blob/main/papers/2021/211005%20Exploring%20the%20Limits%20of%20Large%20Scale%20Pre-training.md) #classificiation #scaling\n  59. [211018 Unsupervised Finetuning](/rosinality/ml-papers/blob/main/papers/2021/211018%20Unsupervised%20Finetuning.md) #unsupervised_training #finetuning\n  60. [211026 WavLM](/rosinality/ml-papers/blob/main/papers/2021/211026%20WavLM.md) #speech\n  61. [211103 VLMo](/rosinality/ml-papers/blob/main/papers/2021/211103%20VLMo.md) #mixture_of_experts #vision-language\n  62. [211111 Masked Autoencoders Are Scalable Vision Learners](/rosinality/ml-papers/blob/main/papers/2021/211111%20Masked%20Autoencoders%20Are%20Scalable%20Vision%20Learners.md) #vit\n  63. [211122 ExT5](/rosinality/ml-papers/blob/main/papers/2021/211122%20ExT5.md) #multitask\n  64. [211122 Florence](/rosinality/ml-papers/blob/main/papers/2021/211122%20Florence.md) #vision-language #transfer\n  65. [211201 Revisiting the Transferability of Supervised Pretraining](/rosinality/ml-papers/blob/main/papers/2021/211201%20Revisiting%20the%20Transferability%20of%20Supervised%20Pretraining.md) #transfer\n  66. [211216 Masked Feature Prediction for Self-Supervised Visual Pre-Training](/rosinality/ml-papers/blob/main/papers/2021/211216%20Masked%20Feature%20Prediction%20for%20Self-Supervised%20Visual%20Pre-Training.md) #self_supervised\n  67. [211220 Are Large-scale Datasets Necessary for Self-Supervised Pre-training](/rosinality/ml-papers/blob/main/papers/2021/211220%20Are%20Large-scale%20Datasets%20Necessary%20for%20Self-Supervised%20Pre-training.md) #self_supervised #transfer\n  68. [220429 Vision-Language Pre-Training for Boosting Scene Text Detectors](/rosinality/ml-papers/blob/main/papers/2022/220429%20Vision-Language%20Pre-Training%20for%20Boosting%20Scene%20Text%20Detectors.md)\n  69. [220914 PaLI](/rosinality/ml-papers/blob/main/papers/2022/220914%20PaLI.md) #vision-language\n  70.", "start_char_idx": 186820, "end_char_idx": 189771, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3c02b981-df4f-46ba-aeaa-9bfea91e9f5b": {"__data__": {"id_": "3c02b981-df4f-46ba-aeaa-9bfea91e9f5b", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ac0f355f-375b-470b-8436-d7c41c1f9043", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "71f9618a5eac130b488795db642418f25fb9ace86433fefda60b4dfd47fa66c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5b9d14e5-9e26-4604-8dcc-510e81f136d8", "node_type": "1", "metadata": {}, "hash": "0164f66e48d05cbe8a4bb8fa35852c4098c5fe8c2664d0e0d90f26f318051eaa", "class_name": "RelatedNodeInfo"}}, "text": "[211220 Are Large-scale Datasets Necessary for Self-Supervised Pre-training](/rosinality/ml-papers/blob/main/papers/2021/211220%20Are%20Large-scale%20Datasets%20Necessary%20for%20Self-Supervised%20Pre-training.md) #self_supervised #transfer\n  68. [220429 Vision-Language Pre-Training for Boosting Scene Text Detectors](/rosinality/ml-papers/blob/main/papers/2022/220429%20Vision-Language%20Pre-Training%20for%20Boosting%20Scene%20Text%20Detectors.md)\n  69. [220914 PaLI](/rosinality/ml-papers/blob/main/papers/2022/220914%20PaLI.md) #vision-language\n  70. [230808 Continual Pre-Training of Large Language Models](/rosinality/ml-papers/blob/main/papers/2023/230808%20Continual%20Pre-Training%20of%20Large%20Language%20Models.md)\n\n## probabilistic model\n\n  1. [200413 Einsum Networks](/rosinality/ml-papers/blob/main/papers/2020/200413%20Einsum%20Networks.md)\n  2. [200419 Roundtrip](/rosinality/ml-papers/blob/main/papers/2020/200419%20Roundtrip.md)\n\n## prompt\n\n  1. [220118 ZeroPrompt](/rosinality/ml-papers/blob/main/papers/2022/220118%20ZeroPrompt.md) #zero-shot\n  2. [220916 Text and Patterns](/rosinality/ml-papers/blob/main/papers/2022/220916%20Text%20and%20Patterns.md)\n  3. [230207 Hard Prompts Made Easy](/rosinality/ml-papers/blob/main/papers/2023/230207%20Hard%20Prompts%20Made%20Easy.md) #text2img\n  4. [230517 Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models](/rosinality/ml-papers/blob/main/papers/2023/230517%20Chain-of-Symbol%20Prompting%20Elicits%20Planning%20in%20Large%20Langauge%20Models.md) #in_context_learning\n  5. [230517 Tree of Thoughts](/rosinality/ml-papers/blob/main/papers/2023/230517%20Tree%20of%20Thoughts.md) #in_context_learning\n\n## pruning\n\n  1. [200130 Rethinking Pruning](/rosinality/ml-papers/blob/main/papers/2020/200130%20Rethinking%20Pruning.md)\n  2. [200218 Picking Winning Tickets Before Training by Preserving Gradient Flow](/rosinality/ml-papers/blob/main/papers/2020/200218%20Picking%20Winning%20Tickets%20Before%20Training%20by%20Preserving%20Gradient%20Flow.md) #lottery_ticket\n  3. [200224 HRank](/rosinality/ml-papers/blob/main/papers/2020/200224%20HRank.md) #rank\n  4. [200305 Comparing Rewinding and Fine-tuning in Neural Network Pruning](/rosinality/ml-papers/blob/main/papers/2020/200305%20Comparing%20Rewinding%20and%20Fine-tuning%20in%20Neural%20Network%20Pruning.md)\n  5. [200424 Convolution-Weight-Distribution Assumption](/rosinality/ml-papers/blob/main/papers/2020/200424%20Convolution-Weight-Distribution%20Assumption.md)\n  6. [200514 Bayesian Bits](/rosinality/ml-papers/blob/main/papers/2020/200514%20Bayesian%20Bits.md) #quantization #variational_inference\n  7. [200515 Movement Pruning](/rosinality/ml-papers/blob/main/papers/2020/200515%20Movement%20Pruning.md)\n  8. [200518 Joint Multi-Dimension Pruning](/rosinality/ml-papers/blob/main/papers/2020/200518%20Joint%20Multi-Dimension%20Pruning.md)\n  9.", "start_char_idx": 189216, "end_char_idx": 192101, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b9d14e5-9e26-4604-8dcc-510e81f136d8": {"__data__": {"id_": "5b9d14e5-9e26-4604-8dcc-510e81f136d8", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3c02b981-df4f-46ba-aeaa-9bfea91e9f5b", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "d7778beb8fca661f5034137a4d6cebe56dc7f8aba0bc0171a0e1d2507c4d6bc3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f7e3635b-8d04-4eed-88ed-dc1cae2abe74", "node_type": "1", "metadata": {}, "hash": "a7ba4822000a33603c1e3f722c409e3b9831ad8cd0fc92a045eebc11f274a7c2", "class_name": "RelatedNodeInfo"}}, "text": "[200424 Convolution-Weight-Distribution Assumption](/rosinality/ml-papers/blob/main/papers/2020/200424%20Convolution-Weight-Distribution%20Assumption.md)\n  6. [200514 Bayesian Bits](/rosinality/ml-papers/blob/main/papers/2020/200514%20Bayesian%20Bits.md) #quantization #variational_inference\n  7. [200515 Movement Pruning](/rosinality/ml-papers/blob/main/papers/2020/200515%20Movement%20Pruning.md)\n  8. [200518 Joint Multi-Dimension Pruning](/rosinality/ml-papers/blob/main/papers/2020/200518%20Joint%20Multi-Dimension%20Pruning.md)\n  9. [200706 Lossless CNN Channel Pruning via Decoupling Remembering and Forgetting](/rosinality/ml-papers/blob/main/papers/2020/200706%20Lossless%20CNN%20Channel%20Pruning%20via%20Decoupling%20Remembering%20and%20Forgetting.md)\n  10. [200710 To Filter Prune, or to Layer Prune, That Is The Question](/rosinality/ml-papers/blob/main/papers/2020/200710%20To%20Filter%20Prune%2C%20or%20to%20Layer%20Prune%2C%20That%20Is%20The%20Question.md)\n\n## qa\n\n  1. [200222 Unsupervised Question Decomposition for Question Answering](/rosinality/ml-papers/blob/main/papers/2020/200222%20Unsupervised%20Question%20Decomposition%20for%20Question%20Answering.md)\n\n## quantization\n\n  1. [220815 LLM.int8()](/rosinality/ml-papers/blob/main/papers/2022/220815%20LLM.int8%28%29.md)\n  2. [230216 Shared Microexponents](/rosinality/ml-papers/blob/main/papers/2023/230216%20Shared%20Microexponents.md)\n  3. [230425 Stable and low-precision training for large-scale vision-language models](/rosinality/ml-papers/blob/main/papers/2023/230425%20Stable%20and%20low-precision%20training%20for%20large-scale%20vision-language%20models.md) #optimizer\n  4. [230601 AWQ](/rosinality/ml-papers/blob/main/papers/2023/230601%20AWQ.md)\n  5. [230719 ZeroQuant-FP](/rosinality/ml-papers/blob/main/papers/2023/230719%20ZeroQuant-FP.md)\n\n## reasoning\n\n  1. [200129 Neural Arithmetic Units](/rosinality/ml-papers/blob/main/papers/2020/200129%20Neural%20Arithmetic%20Units.md)\n  2. [200409 Injecting Numerical Reasoning Skills into Language Models](/rosinality/ml-papers/blob/main/papers/2020/200409%20Injecting%20Numerical%20Reasoning%20Skills%20into%20Language%20Models.md)\n\n## recommender\n\n  1. [230510 Do LLMs Understand User Preferences](/rosinality/ml-papers/blob/main/papers/2023/230510%20Do%20LLMs%20Understand%20User%20Preferences.md)\n\n## regularization\n\n  1. [200130 DropAttention](/rosinality/ml-papers/blob/main/papers/2020/200130%20DropAttention.md) #dropout\n  2. [200219 Revisiting Training Strategies and Generalization Performance in Deep](/rosinality/ml-papers/blob/main/papers/2020/200219%20Revisiting%20Training%20Strategies%20and%20Generalization%20Performance%20in%20Deep.md) #metric_learning\n  3. [200225 On Feature Normalization and Data Augmentation](/rosinality/ml-papers/blob/main/papers/2020/200225%20On%20Feature%20Normalization%20and%20Data%20Augmentation.md) #normalization #mixup\n  4.", "start_char_idx": 191563, "end_char_idx": 194469, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f7e3635b-8d04-4eed-88ed-dc1cae2abe74": {"__data__": {"id_": "f7e3635b-8d04-4eed-88ed-dc1cae2abe74", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5b9d14e5-9e26-4604-8dcc-510e81f136d8", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "0ec493c21d0ea21f539b89d3688d3deea3ba967e99dc28bf46f5bf27d8a28271", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4f55b8aa-c792-49b5-9d80-64713df534c5", "node_type": "1", "metadata": {}, "hash": "f0241598bc6517ea096a3d4568b5eafbf9724a2f17c007658a04f81ab7122796", "class_name": "RelatedNodeInfo"}}, "text": "[200130 DropAttention](/rosinality/ml-papers/blob/main/papers/2020/200130%20DropAttention.md) #dropout\n  2. [200219 Revisiting Training Strategies and Generalization Performance in Deep](/rosinality/ml-papers/blob/main/papers/2020/200219%20Revisiting%20Training%20Strategies%20and%20Generalization%20Performance%20in%20Deep.md) #metric_learning\n  3. [200225 On Feature Normalization and Data Augmentation](/rosinality/ml-papers/blob/main/papers/2020/200225%20On%20Feature%20Normalization%20and%20Data%20Augmentation.md) #normalization #mixup\n  4. [200228 The Implicit and Explicit Regularization Effects of Dropout](/rosinality/ml-papers/blob/main/papers/2020/200228%20The%20Implicit%20and%20Explicit%20Regularization%20Effects%20of%20Dropout.md) #dropout\n  5. [200331 Regularizing Class-wise Predictions via Self-knowledge Distillation](/rosinality/ml-papers/blob/main/papers/2020/200331%20Regularizing%20Class-wise%20Predictions%20via%20Self-knowledge%20Distillation.md) #distillation #consistency_regularization\n  6. [200409 Orthogonal Over-Parameterized Training](/rosinality/ml-papers/blob/main/papers/2020/200409%20Orthogonal%20Over-Parameterized%20Training.md)\n  7. [200424 Dropout as an Implicit Gating Mechanism For Continual Learning](/rosinality/ml-papers/blob/main/papers/2020/200424%20Dropout%20as%20an%20Implicit%20Gating%20Mechanism%20For%20Continual%20Learning.md)\n  8. [200427 Scheduled DropHead](/rosinality/ml-papers/blob/main/papers/2020/200427%20Scheduled%20DropHead.md)\n  9. [200513 Implicit Regularization in Deep Learning May Not Be Explainable by Norms](/rosinality/ml-papers/blob/main/papers/2020/200513%20Implicit%20Regularization%20in%20Deep%20Learning%20May%20Not%20Be%20Explainable%20by%20Norms.md) #training #optimization\n  10. [200707 RIFLE](/rosinality/ml-papers/blob/main/papers/2020/200707%20RIFLE.md) #finetuning\n  11. [200707 Remix](/rosinality/ml-papers/blob/main/papers/2020/200707%20Remix.md) #imbalanced\n  12. [200721 Improving compute efficacy frontiers with SliceOut](/rosinality/ml-papers/blob/main/papers/2020/200721%20Improving%20compute%20efficacy%20frontiers%20with%20SliceOut.md) #efficient_training\n  13. [201122 Stable Weight Decay Regularization](/rosinality/ml-papers/blob/main/papers/2020/201122%20Stable%20Weight%20Decay%20Regularization.md)\n  14. [220527 Sharpness-Aware Training for Free](/rosinality/ml-papers/blob/main/papers/2022/220527%20Sharpness-Aware%20Training%20for%20Free.md)\n  15. [230302 Dropout Reduces Underfitting](/rosinality/ml-papers/blob/main/papers/2023/230302%20Dropout%20Reduces%20Underfitting.md) #dropout\n\n## reinforcement learning\n\n  1. [191120 Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model](/rosinality/ml-papers/blob/main/papers/2019/191120%20Mastering%20Atari%2C%20Go%2C%20Chess%20and%20Shogi%20by%20Planning%20with%20a%20Learned%20Model.md)\n  2. [200130 Mastering Atari, Go, Chess, Shogi](/rosinality/ml-papers/blob/main/papers/2020/200130%20Mastering%20Atari%2C%20Go%2C%20Chess%2C%20Shogi.md)\n  3.", "start_char_idx": 193923, "end_char_idx": 196931, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f55b8aa-c792-49b5-9d80-64713df534c5": {"__data__": {"id_": "4f55b8aa-c792-49b5-9d80-64713df534c5", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f7e3635b-8d04-4eed-88ed-dc1cae2abe74", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ff8d038450081d5b730ea4d9776af6f1f08fae7c1fa3d189367b5f0b753adaf3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48e1240f-8d2d-49b3-9dd1-f243a76b44e6", "node_type": "1", "metadata": {}, "hash": "f2075fc67ff8da448a589eb1551fb8a71825fa51b615e138258821d5042e3914", "class_name": "RelatedNodeInfo"}}, "text": "[191120 Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model](/rosinality/ml-papers/blob/main/papers/2019/191120%20Mastering%20Atari%2C%20Go%2C%20Chess%20and%20Shogi%20by%20Planning%20with%20a%20Learned%20Model.md)\n  2. [200130 Mastering Atari, Go, Chess, Shogi](/rosinality/ml-papers/blob/main/papers/2020/200130%20Mastering%20Atari%2C%20Go%2C%20Chess%2C%20Shogi.md)\n  3. [200626 Critic Regularized Regression](/rosinality/ml-papers/blob/main/papers/2020/200626%20Critic%20Regularized%20Regression.md)\n  4. [210929 Vision-Guided Quadrupedal Locomotion in the Wild with Multi-Modal Delay Randomization](/rosinality/ml-papers/blob/main/papers/2021/210929%20Vision-Guided%20Quadrupedal%20Locomotion%20in%20the%20Wild%20with%20Multi-Modal%20Delay%20Randomization.md)\n  5. [211030 Mastering Atari Games with Limited Data](/rosinality/ml-papers/blob/main/papers/2021/211030%20Mastering%20Atari%20Games%20with%20Limited%20Data.md)\n\n## rendering\n\n  1. [200130 Textured Neural Avatars](/rosinality/ml-papers/blob/main/papers/2020/200130%20Textured%20Neural%20Avatars.md)\n\n## representation\n\n  1. [200220 Neural Bayes](/rosinality/ml-papers/blob/main/papers/2020/200220%20Neural%20Bayes.md) #bayesian #clustering\n  2. [200412 Gradients as Features for Deep Representation Learning](/rosinality/ml-papers/blob/main/papers/2020/200412%20Gradients%20as%20Features%20for%20Deep%20Representation%20Learning.md)\n  3. [201223 Noisy Labels Can Induce Good Representations](/rosinality/ml-papers/blob/main/papers/2020/201223%20Noisy%20Labels%20Can%20Induce%20Good%20Representations.md) #noise\n\n## resampling\n\n  1. [200512 Invertible Image Rescaling](/rosinality/ml-papers/blob/main/papers/2020/200512%20Invertible%20Image%20Rescaling.md)\n\n## restoration\n\n  1. [200402 Learning to See Through Obstructions](/rosinality/ml-papers/blob/main/papers/2020/200402%20Learning%20to%20See%20Through%20Obstructions.md)\n  2. [200404 Deblurring by Realistic Blurring](/rosinality/ml-papers/blob/main/papers/2020/200404%20Deblurring%20by%20Realistic%20Blurring.md)\n  3. [200406 Self-Supervised Scene De-occlusion](/rosinality/ml-papers/blob/main/papers/2020/200406%20Self-Supervised%20Scene%20De-occlusion.md)\n  4. [201123 Cross-Camera Convolutional Color Constancy](/rosinality/ml-papers/blob/main/papers/2020/201123%20Cross-Camera%20Convolutional%20Color%20Constancy.md)\n  5. [201123 Dissecting Image Crops](/rosinality/ml-papers/blob/main/papers/2020/201123%20Dissecting%20Image%20Crops.md)\n\n## retrieval\n\n  1. [210715 Internet-Augmented Dialogue Generation](/rosinality/ml-papers/blob/main/papers/2021/210715%20Internet-Augmented%20Dialogue%20Generation.md) #dialog\n  2. [220124 Text and Code Embeddings by Contrastive Pre-Training](/rosinality/ml-papers/blob/main/papers/2022/220124%20Text%20and%20Code%20Embeddings%20by%20Contrastive%20Pre-Training.md)\n\n## review\n\n  1.", "start_char_idx": 196542, "end_char_idx": 199402, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "48e1240f-8d2d-49b3-9dd1-f243a76b44e6": {"__data__": {"id_": "48e1240f-8d2d-49b3-9dd1-f243a76b44e6", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f55b8aa-c792-49b5-9d80-64713df534c5", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "79adf77d483106975c43c05672943f0857f643781d36c4a002af6b58c82e2892", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b43bc357-06a4-47da-8f03-da3509491ea7", "node_type": "1", "metadata": {}, "hash": "c41f1cbbf0938cc16de4a7f9af67e548906c0390b2b791c9e2823af8a77210f0", "class_name": "RelatedNodeInfo"}}, "text": "[201123 Dissecting Image Crops](/rosinality/ml-papers/blob/main/papers/2020/201123%20Dissecting%20Image%20Crops.md)\n\n## retrieval\n\n  1. [210715 Internet-Augmented Dialogue Generation](/rosinality/ml-papers/blob/main/papers/2021/210715%20Internet-Augmented%20Dialogue%20Generation.md) #dialog\n  2. [220124 Text and Code Embeddings by Contrastive Pre-Training](/rosinality/ml-papers/blob/main/papers/2022/220124%20Text%20and%20Code%20Embeddings%20by%20Contrastive%20Pre-Training.md)\n\n## review\n\n  1. [200130 Filter Response Normalization](/rosinality/ml-papers/blob/main/papers/2020/200130%20Filter%20Response%20Normalization.md)\n  2. [200227 A Primer in BERTology](/rosinality/ml-papers/blob/main/papers/2020/200227%20A%20Primer%20in%20BERTology.md) #bert\n  3. [200306 What is the State of Neural Network Pruning](/rosinality/ml-papers/blob/main/papers/2020/200306%20What%20is%20the%20State%20of%20Neural%20Network%20Pruning.md) #pruning\n  4. [200318 A Metric Learning Reality Check](/rosinality/ml-papers/blob/main/papers/2020/200318%20A%20Metric%20Learning%20Reality%20Check.md) #metric_learning\n  5. [200324 A Systematic Evaluation](/rosinality/ml-papers/blob/main/papers/2020/200324%20A%20Systematic%20Evaluation.md)\n  6. [200325 Rethinking Few-Shot Image Classification](/rosinality/ml-papers/blob/main/papers/2020/200325%20Rethinking%20Few-Shot%20Image%20Classification.md) #meta_learning\n  7. [200408 State of the Art on Neural Rendering](/rosinality/ml-papers/blob/main/papers/2020/200408%20State%20of%20the%20Art%20on%20Neural%20Rendering.md) #neural_rendering\n  8. [200409 EvoNorm](/rosinality/ml-papers/blob/main/papers/2020/200409%20EvoNorm.md)\n  9. [200428 Showing Your Work Doesn't Always Work](/rosinality/ml-papers/blob/main/papers/2020/200428%20Showing%20Your%20Work%20Doesn%27t%20Always%20Work.md)\n  10. [200619 Augmentation for GANs](/rosinality/ml-papers/blob/main/papers/2020/200619%20Augmentation%20for%20GANs.md)\n  11. [200627 Denoising Diffusion Probabilistic Models Implementation](/rosinality/ml-papers/blob/main/papers/2020/200627%20Denoising%20Diffusion%20Probabilistic%20Models%20Implementation.md)\n  12. [200717 Semantic factor of GANs](/rosinality/ml-papers/blob/main/papers/2020/200717%20Semantic%20factor%20of%20GANs.md)\n  13. [200725 Neighbor Embedding](/rosinality/ml-papers/blob/main/papers/2020/200725%20Neighbor%20Embedding.md)\n  14. [200821 Virtual Try On](/rosinality/ml-papers/blob/main/papers/2020/200821%20Virtual%20Try%20On.md)\n  15. [201016 Representation Learning via Invariant Causal Mechanisms](/rosinality/ml-papers/blob/main/papers/2020/201016%20Representation%20Learning%20via%20Invariant%20Causal%20Mechanisms.md)\n  16. [201021 BYOL works even without batch statistics](/rosinality/ml-papers/blob/main/papers/2020/201021%20BYOL%20works%20even%20without%20batch%20statistics.md)\n  17. [201108 Long Range Arena](/rosinality/ml-papers/blob/main/papers/2020/201108%20Long%20Range%20Arena.md) #attention #efficient_attention\n  18.", "start_char_idx": 198905, "end_char_idx": 201881, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b43bc357-06a4-47da-8f03-da3509491ea7": {"__data__": {"id_": "b43bc357-06a4-47da-8f03-da3509491ea7", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48e1240f-8d2d-49b3-9dd1-f243a76b44e6", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "275236e1af7d9eb3be028bac3084de6160e3b367384a0cd682a11a732053ff1c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ee0cfe5c-c3db-454b-9e13-33db1bab87f4", "node_type": "1", "metadata": {}, "hash": "0d29b3bc97d6dc53fc09094e84d57f64d659a1632f528976597deca95dabd9b3", "class_name": "RelatedNodeInfo"}}, "text": "[200821 Virtual Try On](/rosinality/ml-papers/blob/main/papers/2020/200821%20Virtual%20Try%20On.md)\n  15. [201016 Representation Learning via Invariant Causal Mechanisms](/rosinality/ml-papers/blob/main/papers/2020/201016%20Representation%20Learning%20via%20Invariant%20Causal%20Mechanisms.md)\n  16. [201021 BYOL works even without batch statistics](/rosinality/ml-papers/blob/main/papers/2020/201021%20BYOL%20works%20even%20without%20batch%20statistics.md)\n  17. [201108 Long Range Arena](/rosinality/ml-papers/blob/main/papers/2020/201108%20Long%20Range%20Arena.md) #attention #efficient_attention\n  18. [201112 Learning Semantic-aware Normalization for Generative Adversarial Networks](/rosinality/ml-papers/blob/main/papers/2020/201112%20Learning%20Semantic-aware%20Normalization%20for%20Generative%20Adversarial%20Networks.md)\n  19. [201112 When Do You Need Billions of Words of Pretraining Data](/rosinality/ml-papers/blob/main/papers/2020/201112%20When%20Do%20You%20Need%20Billions%20of%20Words%20of%20Pretraining%20Data.md)\n\n## rl\n\n  1. [230807 AlphaStar Unplugged](/rosinality/ml-papers/blob/main/papers/2023/230807%20AlphaStar%20Unplugged.md)\n\n## robustness\n\n  1. [200211 Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial](/rosinality/ml-papers/blob/main/papers/2020/200211%20Fundamental%20Tradeoffs%20between%20Invariance%20and%20Sensitivity%20to%20Adversarial.md) #adversarial_training\n  2. [200304 A Closer Look at Accuracy vs. Robustness](/rosinality/ml-papers/blob/main/papers/2020/200304%20A%20Closer%20Look%20at%20Accuracy%20vs.%20Robustness.md) #adversarial_training\n  3. [200810 Informative Dropout for Robust Representation Learning](/rosinality/ml-papers/blob/main/papers/2020/200810%20Informative%20Dropout%20for%20Robust%20Representation%20Learning.md)\n  4. [220607 Can CNNs Be More Robust Than Transformers](/rosinality/ml-papers/blob/main/papers/2022/220607%20Can%20CNNs%20Be%20More%20Robust%20Than%20Transformers.md)\n\n## saliency\n\n  1. [200406 There and Back Again](/rosinality/ml-papers/blob/main/papers/2020/200406%20There%20and%20Back%20Again.md)\n\n## salient object detection\n\n  1. [200518 U$^2$-Net](/rosinality/ml-papers/blob/main/papers/2020/200518%20U%24%5E2%24-Net.md)\n\n## scale\n\n  1. [200712 Learning to Learn Parameterized Classification Networks for Scalable](/rosinality/ml-papers/blob/main/papers/2020/200712%20Learning%20to%20Learn%20Parameterized%20Classification%20Networks%20for%20Scalable.md) #hypernetwork\n  2. [201130 Towards Better Accuracy-efficiency Trade-offs](/rosinality/ml-papers/blob/main/papers/2020/201130%20Towards%20Better%20Accuracy-efficiency%20Trade-offs.md)\n\n## score\n\n  1. [200319 GIQA](/rosinality/ml-papers/blob/main/papers/2020/200319%20GIQA.md)\n  2. [200426 Evaluation Metrics for Conditional Image Generation](/rosinality/ml-papers/blob/main/papers/2020/200426%20Evaluation%20Metrics%20for%20Conditional%20Image%20Generation.md)\n\n## self supervised\n\n  1.", "start_char_idx": 201276, "end_char_idx": 204220, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ee0cfe5c-c3db-454b-9e13-33db1bab87f4": {"__data__": {"id_": "ee0cfe5c-c3db-454b-9e13-33db1bab87f4", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b43bc357-06a4-47da-8f03-da3509491ea7", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b075017b27980895ec2281a4e60b3e85611489788ec000233666b169ce007fc0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b35a892-6483-4111-adeb-2a1bea4fae9a", "node_type": "1", "metadata": {}, "hash": "fbc49c768a0ee9627cbc1d7bb9081a8fd5adc1604f3fa9d0447d620490b6258b", "class_name": "RelatedNodeInfo"}}, "text": "[201130 Towards Better Accuracy-efficiency Trade-offs](/rosinality/ml-papers/blob/main/papers/2020/201130%20Towards%20Better%20Accuracy-efficiency%20Trade-offs.md)\n\n## score\n\n  1. [200319 GIQA](/rosinality/ml-papers/blob/main/papers/2020/200319%20GIQA.md)\n  2. [200426 Evaluation Metrics for Conditional Image Generation](/rosinality/ml-papers/blob/main/papers/2020/200426%20Evaluation%20Metrics%20for%20Conditional%20Image%20Generation.md)\n\n## self supervised\n\n  1. [200213 Automatically Discovering and Learning New Visual Categories with Ranking Statistics](/rosinality/ml-papers/blob/main/papers/2020/200213%20Automatically%20Discovering%20and%20Learning%20New%20Visual%20Categories%20with%20Ranking%20Statistics.md) #weak_supervision\n  2. [200218 MAST](/rosinality/ml-papers/blob/main/papers/2020/200218%20MAST.md) #tracking\n  3. [200224 Self-Adaptive Training](/rosinality/ml-papers/blob/main/papers/2020/200224%20Self-Adaptive%20Training.md) #noise #dataset\n  4. [200408 Improving BERT with Self-Supervised Attention](/rosinality/ml-papers/blob/main/papers/2020/200408%20Improving%20BERT%20with%20Self-Supervised%20Attention.md) #bert #distillation\n  5. [200722 CrossTransformers](/rosinality/ml-papers/blob/main/papers/2020/200722%20CrossTransformers.md) #few_shot\n  6. [201015 Representation Learning via Invariant Causal Mechanisms](/rosinality/ml-papers/blob/main/papers/2020/201015%20Representation%20Learning%20via%20Invariant%20Causal%20Mechanisms.md) #causality\n  7. [201117 Neural Semi-supervised Learning for Text Classification Under](/rosinality/ml-papers/blob/main/papers/2020/201117%20Neural%20Semi-supervised%20Learning%20for%20Text%20Classification%20Under.md) #nlp\n  8. [201125 Can Temporal Information Help with Contrastive Self-Supervised Learning](/rosinality/ml-papers/blob/main/papers/2020/201125%20Can%20Temporal%20Information%20Help%20with%20Contrastive%20Self-Supervised%20Learning.md) #video #augmentation\n  9. [201224 Self-supervised Pre-training with Hard Examples Improves Visual](/rosinality/ml-papers/blob/main/papers/2020/201224%20Self-supervised%20Pre-training%20with%20Hard%20Examples%20Improves%20Visual.md) #mixup\n  10. [210726 Continental-Scale Building Detection from High Resolution Satellite Imagery](/rosinality/ml-papers/blob/main/papers/2021/210726%20Continental-Scale%20Building%20Detection%20from%20High%20Resolution%20Satellite%20Imagery.md)\n  11. [210827 Injecting Text in Self-Supervised Speech Pretraining](/rosinality/ml-papers/blob/main/papers/2021/210827%20Injecting%20Text%20in%20Self-Supervised%20Speech%20Pretraining.md) #asr\n  12. [210927 Compressive Visual Representations](/rosinality/ml-papers/blob/main/papers/2021/210927%20Compressive%20Visual%20Representations.md)\n  13. [211027 Neural Analysis and Synthesis](/rosinality/ml-papers/blob/main/papers/2021/211027%20Neural%20Analysis%20and%20Synthesis.md) #audio_synthesis\n  14. [220124 data2vec](/rosinality/ml-papers/blob/main/papers/2022/220124%20data2vec.md)\n  15.", "start_char_idx": 203754, "end_char_idx": 206738, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b35a892-6483-4111-adeb-2a1bea4fae9a": {"__data__": {"id_": "0b35a892-6483-4111-adeb-2a1bea4fae9a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ee0cfe5c-c3db-454b-9e13-33db1bab87f4", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "f68af8bdd04a1aac7cd211e536d61ad0b0a2ddbb93d2fb991b595fb294c48621", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e3d49e79-0357-45dd-b3b1-3d84ce5e7e19", "node_type": "1", "metadata": {}, "hash": "4935011ba5189686f3149f9ae4e9a561356bc265ece787328ba3ac0cffe437b0", "class_name": "RelatedNodeInfo"}}, "text": "[210827 Injecting Text in Self-Supervised Speech Pretraining](/rosinality/ml-papers/blob/main/papers/2021/210827%20Injecting%20Text%20in%20Self-Supervised%20Speech%20Pretraining.md) #asr\n  12. [210927 Compressive Visual Representations](/rosinality/ml-papers/blob/main/papers/2021/210927%20Compressive%20Visual%20Representations.md)\n  13. [211027 Neural Analysis and Synthesis](/rosinality/ml-papers/blob/main/papers/2021/211027%20Neural%20Analysis%20and%20Synthesis.md) #audio_synthesis\n  14. [220124 data2vec](/rosinality/ml-papers/blob/main/papers/2022/220124%20data2vec.md)\n  15. [220216 Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision](/rosinality/ml-papers/blob/main/papers/2022/220216%20Vision%20Models%20Are%20More%20Robust%20And%20Fair%20When%20Pretrained%20On%20Uncurated%20Images%20Without%20Supervision.md)\n  16. [220520 Uniform Masking](/rosinality/ml-papers/blob/main/papers/2022/220520%20Uniform%20Masking.md)\n  17. [220526 Green Hierarchical Vision Transformer for Masked Image Modeling](/rosinality/ml-papers/blob/main/papers/2022/220526%20Green%20Hierarchical%20Vision%20Transformer%20for%20Masked%20Image%20Modeling.md)\n  18. [220526 MixMIM](/rosinality/ml-papers/blob/main/papers/2022/220526%20MixMIM.md)\n  19. [220526 Revealing the Dark Secrets of Masked Image Modeling](/rosinality/ml-papers/blob/main/papers/2022/220526%20Revealing%20the%20Dark%20Secrets%20of%20Masked%20Image%20Modeling.md) #representation\n  20. [220715 Is a Caption Worth a Thousand Images](/rosinality/ml-papers/blob/main/papers/2022/220715%20Is%20a%20Caption%20Worth%20a%20Thousand%20Images.md) #clip\n  21. [220803 Masked Vision and Language Modeling for Multi-modal Representation Learning](/rosinality/ml-papers/blob/main/papers/2022/220803%20Masked%20Vision%20and%20Language%20Modeling%20for%20Multi-modal%20Representation%20Learning.md) #mlm\n\n## self supervised discovery\n\n  1. [200403 Self-Supervised Viewpoint Learning From Image Collections](/rosinality/ml-papers/blob/main/papers/2020/200403%20Self-Supervised%20Viewpoint%20Learning%20From%20Image%20Collections.md) #viewpoint\n  2. [201127 Unsupervised part representation by Flow Capsules](/rosinality/ml-papers/blob/main/papers/2020/201127%20Unsupervised%20part%20representation%20by%20Flow%20Capsules.md)\n  3. [210429 MarioNette](/rosinality/ml-papers/blob/main/papers/2021/210429%20MarioNette.md)\n\n## semantic factor\n\n  1. [200307 StyleGAN2 Distillation for Feed-forward Image Manipulation](/rosinality/ml-papers/blob/main/papers/2020/200307%20StyleGAN2%20Distillation%20for%20Feed-forward%20Image%20Manipulation.md) #stylegan\n  2. [200308 PULSE](/rosinality/ml-papers/blob/main/papers/2020/200308%20PULSE.md) #stylegan\n  3. [200406 GANSpace](/rosinality/ml-papers/blob/main/papers/2020/200406%20GANSpace.md)\n  4. [201222 Time-Travel Rephotography](/rosinality/ml-papers/blob/main/papers/2020/201222%20Time-Travel%20Rephotography.md) #restoration #stylegan\n\n## semantic segmentation\n\n  1.", "start_char_idx": 206155, "end_char_idx": 209146, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e3d49e79-0357-45dd-b3b1-3d84ce5e7e19": {"__data__": {"id_": "e3d49e79-0357-45dd-b3b1-3d84ce5e7e19", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b35a892-6483-4111-adeb-2a1bea4fae9a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "e8a60d6050d85780d6223e11033882043861f071e3a64b49de2e6675d169054f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8ce21e9b-9a76-4a21-a3d9-a79f96cef94c", "node_type": "1", "metadata": {}, "hash": "dd75456a380d57fba2be324f5f52281a3598fceda2c58bbbf5edb84c7932be16", "class_name": "RelatedNodeInfo"}}, "text": "[200307 StyleGAN2 Distillation for Feed-forward Image Manipulation](/rosinality/ml-papers/blob/main/papers/2020/200307%20StyleGAN2%20Distillation%20for%20Feed-forward%20Image%20Manipulation.md) #stylegan\n  2. [200308 PULSE](/rosinality/ml-papers/blob/main/papers/2020/200308%20PULSE.md) #stylegan\n  3. [200406 GANSpace](/rosinality/ml-papers/blob/main/papers/2020/200406%20GANSpace.md)\n  4. [201222 Time-Travel Rephotography](/rosinality/ml-papers/blob/main/papers/2020/201222%20Time-Travel%20Rephotography.md) #restoration #stylegan\n\n## semantic segmentation\n\n  1. [200323 Learning Dynamic Routing for Semantic Segmentation](/rosinality/ml-papers/blob/main/papers/2020/200323%20Learning%20Dynamic%20Routing%20for%20Semantic%20Segmentation.md)\n  2. [200516 Single-Stage Semantic Segmentation from Image Labels](/rosinality/ml-papers/blob/main/papers/2020/200516%20Single-Stage%20Semantic%20Segmentation%20from%20Image%20Labels.md)\n  3. [200826 EfficientFCN](/rosinality/ml-papers/blob/main/papers/2020/200826%20EfficientFCN.md)\n  4. [210512 Segmenter](/rosinality/ml-papers/blob/main/papers/2021/210512%20Segmenter.md)\n  5. [220918 SegNeXt](/rosinality/ml-papers/blob/main/papers/2022/220918%20SegNeXt.md)\n\n## semi supervised learning\n\n  1. [200306 Semi-Supervised StyleGAN for Disentanglement Learning](/rosinality/ml-papers/blob/main/papers/2020/200306%20Semi-Supervised%20StyleGAN%20for%20Disentanglement%20Learning.md) #stylegan #mixup\n  2. [200323 Meta Pseudo Labels](/rosinality/ml-papers/blob/main/papers/2020/200323%20Meta%20Pseudo%20Labels.md) #meta_learning\n  3. [200627 Laplacian Regularized Few-Shot Learning](/rosinality/ml-papers/blob/main/papers/2020/200627%20Laplacian%20Regularized%20Few-Shot%20Learning.md) #few_shot\n  4. [200724 Deep Co-Training with Task Decomposition for Semi-Supervised Domain](/rosinality/ml-papers/blob/main/papers/2020/200724%20Deep%20Co-Training%20with%20Task%20Decomposition%20for%20Semi-Supervised%20Domain.md) #domain_adaptation\n  5. [201116 On the Marginal Benefit of Active Learning](/rosinality/ml-papers/blob/main/papers/2020/201116%20On%20the%20Marginal%20Benefit%20of%20Active%20Learning.md) #active_learning #unsupervised_training\n  6. [201118 FROST](/rosinality/ml-papers/blob/main/papers/2020/201118%20FROST.md)\n  7. [220811 Semi-supervised Vision Transformers at Scale](/rosinality/ml-papers/blob/main/papers/2022/220811%20Semi-supervised%20Vision%20Transformers%20at%20Scale.md)\n  8. [220829 Open-Set Semi-Supervised Object Detection](/rosinality/ml-papers/blob/main/papers/2022/220829%20Open-Set%20Semi-Supervised%20Object%20Detection.md) #open_set_recognition\n  9. [220918 The Geometry of Self-supervised Learning Models and its Impact on Transfer Learning](/rosinality/ml-papers/blob/main/papers/2022/220918%20The%20Geometry%20of%20Self-supervised%20Learning%20Models%20and%20its%20Impact%20on%20Transfer%20Learning.md)\n\n## seq2seq\n\n  1. [230502 Unlimiformer](/rosinality/ml-papers/blob/main/papers/2023/230502%20Unlimiformer.md)\n\n## sgld\n\n  1.", "start_char_idx": 208581, "end_char_idx": 211585, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8ce21e9b-9a76-4a21-a3d9-a79f96cef94c": {"__data__": {"id_": "8ce21e9b-9a76-4a21-a3d9-a79f96cef94c", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e3d49e79-0357-45dd-b3b1-3d84ce5e7e19", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "0bc7e1147eabcad079a6605bd1384319352b9e86d7d2c4ae5e20ede4d9976a29", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "901847c2-03d1-4186-b48b-7a6d047e1f4c", "node_type": "1", "metadata": {}, "hash": "44db6f53d51a2463b1488208eb802d35cca6272f47dd39710c9d273c2dbed18b", "class_name": "RelatedNodeInfo"}}, "text": "[220829 Open-Set Semi-Supervised Object Detection](/rosinality/ml-papers/blob/main/papers/2022/220829%20Open-Set%20Semi-Supervised%20Object%20Detection.md) #open_set_recognition\n  9. [220918 The Geometry of Self-supervised Learning Models and its Impact on Transfer Learning](/rosinality/ml-papers/blob/main/papers/2022/220918%20The%20Geometry%20of%20Self-supervised%20Learning%20Models%20and%20its%20Impact%20on%20Transfer%20Learning.md)\n\n## seq2seq\n\n  1. [230502 Unlimiformer](/rosinality/ml-papers/blob/main/papers/2023/230502%20Unlimiformer.md)\n\n## sgld\n\n  1. [200706 Kernel Stein Generative Modeling](/rosinality/ml-papers/blob/main/papers/2020/200706%20Kernel%20Stein%20Generative%20Modeling.md) #svgd\n\n## singing voice synthesis\n\n  1. [211008 KaraSinger](/rosinality/ml-papers/blob/main/papers/2021/211008%20KaraSinger.md)\n\n## single image\n\n  1. [200405 Structural-analogy from a Single Image Pair](/rosinality/ml-papers/blob/main/papers/2020/200405%20Structural-analogy%20from%20a%20Single%20Image%20Pair.md)\n\n## speech\n\n  1. [200129 Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/200129%20Speech%20Recognition.md)\n  2. [200129 WaveFlow](/rosinality/ml-papers/blob/main/papers/2020/200129%20WaveFlow.md) #conditional_generative_model\n  3. [230511 CoMoSpeech](/rosinality/ml-papers/blob/main/papers/2023/230511%20CoMoSpeech.md) #audio_synthesis\n\n## state space model\n\n  1. [211031 Efficiently Modeling Long Sequences with Structured State Spaces](/rosinality/ml-papers/blob/main/papers/2021/211031%20Efficiently%20Modeling%20Long%20Sequences%20with%20Structured%20State%20Spaces.md)\n  2. [221017 What Makes Convolutional Models Great on Long Sequence Modeling](/rosinality/ml-papers/blob/main/papers/2022/221017%20What%20Makes%20Convolutional%20Models%20Great%20on%20Long%20Sequence%20Modeling.md)\n  3. [230213 Simple Hardware-Efficient Long Convolutions for Sequence Modeling](/rosinality/ml-papers/blob/main/papers/2023/230213%20Simple%20Hardware-Efficient%20Long%20Convolutions%20for%20Sequence%20Modeling.md)\n\n## structure learning\n\n  1. [200518 Large-scale empirical validation of Bayesian Network structure learning](/rosinality/ml-papers/blob/main/papers/2020/200518%20Large-scale%20empirical%20validation%20of%20Bayesian%20Network%20structure%20learning.md)\n\n## style transfer\n\n  1. [200318 A Content Transformation Block For Image Style Transfer](/rosinality/ml-papers/blob/main/papers/2020/200318%20A%20Content%20Transformation%20Block%20For%20Image%20Style%20Transfer.md)\n  2. [200324 Deformable Style Transfer](/rosinality/ml-papers/blob/main/papers/2020/200324%20Deformable%20Style%20Transfer.md)\n  3. [200710 Geometric Style Transfer](/rosinality/ml-papers/blob/main/papers/2020/200710%20Geometric%20Style%20Transfer.md)\n\n## stylegan\n\n  1. [210318 Labels4Free](/rosinality/ml-papers/blob/main/papers/2021/210318%20Labels4Free.md) #unsupervised_segmentation\n\n## super resolution\n\n  1. [200129 ESRGAN+](/rosinality/ml-papers/blob/main/papers/2020/200129%20ESRGAN%2B.md)\n  2.", "start_char_idx": 211022, "end_char_idx": 214032, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "901847c2-03d1-4186-b48b-7a6d047e1f4c": {"__data__": {"id_": "901847c2-03d1-4186-b48b-7a6d047e1f4c", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8ce21e9b-9a76-4a21-a3d9-a79f96cef94c", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ad280693aeee5f7dac1f76cb2620249f1b2dc96190ae8721916b2a080bede02b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "88c3bbda-4050-4618-9836-9ef45dbb9eda", "node_type": "1", "metadata": {}, "hash": "ae63b95e90d86656e32e1ec53127ad4d0ae3ed34701ed383f5637cb839bc0545", "class_name": "RelatedNodeInfo"}}, "text": "[200324 Deformable Style Transfer](/rosinality/ml-papers/blob/main/papers/2020/200324%20Deformable%20Style%20Transfer.md)\n  3. [200710 Geometric Style Transfer](/rosinality/ml-papers/blob/main/papers/2020/200710%20Geometric%20Style%20Transfer.md)\n\n## stylegan\n\n  1. [210318 Labels4Free](/rosinality/ml-papers/blob/main/papers/2021/210318%20Labels4Free.md) #unsupervised_segmentation\n\n## super resolution\n\n  1. [200129 ESRGAN+](/rosinality/ml-papers/blob/main/papers/2020/200129%20ESRGAN%2B.md)\n  2. [200323 Deep Unfolding Network for Image Super-Resolution](/rosinality/ml-papers/blob/main/papers/2020/200323%20Deep%20Unfolding%20Network%20for%20Image%20Super-Resolution.md)\n\n## table\n\n  1. [210906 Parsing Table Structures in the Wild](/rosinality/ml-papers/blob/main/papers/2021/210906%20Parsing%20Table%20Structures%20in%20the%20Wild.md)\n  2. [220809 TSRFormer](/rosinality/ml-papers/blob/main/papers/2022/220809%20TSRFormer.md)\n\n## text generation\n\n  1. [200130 Unlikelihood Training](/rosinality/ml-papers/blob/main/papers/2020/200130%20Unlikelihood%20Training.md)\n  2. [200605 CoCon](/rosinality/ml-papers/blob/main/papers/2020/200605%20CoCon.md)\n\n## text2img\n\n  1. [221125 3DDesigner](/rosinality/ml-papers/blob/main/papers/2022/221125%203DDesigner.md) #3d_generative_model\n  2. [221125 SpaText](/rosinality/ml-papers/blob/main/papers/2022/221125%20SpaText.md)\n  3. [230502 Pick-a-Pic](/rosinality/ml-papers/blob/main/papers/2023/230502%20Pick-a-Pic.md)\n\n## tokenizer\n\n  1. [211006 How BPE Affects Memorization in Transformers](/rosinality/ml-papers/blob/main/papers/2021/211006%20How%20BPE%20Affects%20Memorization%20in%20Transformers.md)\n  2. [230421 Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition](/rosinality/ml-papers/blob/main/papers/2023/230421%20Evaluating%20Transformer%20Language%20Models%20on%20Arithmetic%20Operations%20Using%20Number%20Decomposition.md)\n\n## topic model\n\n  1. [200426 Neural Topic Modeling with Bidirectional Adversarial Training](/rosinality/ml-papers/blob/main/papers/2020/200426%20Neural%20Topic%20Modeling%20with%20Bidirectional%20Adversarial%20Training.md)\n\n## topology\n\n  1. [200413 Topology of deep neural networks](/rosinality/ml-papers/blob/main/papers/2020/200413%20Topology%20of%20deep%20neural%20networks.md) #theory\n\n## tracking\n\n  1. [200402 Tracking Objects as Points](/rosinality/ml-papers/blob/main/papers/2020/200402%20Tracking%20Objects%20as%20Points.md) #keypoint\n  2. [200402 Tracking by Instance Detection](/rosinality/ml-papers/blob/main/papers/2020/200402%20Tracking%20by%20Instance%20Detection.md) #meta_learning\n  3. [200403 FairMOT](/rosinality/ml-papers/blob/main/papers/2020/200403%20FairMOT.md)\n  4. [200506 PeTra](/rosinality/ml-papers/blob/main/papers/2020/200506%20PeTra.md)\n  5. [201215 Detecting Invisible People](/rosinality/ml-papers/blob/main/papers/2020/201215%20Detecting%20Invisible%20People.md)\n  6.", "start_char_idx": 213534, "end_char_idx": 216455, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "88c3bbda-4050-4618-9836-9ef45dbb9eda": {"__data__": {"id_": "88c3bbda-4050-4618-9836-9ef45dbb9eda", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "901847c2-03d1-4186-b48b-7a6d047e1f4c", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "e705f4ab4d1d9e94cef6ac17277d87078af54d3f3ed10bd55c906d62e8b7134e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bd9bf0d2-c2b1-4d1b-894b-4ac7416182b1", "node_type": "1", "metadata": {}, "hash": "66c6768ff1cce6db2e9737213efa5c2e03fccbdbb53502b80a1069332a3036a1", "class_name": "RelatedNodeInfo"}}, "text": "[200402 Tracking by Instance Detection](/rosinality/ml-papers/blob/main/papers/2020/200402%20Tracking%20by%20Instance%20Detection.md) #meta_learning\n  3. [200403 FairMOT](/rosinality/ml-papers/blob/main/papers/2020/200403%20FairMOT.md)\n  4. [200506 PeTra](/rosinality/ml-papers/blob/main/papers/2020/200506%20PeTra.md)\n  5. [201215 Detecting Invisible People](/rosinality/ml-papers/blob/main/papers/2020/201215%20Detecting%20Invisible%20People.md)\n  6. [211013 ByteTrack](/rosinality/ml-papers/blob/main/papers/2021/211013%20ByteTrack.md)\n\n## training\n\n  1. [200702 Beyond Signal Propagation](/rosinality/ml-papers/blob/main/papers/2020/200702%20Beyond%20Signal%20Propagation.md)\n\n## transducer\n\n  1. [200519 A New Training Pipeline for an Improved Neural Transducer](/rosinality/ml-papers/blob/main/papers/2020/200519%20A%20New%20Training%20Pipeline%20for%20an%20Improved%20Neural%20Transducer.md)\n\n## transfer\n\n  1. [200130 BiT ResNet](/rosinality/ml-papers/blob/main/papers/2020/200130%20BiT%20ResNet.md) #resnet\n  2. [200512 Neural Architecture Transfer](/rosinality/ml-papers/blob/main/papers/2020/200512%20Neural%20Architecture%20Transfer.md) #nas\n  3. [200711 Adversarially-Trained Deep Nets Transfer Better](/rosinality/ml-papers/blob/main/papers/2020/200711%20Adversarially-Trained%20Deep%20Nets%20Transfer%20Better.md) #adversarial_training\n  4. [200716 Do Adversarially Robust ImageNet Models Transfer Better](/rosinality/ml-papers/blob/main/papers/2020/200716%20Do%20Adversarially%20Robust%20ImageNet%20Models%20Transfer%20Better.md) #robust\n  5. [200721 Adversarial Training Reduces Information and Improves Transferability](/rosinality/ml-papers/blob/main/papers/2020/200721%20Adversarial%20Training%20Reduces%20Information%20and%20Improves%20Transferability.md) #adversarial_training\n  6. [201122 Ranking Neural Checkpoints](/rosinality/ml-papers/blob/main/papers/2020/201122%20Ranking%20Neural%20Checkpoints.md)\n  7. [211012 Rethinking supervised pre-training for better downstream transferring](/rosinality/ml-papers/blob/main/papers/2021/211012%20Rethinking%20supervised%20pre-training%20for%20better%20downstream%20transferring.md) #classificiation #metric_learning\n\n## transformer\n\n  1. [200129 Are Transformers universal approximator](/rosinality/ml-papers/blob/main/papers/2020/200129%20Are%20Transformers%20universal%20approximator.md)\n  2. [200129 Product Key Memory](/rosinality/ml-papers/blob/main/papers/2020/200129%20Product%20Key%20Memory.md) #attention\n  3. [200129 Reformer](/rosinality/ml-papers/blob/main/papers/2020/200129%20Reformer.md) #attention\n  4. [200130 RoBERTa](/rosinality/ml-papers/blob/main/papers/2020/200130%20RoBERTa.md) #pretraining #language_model #nlp\n  5. [200130 Sparse Transformer](/rosinality/ml-papers/blob/main/papers/2020/200130%20Sparse%20Transformer.md) #generative_model\n  6. [200130 Structured Pruning for LM](/rosinality/ml-papers/blob/main/papers/2020/200130%20Structured%20Pruning%20for%20LM.md) #pruning\n  7.", "start_char_idx": 216003, "end_char_idx": 218978, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd9bf0d2-c2b1-4d1b-894b-4ac7416182b1": {"__data__": {"id_": "bd9bf0d2-c2b1-4d1b-894b-4ac7416182b1", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "88c3bbda-4050-4618-9836-9ef45dbb9eda", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "51fe46f09c013b047fbdc4041bd9770773ae5f28e3615ab15547217ec2105110", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e57147ab-9e3c-4c6b-bf0e-92f8c195843a", "node_type": "1", "metadata": {}, "hash": "3156761f62e75376af0922b2ccc3eebf40c966ec9084c3198131f3c9aca53edf", "class_name": "RelatedNodeInfo"}}, "text": "[200129 Reformer](/rosinality/ml-papers/blob/main/papers/2020/200129%20Reformer.md) #attention\n  4. [200130 RoBERTa](/rosinality/ml-papers/blob/main/papers/2020/200130%20RoBERTa.md) #pretraining #language_model #nlp\n  5. [200130 Sparse Transformer](/rosinality/ml-papers/blob/main/papers/2020/200130%20Sparse%20Transformer.md) #generative_model\n  6. [200130 Structured Pruning for LM](/rosinality/ml-papers/blob/main/papers/2020/200130%20Structured%20Pruning%20for%20LM.md) #pruning\n  7. [200130 T5](/rosinality/ml-papers/blob/main/papers/2020/200130%20T5.md) #pretraining #nlp #seq2seq\n  8. [200207 Transformer Transducer](/rosinality/ml-papers/blob/main/papers/2020/200207%20Transformer%20Transducer.md) #asr #transducer\n  9. [200211 On Layer Normalization in the Transformer Architecture](/rosinality/ml-papers/blob/main/papers/2020/200211%20On%20Layer%20Normalization%20in%20the%20Transformer%20Architecture.md) #normalization\n  10. [200212 GLU Variants Improve Transformer](/rosinality/ml-papers/blob/main/papers/2020/200212%20GLU%20Variants%20Improve%20Transformer.md) #activation\n  11. [200214 Transformer on a Diet](/rosinality/ml-papers/blob/main/papers/2020/200214%20Transformer%20on%20a%20Diet.md) #efficient_attention\n  12. [200214 Transformers as Soft Reasoners over Language](/rosinality/ml-papers/blob/main/papers/2020/200214%20Transformers%20as%20Soft%20Reasoners%20over%20Language.md) #language\n  13. [200215 Fine-Tuning Pretrained Language Models](/rosinality/ml-papers/blob/main/papers/2020/200215%20Fine-Tuning%20Pretrained%20Language%20Models.md) #bert #finetuning\n  14. [200221 Addressing Some Limitations of Transformers with Feedback Memory](/rosinality/ml-papers/blob/main/papers/2020/200221%20Addressing%20Some%20Limitations%20of%20Transformers%20with%20Feedback%20Memory.md) #recurrent\n  15. [200305 Talking-Heads Attention](/rosinality/ml-papers/blob/main/papers/2020/200305%20Talking-Heads%20Attention.md) #attention\n  16. [200424 Lite Transformer with Long-Short Range Attention](/rosinality/ml-papers/blob/main/papers/2020/200424%20Lite%20Transformer%20with%20Long-Short%20Range%20Attention.md) #lightweight\n  17. [200515 Finding Experts in Transformer Models](/rosinality/ml-papers/blob/main/papers/2020/200515%20Finding%20Experts%20in%20Transformer%20Models.md)\n  18. [200515 JDI-T](/rosinality/ml-papers/blob/main/papers/2020/200515%20JDI-T.md) #tts\n  19. [200516 Conformer](/rosinality/ml-papers/blob/main/papers/2020/200516%20Conformer.md) #asr\n  20. [200518 Weak-Attention Suppression For Transformer Based Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/200518%20Weak-Attention%20Suppression%20For%20Transformer%20Based%20Speech%20Recognition.md) #asr\n  21. [200605 Funnel-Transformer](/rosinality/ml-papers/blob/main/papers/2020/200605%20Funnel-Transformer.md) #efficient_attention\n  22. [200707 Do Transformers Need Deep Long-Range Memory](/rosinality/ml-papers/blob/main/papers/2020/200707%20Do%20Transformers%20Need%20Deep%20Long-Range%20Memory.md) #lm #attention\n  23.", "start_char_idx": 218491, "end_char_idx": 221518, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e57147ab-9e3c-4c6b-bf0e-92f8c195843a": {"__data__": {"id_": "e57147ab-9e3c-4c6b-bf0e-92f8c195843a", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd9bf0d2-c2b1-4d1b-894b-4ac7416182b1", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "291abab013da0e991e249902214845a06fb01d6ef41098b6e66c03e6237c8be2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2ebe27a4-ee28-4149-9743-85b59d08fd6b", "node_type": "1", "metadata": {}, "hash": "dda532c08cd061bf6a294a0600061e61b8dda5a4995af25d9e9a2c2625a1844b", "class_name": "RelatedNodeInfo"}}, "text": "[200518 Weak-Attention Suppression For Transformer Based Speech Recognition](/rosinality/ml-papers/blob/main/papers/2020/200518%20Weak-Attention%20Suppression%20For%20Transformer%20Based%20Speech%20Recognition.md) #asr\n  21. [200605 Funnel-Transformer](/rosinality/ml-papers/blob/main/papers/2020/200605%20Funnel-Transformer.md) #efficient_attention\n  22. [200707 Do Transformers Need Deep Long-Range Memory](/rosinality/ml-papers/blob/main/papers/2020/200707%20Do%20Transformers%20Need%20Deep%20Long-Range%20Memory.md) #lm #attention\n  23. [200709 Fast Transformers with Clustered Attention](/rosinality/ml-papers/blob/main/papers/2020/200709%20Fast%20Transformers%20with%20Clustered%20Attention.md) #attention\n  24. [200715 AdapterHub](/rosinality/ml-papers/blob/main/papers/2020/200715%20AdapterHub.md) #nlp #finetuning\n  25. [200727 Big Bird](/rosinality/ml-papers/blob/main/papers/2020/200727%20Big%20Bird.md) #attention\n  26. [200802 DeLighT](/rosinality/ml-papers/blob/main/papers/2020/200802%20DeLighT.md) #nlp\n  27. [201217 Taming Transformers for High-Resolution Image Synthesis](/rosinality/ml-papers/blob/main/papers/2020/201217%20Taming%20Transformers%20for%20High-Resolution%20Image%20Synthesis.md) #discrete_vae #generative_model #autoregressive_model\n  28. [201221 RealFormer](/rosinality/ml-papers/blob/main/papers/2020/201221%20RealFormer.md) #attention\n  29. [201227 SG-Net](/rosinality/ml-papers/blob/main/papers/2020/201227%20SG-Net.md) #syntax #attention\n  30. [210223 Do Transformer Modifications Transfer Across Implementations and](/rosinality/ml-papers/blob/main/papers/2021/210223%20Do%20Transformer%20Modifications%20Transfer%20Across%20Implementations%20and.md)\n  31. [210225 Evolving Attention with Residual Convolutions](/rosinality/ml-papers/blob/main/papers/2021/210225%20Evolving%20Attention%20with%20Residual%20Convolutions.md) #attention\n  32. [210318 HiT](/rosinality/ml-papers/blob/main/papers/2021/210318%20HiT.md) #video #retrieval\n  33. [210318 Looking Beyond Two Frames](/rosinality/ml-papers/blob/main/papers/2021/210318%20Looking%20Beyond%20Two%20Frames.md) #tracking\n  34. [210318 TFPose](/rosinality/ml-papers/blob/main/papers/2021/210318%20TFPose.md) #pose\n  35. [210318 TransCenter](/rosinality/ml-papers/blob/main/papers/2021/210318%20TransCenter.md) #tracking\n  36. [210318 Transformer Trackin](/rosinality/ml-papers/blob/main/papers/2021/210318%20Transformer%20Trackin.md) #tracking\n  37. [210407 Seeing Out of tHe bOx](/rosinality/ml-papers/blob/main/papers/2021/210407%20Seeing%20Out%20of%20tHe%20bOx.md) #multimodal #vision-language\n  38. [210409 Efficient Large-Scale Language Model Training on GPU Clusters](/rosinality/ml-papers/blob/main/papers/2021/210409%20Efficient%20Large-Scale%20Language%20Model%20Training%20on%20GPU%20Clusters.md) #distributed_training\n  39. [210409 Not All Attention Is All You Need](/rosinality/ml-papers/blob/main/papers/2021/210409%20Not%20All%20Attention%20Is%20All%20You%20Need.md)\n  40.", "start_char_idx": 220978, "end_char_idx": 223954, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2ebe27a4-ee28-4149-9743-85b59d08fd6b": {"__data__": {"id_": "2ebe27a4-ee28-4149-9743-85b59d08fd6b", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e57147ab-9e3c-4c6b-bf0e-92f8c195843a", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "5851a0678864fd481b03829417e7a1b7606cdae4fdcf5811d67e00110785f939", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a2bfdb16-abbd-46ca-8849-e6d63bbb3f79", "node_type": "1", "metadata": {}, "hash": "a5f1ffa266cdbb38eae70802f643f13f5e91666a56d1542ab2ad2af67363947a", "class_name": "RelatedNodeInfo"}}, "text": "[210407 Seeing Out of tHe bOx](/rosinality/ml-papers/blob/main/papers/2021/210407%20Seeing%20Out%20of%20tHe%20bOx.md) #multimodal #vision-language\n  38. [210409 Efficient Large-Scale Language Model Training on GPU Clusters](/rosinality/ml-papers/blob/main/papers/2021/210409%20Efficient%20Large-Scale%20Language%20Model%20Training%20on%20GPU%20Clusters.md) #distributed_training\n  39. [210409 Not All Attention Is All You Need](/rosinality/ml-papers/blob/main/papers/2021/210409%20Not%20All%20Attention%20Is%20All%20You%20Need.md)\n  40. [210410 UniDrop](/rosinality/ml-papers/blob/main/papers/2021/210410%20UniDrop.md) #regularization\n  41. [210417 Demystifying the Better Performance of Position Encoding Variants for](/rosinality/ml-papers/blob/main/papers/2021/210417%20Demystifying%20the%20Better%20Performance%20of%20Position%20Encoding%20Variants%20for.md) #positional_encoding\n  42. [210420 RoFormer](/rosinality/ml-papers/blob/main/papers/2021/210420%20RoFormer.md) #positional_encoding\n  43. [210423 M3DeTR](/rosinality/ml-papers/blob/main/papers/2021/210423%20M3DeTR.md) #3d\n  44. [210509 FNet](/rosinality/ml-papers/blob/main/papers/2021/210509%20FNet.md) #efficient_attention #fourier\n  45. [210510 Are Pre-trained Convolutions Better than Pre-trained Transformers](/rosinality/ml-papers/blob/main/papers/2021/210510%20Are%20Pre-trained%20Convolutions%20Better%20than%20Pre-trained%20Transformers.md) #pretraining #nlp #convolution\n  46. [210613 Thinking Like Transformers](/rosinality/ml-papers/blob/main/papers/2021/210613%20Thinking%20Like%20Transformers.md)\n  47. [210617 Multi-head or Single-head](/rosinality/ml-papers/blob/main/papers/2021/210617%20Multi-head%20or%20Single-head.md)\n  48. [210730 Perceiver IO](/rosinality/ml-papers/blob/main/papers/2021/210730%20Perceiver%20IO.md)\n  49. [210809 Making Transformers Solve Compositional Tasks](/rosinality/ml-papers/blob/main/papers/2021/210809%20Making%20Transformers%20Solve%20Compositional%20Tasks.md)\n  50. [210812 Mobile-Former](/rosinality/ml-papers/blob/main/papers/2021/210812%20Mobile-Former.md) #backbone\n  51. [210830 A Battle of Network Structures](/rosinality/ml-papers/blob/main/papers/2021/210830%20A%20Battle%20of%20Network%20Structures.md) #cnn #mlp #backbone\n  52. [210830 Shatter](/rosinality/ml-papers/blob/main/papers/2021/210830%20Shatter.md) #bert\n  53. [210908 Panoptic SegFormer](/rosinality/ml-papers/blob/main/papers/2021/210908%20Panoptic%20SegFormer.md) #panoptic_segmentation #detr\n  54. [210909 Bag of Tricks for Optimizing Transformer Efficiency](/rosinality/ml-papers/blob/main/papers/2021/210909%20Bag%20of%20Tricks%20for%20Optimizing%20Transformer%20Efficiency.md) #nmt #lightweight\n  55. [210917 Primer](/rosinality/ml-papers/blob/main/papers/2021/210917%20Primer.md) #lm #nas\n  56. [210922 Scale Efficiently](/rosinality/ml-papers/blob/main/papers/2021/210922%20Scale%20Efficiently.md)\n  57.", "start_char_idx": 223418, "end_char_idx": 226315, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a2bfdb16-abbd-46ca-8849-e6d63bbb3f79": {"__data__": {"id_": "a2bfdb16-abbd-46ca-8849-e6d63bbb3f79", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2ebe27a4-ee28-4149-9743-85b59d08fd6b", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b461fde66705a902b6e5c21019b2d828b2bf922ad8d0287ff8cfcd2629f09a41", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0521a981-f013-442b-b558-120dbef93839", "node_type": "1", "metadata": {}, "hash": "7c64c4a276600950ae2257f4458f419206f0765a82af32e58b4e13d3086eec47", "class_name": "RelatedNodeInfo"}}, "text": "[210908 Panoptic SegFormer](/rosinality/ml-papers/blob/main/papers/2021/210908%20Panoptic%20SegFormer.md) #panoptic_segmentation #detr\n  54. [210909 Bag of Tricks for Optimizing Transformer Efficiency](/rosinality/ml-papers/blob/main/papers/2021/210909%20Bag%20of%20Tricks%20for%20Optimizing%20Transformer%20Efficiency.md) #nmt #lightweight\n  55. [210917 Primer](/rosinality/ml-papers/blob/main/papers/2021/210917%20Primer.md) #lm #nas\n  56. [210922 Scale Efficiently](/rosinality/ml-papers/blob/main/papers/2021/210922%20Scale%20Efficiently.md)\n  57. [211018 NormFormer](/rosinality/ml-papers/blob/main/papers/2021/211018%20NormFormer.md)\n  58. [211026 Hierarchical Transformers Are More Efficient Language Models](/rosinality/ml-papers/blob/main/papers/2021/211026%20Hierarchical%20Transformers%20Are%20More%20Efficient%20Language%20Models.md) #lm #efficient_attention\n  59. [211122 MetaFormer is Actually What You Need for Vision](/rosinality/ml-papers/blob/main/papers/2021/211122%20MetaFormer%20is%20Actually%20What%20You%20Need%20for%20Vision.md) #vit\n  60. [211124 Sparse is Enough in Scaling Transformers](/rosinality/ml-papers/blob/main/papers/2021/211124%20Sparse%20is%20Enough%20in%20Scaling%20Transformers.md) #sparsity #efficiency\n  61. [220221 Transformer Quality in Linear Time](/rosinality/ml-papers/blob/main/papers/2022/220221%20Transformer%20Quality%20in%20Linear%20Time.md) #efficient_attention #linear_attention #local_attention\n  62. [220301 DeepNet](/rosinality/ml-papers/blob/main/papers/2022/220301%20DeepNet.md) #normalization\n  63. [220330 Transformer Language Models without Positional Encodings Still Learn Positional Information](/rosinality/ml-papers/blob/main/papers/2022/220330%20Transformer%20Language%20Models%20without%20Positional%20Encodings%20Still%20Learn%20Positional%20Information.md) #lm #positional_encoding\n  64. [220924 In-context Learning and Induction Heads](/rosinality/ml-papers/blob/main/papers/2022/220924%20In-context%20Learning%20and%20Induction%20Heads.md) #in_context_learning\n  65. [221004 MOAT](/rosinality/ml-papers/blob/main/papers/2022/221004%20MOAT.md) #backbone\n  66. [221220 A Length-Extrapolatable Transformer](/rosinality/ml-papers/blob/main/papers/2022/221220%20A%20Length-Extrapolatable%20Transformer.md) #positional_encoding\n  67. [230209 In-Context Learning with Many Demonstration Examples](/rosinality/ml-papers/blob/main/papers/2023/230209%20In-Context%20Learning%20with%20Many%20Demonstration%20Examples.md) #efficient_attention\n  68. [230311 Stabilizing Transformer Training by Preventing Attention Entropy Collapse](/rosinality/ml-papers/blob/main/papers/2023/230311%20Stabilizing%20Transformer%20Training%20by%20Preventing%20Attention%20Entropy%20Collapse.md) #stability\n  69. [230419 Scaling Transformer to 1M tokens and beyond with RMT](/rosinality/ml-papers/blob/main/papers/2023/230419%20Scaling%20Transformer%20to%201M%20tokens%20and%20beyond%20with%20RMT.md)\n  70. [230428 ResiDual](/rosinality/ml-papers/blob/main/papers/2023/230428%20ResiDual.md) #normalization\n  71.", "start_char_idx": 225764, "end_char_idx": 228816, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0521a981-f013-442b-b558-120dbef93839": {"__data__": {"id_": "0521a981-f013-442b-b558-120dbef93839", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a2bfdb16-abbd-46ca-8849-e6d63bbb3f79", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "db002d050918a1514d6b62a6d28222913246fb2446acfb997d403f125ed1e113", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d6e1ecc-6a42-44bc-9e64-a625996cda4c", "node_type": "1", "metadata": {}, "hash": "8b5ab926c5f51b4ca0b09a515734e910c8804c7c75f3b36c13a5e475140967ee", "class_name": "RelatedNodeInfo"}}, "text": "[230311 Stabilizing Transformer Training by Preventing Attention Entropy Collapse](/rosinality/ml-papers/blob/main/papers/2023/230311%20Stabilizing%20Transformer%20Training%20by%20Preventing%20Attention%20Entropy%20Collapse.md) #stability\n  69. [230419 Scaling Transformer to 1M tokens and beyond with RMT](/rosinality/ml-papers/blob/main/papers/2023/230419%20Scaling%20Transformer%20to%201M%20tokens%20and%20beyond%20with%20RMT.md)\n  70. [230428 ResiDual](/rosinality/ml-papers/blob/main/papers/2023/230428%20ResiDual.md) #normalization\n  71. [230504 BranchNorm](/rosinality/ml-papers/blob/main/papers/2023/230504%20BranchNorm.md) #normalization\n  72. [230504 On the Expressivity Role of LayerNorm in Transformers' Attention](/rosinality/ml-papers/blob/main/papers/2023/230504%20On%20the%20Expressivity%20Role%20of%20LayerNorm%20in%20Transformers%27%20Attention.md) #attention #normalization\n  73. [230507 Vcc](/rosinality/ml-papers/blob/main/papers/2023/230507%20Vcc.md) #efficient_attention\n  74. [230512 MEGABYTE](/rosinality/ml-papers/blob/main/papers/2023/230512%20MEGABYTE.md) #tokenizer\n  75. [230512 TinyStories](/rosinality/ml-papers/blob/main/papers/2023/230512%20TinyStories.md) #lm\n  76. [230522 GQA](/rosinality/ml-papers/blob/main/papers/2023/230522%20GQA.md)\n  77. [230530 Grokking of Hierarchical Structure in Vanilla Transformers](/rosinality/ml-papers/blob/main/papers/2023/230530%20Grokking%20of%20Hierarchical%20Structure%20in%20Vanilla%20Transformers.md)\n  78. [230612 Augmenting Language Models with Long-Term Memory](/rosinality/ml-papers/blob/main/papers/2023/230612%20Augmenting%20Language%20Models%20with%20Long-Term%20Memory.md)\n  79. [230622 Quantizable Transformers](/rosinality/ml-papers/blob/main/papers/2023/230622%20Quantizable%20Transformers.md)\n  80. [230627 Length Generalization in Arithmetic Transformers](/rosinality/ml-papers/blob/main/papers/2023/230627%20Length%20Generalization%20in%20Arithmetic%20Transformers.md)\n  81. [230706 Lost in the Middle](/rosinality/ml-papers/blob/main/papers/2023/230706%20Lost%20in%20the%20Middle.md) #lm\n  82. [230707 Teaching Arithmetic to Small Transformers](/rosinality/ml-papers/blob/main/papers/2023/230707%20Teaching%20Arithmetic%20to%20Small%20Transformers.md)\n  83. [230720 L-Eval](/rosinality/ml-papers/blob/main/papers/2023/230720%20L-Eval.md) #benchmark\n  84. [230727 Scaling TransNormer to 175 Billion Parameters](/rosinality/ml-papers/blob/main/papers/2023/230727%20Scaling%20TransNormer%20to%20175%20Billion%20Parameters.md) #efficient_attention\n\n## tropical geometry\n\n  1. [200220 On the Decision Boundaries of Neural Networks](/rosinality/ml-papers/blob/main/papers/2020/200220%20On%20the%20Decision%20Boundaries%20of%20Neural%20Networks.md)\n\n## tts\n\n  1. [200512 Flowtron](/rosinality/ml-papers/blob/main/papers/2020/200512%20Flowtron.md) #flow\n  2. [210617 WaveGrad 2](/rosinality/ml-papers/blob/main/papers/2021/210617%20WaveGrad%202.md)\n\n## uncertainty\n\n  1.", "start_char_idx": 228273, "end_char_idx": 231226, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4d6e1ecc-6a42-44bc-9e64-a625996cda4c": {"__data__": {"id_": "4d6e1ecc-6a42-44bc-9e64-a625996cda4c", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0521a981-f013-442b-b558-120dbef93839", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "9abd3dbe1d57a1017e71cf7b067a8342554afa2c5afb7dc3830ef5c777ece306", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aad62f9a-261f-4fac-a0d6-5f838a8e9328", "node_type": "1", "metadata": {}, "hash": "bdd5a990077ed5186ecc09701efb233a96061ff9df0184400a013a48c7d3a860", "class_name": "RelatedNodeInfo"}}, "text": "[200220 On the Decision Boundaries of Neural Networks](/rosinality/ml-papers/blob/main/papers/2020/200220%20On%20the%20Decision%20Boundaries%20of%20Neural%20Networks.md)\n\n## tts\n\n  1. [200512 Flowtron](/rosinality/ml-papers/blob/main/papers/2020/200512%20Flowtron.md) #flow\n  2. [210617 WaveGrad 2](/rosinality/ml-papers/blob/main/papers/2021/210617%20WaveGrad%202.md)\n\n## uncertainty\n\n  1. [210727 A Tale Of Two Long Tails](/rosinality/ml-papers/blob/main/papers/2021/210727%20A%20Tale%20Of%20Two%20Long%20Tails.md)\n\n## unsupervised img2img\n\n  1. [200310 Unpaired Image-to-Image Translation using Adversarial Consistency Loss](/rosinality/ml-papers/blob/main/papers/2020/200310%20Unpaired%20Image-to-Image%20Translation%20using%20Adversarial%20Consistency%20Loss.md)\n  2. [200611 Rethinking the Truly Unsupervised Image-to-Image Translation](/rosinality/ml-papers/blob/main/papers/2020/200611%20Rethinking%20the%20Truly%20Unsupervised%20Image-to-Image%20Translation.md)\n  3. [201201 Unpaired Image-to-Image Translation via Latent Energy Transport](/rosinality/ml-papers/blob/main/papers/2020/201201%20Unpaired%20Image-to-Image%20Translation%20via%20Latent%20Energy%20Transport.md)\n\n## unsupervised nmt\n\n  1. [200422 When and Why is Unsupervised Neural Machine Translation Useless](/rosinality/ml-papers/blob/main/papers/2020/200422%20When%20and%20Why%20is%20Unsupervised%20Neural%20Machine%20Translation%20Useless.md)\n\n## vae\n\n  1. [200420 Bringing Old Photos Back to Life](/rosinality/ml-papers/blob/main/papers/2020/200420%20Bringing%20Old%20Photos%20Back%20to%20Life.md) #restoration\n  2. [200707 NVAE](/rosinality/ml-papers/blob/main/papers/2020/200707%20NVAE.md)\n  3. [201119 Dual Contradistinctive Generative Autoencoder](/rosinality/ml-papers/blob/main/papers/2020/201119%20Dual%20Contradistinctive%20Generative%20Autoencoder.md)\n  4. [201120 Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them](/rosinality/ml-papers/blob/main/papers/2020/201120%20Very%20Deep%20VAEs%20Generalize%20Autoregressive%20Models%20and%20Can%20Outperform%20Them.md)\n\n## video\n\n  1. [210325 An Image is Worth 16x16 Words, What is a Video Worth](/rosinality/ml-papers/blob/main/papers/2021/210325%20An%20Image%20is%20Worth%2016x16%20Words%2C%20What%20is%20a%20Video%20Worth.md)\n\n## video transformer\n\n  1. [210423 VidTr](/rosinality/ml-papers/blob/main/papers/2021/210423%20VidTr.md)\n\n## vision\n\n  1. [200305 Optimizing JPEG Quantization for Classification Networks](/rosinality/ml-papers/blob/main/papers/2020/200305%20Optimizing%20JPEG%20Quantization%20for%20Classification%20Networks.md)\n  2. [201127 Field of Junctions](/rosinality/ml-papers/blob/main/papers/2020/201127%20Field%20of%20Junctions.md)\n\n## vision language\n\n  1. [201212 MiniVLM](/rosinality/ml-papers/blob/main/papers/2020/201212%20MiniVLM.md)\n  2.", "start_char_idx": 230836, "end_char_idx": 233655, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aad62f9a-261f-4fac-a0d6-5f838a8e9328": {"__data__": {"id_": "aad62f9a-261f-4fac-a0d6-5f838a8e9328", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d6e1ecc-6a42-44bc-9e64-a625996cda4c", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "9b5beaa5975d4e7dfbc2b5ea01e41514a9e96ace156daacdfa3d0aefb0871b38", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6c000b3c-f989-4b64-b81f-9e8bd376c891", "node_type": "1", "metadata": {}, "hash": "fe6c8e7a051c2406a3e8c80ae97aafb3cf430327a7ece1adf5b1760c5cb32dfb", "class_name": "RelatedNodeInfo"}}, "text": "[210423 VidTr](/rosinality/ml-papers/blob/main/papers/2021/210423%20VidTr.md)\n\n## vision\n\n  1. [200305 Optimizing JPEG Quantization for Classification Networks](/rosinality/ml-papers/blob/main/papers/2020/200305%20Optimizing%20JPEG%20Quantization%20for%20Classification%20Networks.md)\n  2. [201127 Field of Junctions](/rosinality/ml-papers/blob/main/papers/2020/201127%20Field%20of%20Junctions.md)\n\n## vision language\n\n  1. [201212 MiniVLM](/rosinality/ml-papers/blob/main/papers/2020/201212%20MiniVLM.md)\n  2. [201222 Seeing past words](/rosinality/ml-papers/blob/main/papers/2020/201222%20Seeing%20past%20words.md)\n  3. [210407 Multimodal Fusion Refiner Networks](/rosinality/ml-papers/blob/main/papers/2021/210407%20Multimodal%20Fusion%20Refiner%20Networks.md)\n  4. [210727 Is Object Detection Necessary for Human-Object Interaction Recognition](/rosinality/ml-papers/blob/main/papers/2021/210727%20Is%20Object%20Detection%20Necessary%20for%20Human-Object%20Interaction%20Recognition.md) #human-object-interaction\n  5. [220221 Vision-Language Pre-Training with Triple Contrastive Learning](/rosinality/ml-papers/blob/main/papers/2022/220221%20Vision-Language%20Pre-Training%20with%20Triple%20Contrastive%20Learning.md)\n  6. [220504 CoCa](/rosinality/ml-papers/blob/main/papers/2022/220504%20CoCa.md)\n  7. [220612 GLIPv2](/rosinality/ml-papers/blob/main/papers/2022/220612%20GLIPv2.md)\n  8. [220615 Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone](/rosinality/ml-papers/blob/main/papers/2022/220615%20Coarse-to-Fine%20Vision-Language%20Pre-training%20with%20Fusion%20in%20the%20Backbone.md)\n  9. [220617 Bridge-Tower](/rosinality/ml-papers/blob/main/papers/2022/220617%20Bridge-Tower.md)\n  10. [220617 Unified-IO](/rosinality/ml-papers/blob/main/papers/2022/220617%20Unified-IO.md) #multitask\n  11. [220810 Patching open-vocabulary models by interpolating weights](/rosinality/ml-papers/blob/main/papers/2022/220810%20Patching%20open-vocabulary%20models%20by%20interpolating%20weights.md) #clip #multitask #domain\n  12. [220822 Image as a Foreign Language](/rosinality/ml-papers/blob/main/papers/2022/220822%20Image%20as%20a%20Foreign%20Language.md) #mlm\n  13. [230209 Re-ViLM](/rosinality/ml-papers/blob/main/papers/2023/230209%20Re-ViLM.md)\n  14. [230313 Scaling Vision-Language Models with Sparse Mixture of Experts](/rosinality/ml-papers/blob/main/papers/2023/230313%20Scaling%20Vision-Language%20Models%20with%20Sparse%20Mixture%20of%20Experts.md) #mixture_of_experts\n\n## vision transformer\n\n  1. [201127 General Multi-label Image Classification with Transformers](/rosinality/ml-papers/blob/main/papers/2020/201127%20General%20Multi-label%20Image%20Classification%20with%20Transformers.md)\n  2. [201223 A Survey on Visual Transformer](/rosinality/ml-papers/blob/main/papers/2020/201223%20A%20Survey%20on%20Visual%20Transformer.md)\n  3.", "start_char_idx": 233145, "end_char_idx": 236012, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6c000b3c-f989-4b64-b81f-9e8bd376c891": {"__data__": {"id_": "6c000b3c-f989-4b64-b81f-9e8bd376c891", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aad62f9a-261f-4fac-a0d6-5f838a8e9328", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "88a74ee5e6e531533e55040faeb528ab4d170e17fc096a157073d179cd55f927", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b9aba0a4-89b5-45fc-b3b2-62dcfa26196e", "node_type": "1", "metadata": {}, "hash": "3539c2e2ccea36fc887c7a17fe5733442d0fa071725e7fd4191d58da43ab56f5", "class_name": "RelatedNodeInfo"}}, "text": "[230313 Scaling Vision-Language Models with Sparse Mixture of Experts](/rosinality/ml-papers/blob/main/papers/2023/230313%20Scaling%20Vision-Language%20Models%20with%20Sparse%20Mixture%20of%20Experts.md) #mixture_of_experts\n\n## vision transformer\n\n  1. [201127 General Multi-label Image Classification with Transformers](/rosinality/ml-papers/blob/main/papers/2020/201127%20General%20Multi-label%20Image%20Classification%20with%20Transformers.md)\n  2. [201223 A Survey on Visual Transformer](/rosinality/ml-papers/blob/main/papers/2020/201223%20A%20Survey%20on%20Visual%20Transformer.md)\n  3. [201223 Training data-efficient image transformers & distillation through](/rosinality/ml-papers/blob/main/papers/2020/201223%20Training%20data-efficient%20image%20transformers%20%26%20distillation%20through.md) #distillation\n  4. [210223 Pyramid Vision Transformer](/rosinality/ml-papers/blob/main/papers/2021/210223%20Pyramid%20Vision%20Transformer.md)\n  5. [210318 CrossViT](/rosinality/ml-papers/blob/main/papers/2021/210318%20CrossViT.md)\n  6. [210318 CvT](/rosinality/ml-papers/blob/main/papers/2021/210318%20CvT.md)\n  7. [210318 Multi-Scale Vision Longformer](/rosinality/ml-papers/blob/main/papers/2021/210318%20Multi-Scale%20Vision%20Longformer.md)\n  8. [210319 ConViT](/rosinality/ml-papers/blob/main/papers/2021/210319%20ConViT.md)\n  9. [210319 Scalable Visual Transformers with Hierarchical Pooling](/rosinality/ml-papers/blob/main/papers/2021/210319%20Scalable%20Visual%20Transformers%20with%20Hierarchical%20Pooling.md)\n  10. [210324 Vision Transformers for Dense Prediction](/rosinality/ml-papers/blob/main/papers/2021/210324%20Vision%20Transformers%20for%20Dense%20Prediction.md) #fpn\n  11. [210325 Swin Transformer](/rosinality/ml-papers/blob/main/papers/2021/210325%20Swin%20Transformer.md) #local_attention\n  12. [210331 Going deeper with Image Transformers](/rosinality/ml-papers/blob/main/papers/2021/210331%20Going%20deeper%20with%20Image%20Transformers.md)\n  13. [210402 LeViT](/rosinality/ml-papers/blob/main/papers/2021/210402%20LeViT.md)\n  14. [210421 Token Labeling](/rosinality/ml-papers/blob/main/papers/2021/210421%20Token%20Labeling.md)\n  15. [210422 Multiscale Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/210422%20Multiscale%20Vision%20Transformers.md)\n  16. [210422 So-ViT](/rosinality/ml-papers/blob/main/papers/2021/210422%20So-ViT.md)\n  17. [210426 Improve Vision Transformers Training by Suppressing Over-smoothing](/rosinality/ml-papers/blob/main/papers/2021/210426%20Improve%20Vision%20Transformers%20Training%20by%20Suppressing%20Over-smoothing.md)\n  18. [210426 Visformer](/rosinality/ml-papers/blob/main/papers/2021/210426%20Visformer.md)\n  19. [210427 ConTNet](/rosinality/ml-papers/blob/main/papers/2021/210427%20ConTNet.md)\n  20. [210428 Twins](/rosinality/ml-papers/blob/main/papers/2021/210428%20Twins.md) #local_attention #positional_encoding\n  21. [210509 Conformer](/rosinality/ml-papers/blob/main/papers/2021/210509%20Conformer.md)\n  22.", "start_char_idx": 235420, "end_char_idx": 238422, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b9aba0a4-89b5-45fc-b3b2-62dcfa26196e": {"__data__": {"id_": "b9aba0a4-89b5-45fc-b3b2-62dcfa26196e", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6c000b3c-f989-4b64-b81f-9e8bd376c891", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "3145902706fce3c6f0c49d668a7c0f0710438b0f0847b598dbcd8410618b4b7a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5749cac3-dcf1-4276-895d-be27cbcde49f", "node_type": "1", "metadata": {}, "hash": "617fc8caed7f9b44f7f941a62045da0b4d007bd3671e2e58da7b2a946de1cf81", "class_name": "RelatedNodeInfo"}}, "text": "[210426 Visformer](/rosinality/ml-papers/blob/main/papers/2021/210426%20Visformer.md)\n  19. [210427 ConTNet](/rosinality/ml-papers/blob/main/papers/2021/210427%20ConTNet.md)\n  20. [210428 Twins](/rosinality/ml-papers/blob/main/papers/2021/210428%20Twins.md) #local_attention #positional_encoding\n  21. [210509 Conformer](/rosinality/ml-papers/blob/main/papers/2021/210509%20Conformer.md)\n  22. [210515 Are Convolutional Neural Networks or Transformers more like human vision](/rosinality/ml-papers/blob/main/papers/2021/210515%20Are%20Convolutional%20Neural%20Networks%20or%20Transformers%20more%20like%20human%20vision.md) #cnn #inductive_bias\n  23. [210517 Rethinking the Design Principles of Robust Vision Transformer](/rosinality/ml-papers/blob/main/papers/2021/210517%20Rethinking%20the%20Design%20Principles%20of%20Robust%20Vision%20Transformer.md) #robustness\n\n## visual grounding\n\n  1. [210401 Towards General Purpose Vision Systems](/rosinality/ml-papers/blob/main/papers/2021/210401%20Towards%20General%20Purpose%20Vision%20Systems.md)\n  2. [210510 Visual Grounding with Transformers](/rosinality/ml-papers/blob/main/papers/2021/210510%20Visual%20Grounding%20with%20Transformers.md)\n\n## vit\n\n  1. [210521 Intriguing Properties of Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/210521%20Intriguing%20Properties%20of%20Vision%20Transformers.md) #robustness\n  2. [210526 Aggregating Nested Transformers](/rosinality/ml-papers/blob/main/papers/2021/210526%20Aggregating%20Nested%20Transformers.md) #local_attention\n  3. [210529 Less is More](/rosinality/ml-papers/blob/main/papers/2021/210529%20Less%20is%20More.md)\n  4. [210603 DynamicViT](/rosinality/ml-papers/blob/main/papers/2021/210603%20DynamicViT.md) #sparse_attention\n  5. [210603 When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations](/rosinality/ml-papers/blob/main/papers/2021/210603%20When%20Vision%20Transformers%20Outperform%20ResNets%20without%20Pretraining%20or%20Strong%20Data%20Augmentations.md) #regularization\n  6. [210604 RegionViT](/rosinality/ml-papers/blob/main/papers/2021/210604%20RegionViT.md) #local_attention\n  7. [210607 Refiner](/rosinality/ml-papers/blob/main/papers/2021/210607%20Refiner.md) #attention\n  8. [210607 Shuffle Transformer](/rosinality/ml-papers/blob/main/papers/2021/210607%20Shuffle%20Transformer.md)\n  9. [210608 Scaling Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/210608%20Scaling%20Vision%20Transformers.md) #scale\n  10. [210609 CoAtNet](/rosinality/ml-papers/blob/main/papers/2021/210609%20CoAtNet.md)\n  11. [210614 Delving Deep into the Generalization of Vision Transformers under Distribution Shifts](/rosinality/ml-papers/blob/main/papers/2021/210614%20Delving%20Deep%20into%20the%20Generalization%20of%20Vision%20Transformers%20under%20Distribution%20Shifts.md) #robustness\n  12.", "start_char_idx": 238029, "end_char_idx": 240899, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5749cac3-dcf1-4276-895d-be27cbcde49f": {"__data__": {"id_": "5749cac3-dcf1-4276-895d-be27cbcde49f", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b9aba0a4-89b5-45fc-b3b2-62dcfa26196e", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "85fb802d412b6c0b30f80fdbc13810f46468ddcc3e7a9dd417ddf3364f28e521", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "01708502-0de4-422b-b649-aab0c42b321f", "node_type": "1", "metadata": {}, "hash": "0e753db4d4fd6d831d191acc9ea7fbd1959c9e9210b2bfd95ccec88bd66c4a2e", "class_name": "RelatedNodeInfo"}}, "text": "[210607 Shuffle Transformer](/rosinality/ml-papers/blob/main/papers/2021/210607%20Shuffle%20Transformer.md)\n  9. [210608 Scaling Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/210608%20Scaling%20Vision%20Transformers.md) #scale\n  10. [210609 CoAtNet](/rosinality/ml-papers/blob/main/papers/2021/210609%20CoAtNet.md)\n  11. [210614 Delving Deep into the Generalization of Vision Transformers under Distribution Shifts](/rosinality/ml-papers/blob/main/papers/2021/210614%20Delving%20Deep%20into%20the%20Generalization%20of%20Vision%20Transformers%20under%20Distribution%20Shifts.md) #robustness\n  12. [210615 Revisiting the Calibration of Modern Neural Networks](/rosinality/ml-papers/blob/main/papers/2021/210615%20Revisiting%20the%20Calibration%20of%20Modern%20Neural%20Networks.md) #mlp #calibration\n  13. [210617 XCiT](/rosinality/ml-papers/blob/main/papers/2021/210617%20XCiT.md) #efficient_attention\n  14. [210624 Exploring Corruption Robustness](/rosinality/ml-papers/blob/main/papers/2021/210624%20Exploring%20Corruption%20Robustness.md) #robustness #mlp\n  15. [210624 VOLO](/rosinality/ml-papers/blob/main/papers/2021/210624%20VOLO.md) #efficient_attention\n  16. [210624 Video Swin Transformer](/rosinality/ml-papers/blob/main/papers/2021/210624%20Video%20Swin%20Transformer.md) #local_attention #video #video_transformer\n  17. [210701 CSWin Transformer](/rosinality/ml-papers/blob/main/papers/2021/210701%20CSWin%20Transformer.md) #efficient_attention #local_attention\n  18. [210701 Focal Self-attention for Local-Global Interactions in Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/210701%20Focal%20Self-attention%20for%20Local-Global%20Interactions%20in%20Vision%20Transformers.md) #local_attention\n  19. [210705 What Makes for Hierarchical Vision Transformer](/rosinality/ml-papers/blob/main/papers/2021/210705%20What%20Makes%20for%20Hierarchical%20Vision%20Transformer.md) #attention #mlp #local_attention\n  20. [210713 Visual Parser](/rosinality/ml-papers/blob/main/papers/2021/210713%20Visual%20Parser.md) #local_attention\n  21. [210731 CrossFormer](/rosinality/ml-papers/blob/main/papers/2021/210731%20CrossFormer.md)\n  22. [210811 ConvNets vs. Transformers](/rosinality/ml-papers/blob/main/papers/2021/210811%20ConvNets%20vs.%20Transformers.md) #robustness #transfer\n  23. [210819 Do Vision Transformers See Like Convolutional Neural Networks](/rosinality/ml-papers/blob/main/papers/2021/210819%20Do%20Vision%20Transformers%20See%20Like%20Convolutional%20Neural%20Networks.md) #resnet\n  24. [210908 Scaled ReLU Matters for Training Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/210908%20Scaled%20ReLU%20Matters%20for%20Training%20Vision%20Transformers.md) #cnn\n  25. [211118 Swin Transformer V2](/rosinality/ml-papers/blob/main/papers/2021/211118%20Swin%20Transformer%20V2.md)\n  26. [211202 Improved Multiscale Vision Transformers for Classification and Detection](/rosinality/ml-papers/blob/main/papers/2021/211202%20Improved%20Multiscale%20Vision%20Transformers%20for%20Classification%20and%20Detection.md)\n  27.", "start_char_idx": 240284, "end_char_idx": 243369, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "01708502-0de4-422b-b649-aab0c42b321f": {"__data__": {"id_": "01708502-0de4-422b-b649-aab0c42b321f", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5749cac3-dcf1-4276-895d-be27cbcde49f", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "5e598cfeee5d71eba059ba75fd84be908f1db6349d53a93327c8cbeca81e7732", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "39e07a45-8390-477e-aca8-58c7b41415b4", "node_type": "1", "metadata": {}, "hash": "4948b4a6d25b272041d201aeba02f9a04aa564b139d2bb6366ba0009d6e781f2", "class_name": "RelatedNodeInfo"}}, "text": "[210908 Scaled ReLU Matters for Training Vision Transformers](/rosinality/ml-papers/blob/main/papers/2021/210908%20Scaled%20ReLU%20Matters%20for%20Training%20Vision%20Transformers.md) #cnn\n  25. [211118 Swin Transformer V2](/rosinality/ml-papers/blob/main/papers/2021/211118%20Swin%20Transformer%20V2.md)\n  26. [211202 Improved Multiscale Vision Transformers for Classification and Detection](/rosinality/ml-papers/blob/main/papers/2021/211202%20Improved%20Multiscale%20Vision%20Transformers%20for%20Classification%20and%20Detection.md)\n  27. [211210 Deep ViT Features as Dense Visual Descriptors](/rosinality/ml-papers/blob/main/papers/2021/211210%20Deep%20ViT%20Features%20as%20Dense%20Visual%20Descriptors.md) #self_supervised #semantic_segmentation\n  28. [211217 A Simple Single-Scale Vision Transformer for Object Localization and Instance Segmentation](/rosinality/ml-papers/blob/main/papers/2021/211217%20A%20Simple%20Single-Scale%20Vision%20Transformer%20for%20Object%20Localization%20and%20Instance%20Segmentation.md) #multiscale\n  29. [220214 How Do Vision Transformers Work](/rosinality/ml-papers/blob/main/papers/2022/220214%20How%20Do%20Vision%20Transformers%20Work.md) #cnn\n  30. [220414 DeiT III](/rosinality/ml-papers/blob/main/papers/2022/220414%20DeiT%20III.md)\n  31. [220722 An Impartial Take to the CNN vs Transformer Robustness Contest](/rosinality/ml-papers/blob/main/papers/2022/220722%20An%20Impartial%20Take%20to%20the%20CNN%20vs%20Transformer%20Robustness%20Contest.md) #robustness #cnn\n  32. [220812 BEiT v2](/rosinality/ml-papers/blob/main/papers/2022/220812%20BEiT%20v2.md) #self_supervised #mlm\n  33. [221110 Demystify Transformers & Convolutions in Modern Image Deep Networks](/rosinality/ml-papers/blob/main/papers/2022/221110%20Demystify%20Transformers%20%26%20Convolutions%20in%20Modern%20Image%20Deep%20Networks.md) #cnn\n  34. [230202 Dual PatchNorm](/rosinality/ml-papers/blob/main/papers/2023/230202%20Dual%20PatchNorm.md) #normalization\n  35. [230712 Patch n' Pack](/rosinality/ml-papers/blob/main/papers/2023/230712%20Patch%20n%27%20Pack.md)\n\n## vocoder\n\n  1. [200512 FeatherWave](/rosinality/ml-papers/blob/main/papers/2020/200512%20FeatherWave.md)\n  2. [201118 Universal MelGAN](/rosinality/ml-papers/blob/main/papers/2020/201118%20Universal%20MelGAN.md)\n\n## vq\n\n  1. [230311 Regularized Vector Quantization for Tokenized Image Synthesis](/rosinality/ml-papers/blob/main/papers/2023/230311%20Regularized%20Vector%20Quantization%20for%20Tokenized%20Image%20Synthesis.md)\n\n## vqa\n\n  1. [220914 MUST-VQA](/rosinality/ml-papers/blob/main/papers/2022/220914%20MUST-VQA.md)\n\n## weak supervision\n\n  1. [201126 SelfText Beyond Polygon](/rosinality/ml-papers/blob/main/papers/2020/201126%20SelfText%20Beyond%20Polygon.md) #ocr\n\n## yolo\n\n  1. [230113 YOLOv6 v3.0](/rosinality/ml-papers/blob/main/papers/2023/230113%20YOLOv6%20v3.0.md)\n\n## uncategorized\n\n  1.", "start_char_idx": 242827, "end_char_idx": 245716, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "39e07a45-8390-477e-aca8-58c7b41415b4": {"__data__": {"id_": "39e07a45-8390-477e-aca8-58c7b41415b4", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "01708502-0de4-422b-b649-aab0c42b321f", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "4c71c1b08f852973cc7dd1f977ed61bd5f726bbb2573c0bb8ccc85ee78194e4f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4b2e1dd2-e66c-4e6a-a4ec-ed43823045eb", "node_type": "1", "metadata": {}, "hash": "1b1b5f2a1969ac9f5e6ae9303af3b647e1f380b0efb6a87f1bc903a6eaadcc1a", "class_name": "RelatedNodeInfo"}}, "text": "[220914 MUST-VQA](/rosinality/ml-papers/blob/main/papers/2022/220914%20MUST-VQA.md)\n\n## weak supervision\n\n  1. [201126 SelfText Beyond Polygon](/rosinality/ml-papers/blob/main/papers/2020/201126%20SelfText%20Beyond%20Polygon.md) #ocr\n\n## yolo\n\n  1. [230113 YOLOv6 v3.0](/rosinality/ml-papers/blob/main/papers/2023/230113%20YOLOv6%20v3.0.md)\n\n## uncategorized\n\n  1. [09](/rosinality/ml-papers/blob/main/papers/2016/09.md)\n  2. [200211 fastai](/rosinality/ml-papers/blob/main/papers/2020/200211%20fastai.md)\n  3. [210224 Zero-Shot Text-to-Image Generation](/rosinality/ml-papers/blob/main/papers/2021/210224%20Zero-Shot%20Text-to-Image%20Generation.md)\n  4. [210603 The Case for Translation-Invariant Self-Attention in Transformer-Based Language Models](/rosinality/ml-papers/blob/main/papers/2021/210603%20The%20Case%20for%20Translation-Invariant%20Self-Attention%20in%20Transformer-Based%20Language%20Models.md)\n  5. [210606 Referring Transformer](/rosinality/ml-papers/blob/main/papers/2021/210606%20Referring%20Transformer.md)\n  6. [210607 ViTAE](/rosinality/ml-papers/blob/main/papers/2021/210607%20ViTAE.md)\n  7. [210614 Non Gaussian Denoising Diffusion Models](/rosinality/ml-papers/blob/main/papers/2021/210614%20Non%20Gaussian%20Denoising%20Diffusion%20Models.md)\n  8. [210909 PIMNet](/rosinality/ml-papers/blob/main/papers/2021/210909%20PIMNet.md)\n  9. [211026 Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers](/rosinality/ml-papers/blob/main/papers/2021/211026%20Combining%20Recurrent%2C%20Convolutional%2C%20and%20Continuous-time%20Models%20with%20Linear%20State-Space%20Layers.md)\n  10. [211028 Colossal-AI](/rosinality/ml-papers/blob/main/papers/2021/211028%20Colossal-AI.md)\n  11. [211215 Value Retrieval with Arbitrary Queries for Form-like Documents](/rosinality/ml-papers/blob/main/papers/2021/211215%20Value%20Retrieval%20with%20Arbitrary%20Queries%20for%20Form-like%20Documents.md)\n  12. [221125 Solving math word problems with process- and outcome-based feedback](/rosinality/ml-papers/blob/main/papers/2021/221125%20Solving%20math%20word%20problems%20with%20process-%20and%20outcome-based%20feedback.md)\n  13. [221204 Languages You Know Influence Those You Learn](/rosinality/ml-papers/blob/main/papers/2021/221204%20Languages%20You%20Know%20Influence%20Those%20You%20Learn.md)\n  14. [221215 Constitutional AI](/rosinality/ml-papers/blob/main/papers/2021/221215%20Constitutional%20AI.md)\n  15. [220114 DeepSpeed-MoE](/rosinality/ml-papers/blob/main/papers/2022/220114%20DeepSpeed-MoE.md)\n  16. [220203 AlphaCode, Formal Math](/rosinality/ml-papers/blob/main/papers/2022/220203%20AlphaCode%2C%20Formal%20Math.md)\n  17. [220204 InstructGPT](/rosinality/ml-papers/blob/main/papers/2022/220204%20InstructGPT.md)\n  18. [220316 Memorizing Transformers](/rosinality/ml-papers/blob/main/papers/2022/220316%20Memorizing%20Transformers.md)\n  19.", "start_char_idx": 245352, "end_char_idx": 248252, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4b2e1dd2-e66c-4e6a-a4ec-ed43823045eb": {"__data__": {"id_": "4b2e1dd2-e66c-4e6a-a4ec-ed43823045eb", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "39e07a45-8390-477e-aca8-58c7b41415b4", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "07c6a2babe366ee88bd9a6252927471d72035e98d46cd8d21aac593cacde233e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42a89060-e97c-493f-a919-89b378104baa", "node_type": "1", "metadata": {}, "hash": "a63caf0791ee938296dd5f4abaa1d325841baab029278d02a7f50683078c4048", "class_name": "RelatedNodeInfo"}}, "text": "[221215 Constitutional AI](/rosinality/ml-papers/blob/main/papers/2021/221215%20Constitutional%20AI.md)\n  15. [220114 DeepSpeed-MoE](/rosinality/ml-papers/blob/main/papers/2022/220114%20DeepSpeed-MoE.md)\n  16. [220203 AlphaCode, Formal Math](/rosinality/ml-papers/blob/main/papers/2022/220203%20AlphaCode%2C%20Formal%20Math.md)\n  17. [220204 InstructGPT](/rosinality/ml-papers/blob/main/papers/2022/220204%20InstructGPT.md)\n  18. [220316 Memorizing Transformers](/rosinality/ml-papers/blob/main/papers/2022/220316%20Memorizing%20Transformers.md)\n  19. [220323 Pathways](/rosinality/ml-papers/blob/main/papers/2022/220323%20Pathways.md)\n  20. [220329 Few Could Be Better Than All](/rosinality/ml-papers/blob/main/papers/2022/220329%20Few%20Could%20Be%20Better%20Than%20All.md)\n  21. [220405 Text Spotting Transformers](/rosinality/ml-papers/blob/main/papers/2022/220405%20Text%20Spotting%20Transformers.md)\n  22. [220416 Benchmarking Generalization via In-Context Instructions on 1,600+ Language Tasks](/rosinality/ml-papers/blob/main/papers/2022/220416%20Benchmarking%20Generalization%20via%20In-Context%20Instructions%20on%201%2C600%2B%20Language%20Tasks.md)\n  23. [220510 UL2](/rosinality/ml-papers/blob/main/papers/2022/220510%20UL2.md)\n  24. [220610 A Multi-Task Benchmark for Korean Legal Language Understanding and Judgement Prediction](/rosinality/ml-papers/blob/main/papers/2022/220610%20A%20Multi-Task%20Benchmark%20for%20Korean%20Legal%20Language%20Understanding%20and%20Judgement%20Prediction.md)\n  25. [220612 Self-critiquing models for assisting human evaluators](/rosinality/ml-papers/blob/main/papers/2022/220612%20Self-critiquing%20models%20for%20assisting%20human%20evaluators.md)\n  26. [220614 RDU](/rosinality/ml-papers/blob/main/papers/2022/220614%20RDU.md)\n  27. [220630 DeepSpeed Inference](/rosinality/ml-papers/blob/main/papers/2022/220630%20DeepSpeed%20Inference.md)\n  28. [220712 Inner Monologue](/rosinality/ml-papers/blob/main/papers/2022/220712%20Inner%20Monologue.md)\n  29. [220720 NUWA-Infinity](/rosinality/ml-papers/blob/main/papers/2022/220720%20NUWA-Infinity.md)\n  30. [220722 Multiface](/rosinality/ml-papers/blob/main/papers/2022/220722%20Multiface.md)\n  31. [220725 CelebV-HQ](/rosinality/ml-papers/blob/main/papers/2022/220725%20CelebV-HQ.md)\n  32. [220725 Neural Generation Meets Real People](/rosinality/ml-papers/blob/main/papers/2022/220725%20Neural%20Generation%20Meets%20Real%20People.md)\n  33. [220725 Towards Complex Document Understanding By Discrete Reasoning](/rosinality/ml-papers/blob/main/papers/2022/220725%20Towards%20Complex%20Document%20Understanding%20By%20Discrete%20Reasoning.md)\n  34. [220819 FP8 Quantization](/rosinality/ml-papers/blob/main/papers/2022/220819%20FP8%20Quantization.md)\n  35. [220823 CLOWER](/rosinality/ml-papers/blob/main/papers/2022/220823%20CLOWER.md)\n  36.", "start_char_idx": 247701, "end_char_idx": 250540, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "42a89060-e97c-493f-a919-89b378104baa": {"__data__": {"id_": "42a89060-e97c-493f-a919-89b378104baa", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b2e1dd2-e66c-4e6a-a4ec-ed43823045eb", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "ccdc41efc12b9f9841bb9a9e5f186c756ae016570f54911541c79cb6ec159872", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "940dc357-2574-4c07-af28-8b76e704d6ea", "node_type": "1", "metadata": {}, "hash": "bd17050f03f10ebffeec02955a9958802a6c0af861b067b63bce0700dced8869", "class_name": "RelatedNodeInfo"}}, "text": "[220725 Neural Generation Meets Real People](/rosinality/ml-papers/blob/main/papers/2022/220725%20Neural%20Generation%20Meets%20Real%20People.md)\n  33. [220725 Towards Complex Document Understanding By Discrete Reasoning](/rosinality/ml-papers/blob/main/papers/2022/220725%20Towards%20Complex%20Document%20Understanding%20By%20Discrete%20Reasoning.md)\n  34. [220819 FP8 Quantization](/rosinality/ml-papers/blob/main/papers/2022/220819%20FP8%20Quantization.md)\n  35. [220823 CLOWER](/rosinality/ml-papers/blob/main/papers/2022/220823%20CLOWER.md)\n  36. [220912 FP8 Formats for Deep Learning](/rosinality/ml-papers/blob/main/papers/2022/220912%20FP8%20Formats%20for%20Deep%20Learning.md)\n  37. [220923 Diffusion](/rosinality/ml-papers/blob/main/papers/2022/220923%20Diffusion.md)\n  38. [220928 Improving alignment of dialogue agents via targeted human judgements](/rosinality/ml-papers/blob/main/papers/2022/220928%20Improving%20alignment%20of%20dialogue%20agents%20via%20targeted%20human%20judgements.md)\n  39. [220928 The Change You Want to See](/rosinality/ml-papers/blob/main/papers/2022/220928%20The%20Change%20You%20Want%20to%20See.md)\n  40. [221219 MatCha](/rosinality/ml-papers/blob/main/papers/2022/221219%20MatCha.md)\n  41. [230203 Measuring The Impact Of Programming Language Distribution](/rosinality/ml-papers/blob/main/papers/2023/230203%20Measuring%20The%20Impact%20Of%20Programming%20Language%20Distribution.md)\n  42. [230206 SmoothQuant](/rosinality/ml-papers/blob/main/papers/2023/230206%20SmoothQuant.md)\n  43. [230207 Efficiently Upgrading Multilingual Machine Translation Models to Support More Languages](/rosinality/ml-papers/blob/main/papers/2023/230207%20Efficiently%20Upgrading%20Multilingual%20Machine%20Translation%20Models%20to%20Support%20More%20Languages.md)\n  44. [230207 FP8](/rosinality/ml-papers/blob/main/papers/2023/230207%20FP8.md)\n  45. [230208 Google Configuration System](/rosinality/ml-papers/blob/main/papers/2023/230208%20Google%20Configuration%20System.md)\n  46. [230209 Efficient Attention via Control Variates](/rosinality/ml-papers/blob/main/papers/2023/230209%20Efficient%20Attention%20via%20Control%20Variates.md)\n  47. [230211 Generative AI\uc5d0 \ub300\ud55c \uc0dd\uac01](/rosinality/ml-papers/blob/main/papers/2023/230211%20Generative%20AI%EC%97%90%20%EB%8C%80%ED%95%9C%20%EC%83%9D%EA%B0%81.md)\n  48. [230213 Lossy Compression](/rosinality/ml-papers/blob/main/papers/2023/230213%20Lossy%20Compression.md)\n  49. [230214 Adding Instructions during Pretraining](/rosinality/ml-papers/blob/main/papers/2023/230214%20Adding%20Instructions%20during%20Pretraining.md)\n  50. [230214 Score-based Diffusion Models in Function Space](/rosinality/ml-papers/blob/main/papers/2023/230214%20Score-based%20Diffusion%20Models%20in%20Function%20Space.md)\n  51. [230216 Aligning Language Models with Preferences through f-divergence Minimization](/rosinality/ml-papers/blob/main/papers/2023/230216%20Aligning%20Language%20Models%20with%20Preferences%20through%20f-divergence%20Minimization.md)\n  52.", "start_char_idx": 249989, "end_char_idx": 252996, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "940dc357-2574-4c07-af28-8b76e704d6ea": {"__data__": {"id_": "940dc357-2574-4c07-af28-8b76e704d6ea", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42a89060-e97c-493f-a919-89b378104baa", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "5e11a406a154fb132cc141d979f1cd530e10b23fd576a71f2737a464aed38e36", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "561f6ebf-71de-4e6e-88af-09da27c698e0", "node_type": "1", "metadata": {}, "hash": "5f20ee60506458877142652f5b241308c4590431c33a848bc71f21a3858726ed", "class_name": "RelatedNodeInfo"}}, "text": "[230214 Adding Instructions during Pretraining](/rosinality/ml-papers/blob/main/papers/2023/230214%20Adding%20Instructions%20during%20Pretraining.md)\n  50. [230214 Score-based Diffusion Models in Function Space](/rosinality/ml-papers/blob/main/papers/2023/230214%20Score-based%20Diffusion%20Models%20in%20Function%20Space.md)\n  51. [230216 Aligning Language Models with Preferences through f-divergence Minimization](/rosinality/ml-papers/blob/main/papers/2023/230216%20Aligning%20Language%20Models%20with%20Preferences%20through%20f-divergence%20Minimization.md)\n  52. [230220 DSP](/rosinality/ml-papers/blob/main/papers/2023/230220%20DSP.md)\n  53. [230221 Anthropic](/rosinality/ml-papers/blob/main/papers/2023/230221%20Anthropic.md)\n  54. [230222 AlpaServe](/rosinality/ml-papers/blob/main/papers/2023/230222%20AlpaServe.md)\n  55. [230222 FlexGen](/rosinality/ml-papers/blob/main/papers/2023/230222%20FlexGen.md)\n  56. [230223 Colossal AI ChatGPT](/rosinality/ml-papers/blob/main/papers/2023/230223%20Colossal%20AI%20ChatGPT.md)\n  57. [230223 On the Generalization Ability of Retrieval-Enhanced Transformers](/rosinality/ml-papers/blob/main/papers/2023/230223%20On%20the%20Generalization%20Ability%20of%20Retrieval-Enhanced%20Transformers.md)\n  58. [230224 World Models](/rosinality/ml-papers/blob/main/papers/2023/230224%20World%20Models.md)\n  59. [230228 SHP](/rosinality/ml-papers/blob/main/papers/2023/230228%20SHP.md)\n  60. [230306](/rosinality/ml-papers/blob/main/papers/2023/230306.md)\n  61. [230311 Resurrecting Recurrent Neural Networks for Long Sequences](/rosinality/ml-papers/blob/main/papers/2023/230311%20Resurrecting%20Recurrent%20Neural%20Networks%20for%20Long%20Sequences.md)\n  62. [230312 ChatGPT Asks, BLIP-2 Answers](/rosinality/ml-papers/blob/main/papers/2023/230312%20ChatGPT%20Asks%2C%20BLIP-2%20Answers.md)\n  63. [230314 ViperGPT](/rosinality/ml-papers/blob/main/papers/2023/230314%20ViperGPT.md)\n  64. [230315 GPT-4](/rosinality/ml-papers/blob/main/papers/2023/230315%20GPT-4.md)\n  65. [230320 Reflexion](/rosinality/ml-papers/blob/main/papers/2023/230320%20Reflexion.md)\n  66. [230323 The Quantization Model of Neural Scaling](/rosinality/ml-papers/blob/main/papers/2023/230323%20The%20Quantization%20Model%20of%20Neural%20Scaling.md)\n  67. [230327 EVA-CLIP](/rosinality/ml-papers/blob/main/papers/2023/230327%20EVA-CLIP.md)\n  68. [230327 unarXive 2022](/rosinality/ml-papers/blob/main/papers/2023/230327%20unarXive%202022.md)\n  69. [230328 Improving Code Generation by Training with Natural Language Feedback](/rosinality/ml-papers/blob/main/papers/2023/230328%20Improving%20Code%20Generation%20by%20Training%20with%20Natural%20Language%20Feedback.md)\n  70. [230331 Autoregressive Model](/rosinality/ml-papers/blob/main/papers/2023/230331%20Autoregressive%20Model.md)\n  71.", "start_char_idx": 252427, "end_char_idx": 255230, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "561f6ebf-71de-4e6e-88af-09da27c698e0": {"__data__": {"id_": "561f6ebf-71de-4e6e-88af-09da27c698e0", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "940dc357-2574-4c07-af28-8b76e704d6ea", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "f193ceaf46cb9319d96452e13b326f7c53fd678144e11e0e243ad9711fb8170d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4c704a28-9bf2-48b4-8e0d-77ac3e48010e", "node_type": "1", "metadata": {}, "hash": "7af0116c4f22600c87bbdfbd5d38264d4f96085f07f0ef1a6a6c0e51ddaba36e", "class_name": "RelatedNodeInfo"}}, "text": "[230327 EVA-CLIP](/rosinality/ml-papers/blob/main/papers/2023/230327%20EVA-CLIP.md)\n  68. [230327 unarXive 2022](/rosinality/ml-papers/blob/main/papers/2023/230327%20unarXive%202022.md)\n  69. [230328 Improving Code Generation by Training with Natural Language Feedback](/rosinality/ml-papers/blob/main/papers/2023/230328%20Improving%20Code%20Generation%20by%20Training%20with%20Natural%20Language%20Feedback.md)\n  70. [230331 Autoregressive Model](/rosinality/ml-papers/blob/main/papers/2023/230331%20Autoregressive%20Model.md)\n  71. [230331 Choose Your Weapon](/rosinality/ml-papers/blob/main/papers/2023/230331%20Choose%20Your%20Weapon.md)\n  72. [230406 Quantization](/rosinality/ml-papers/blob/main/papers/2023/230406%20Quantization.md)\n  73. [230407 RLHF](/rosinality/ml-papers/blob/main/papers/2023/230407%20RLHF.md)\n  74. [230414 OpenAssistant Conversations -- Democratizing Large Language Model Alignment](/rosinality/ml-papers/blob/main/papers/2023/230414%20OpenAssistant%20Conversations%20--%20Democratizing%20Large%20Language%20Model%20Alignment.md)\n  75. [230416 Open Assistant](/rosinality/ml-papers/blob/main/papers/2023/230416%20Open%20Assistant.md)\n  76. [230417 Tool Learning with Foundation Models](/rosinality/ml-papers/blob/main/papers/2023/230417%20Tool%20Learning%20with%20Foundation%20Models.md)\n  77. [230418 HCI](/rosinality/ml-papers/blob/main/papers/2023/230418%20HCI.md)\n  78. [230420 Stable LM](/rosinality/ml-papers/blob/main/papers/2023/230420%20Stable%20LM.md)\n  79. [230428 Are Emergent Abilities of Large Language Models a Mirage](/rosinality/ml-papers/blob/main/papers/2023/230428%20Are%20Emergent%20Abilities%20of%20Large%20Language%20Models%20a%20Mirage.md)\n  80. [230502 RedPajama](/rosinality/ml-papers/blob/main/papers/2023/230502%20RedPajama.md)\n  81. [230504 ZipIt! Merging Models from Different Tasks without Training](/rosinality/ml-papers/blob/main/papers/2023/230504%20ZipIt%21%20Merging%20Models%20from%20Different%20Tasks%20without%20Training.md)\n  82. [230511 An Inverse Scaling Law for CLIP Training](/rosinality/ml-papers/blob/main/papers/2023/230511%20An%20Inverse%20Scaling%20Law%20for%20CLIP%20Training.md)\n  83. [230511 InstructBLIP](/rosinality/ml-papers/blob/main/papers/2023/230511%20InstructBLIP.md)\n  84. [230511 Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers](/rosinality/ml-papers/blob/main/papers/2023/230511%20Region-Aware%20Pretraining%20for%20Open-Vocabulary%20Object%20Detection%20with%20Vision%20Transformers.md)\n  85. [230511 Simple Token-Level Confidence Improves Caption Correctness](/rosinality/ml-papers/blob/main/papers/2023/230511%20Simple%20Token-Level%20Confidence%20Improves%20Caption%20Correctness.md)\n  86. [230516 SpecInfer](/rosinality/ml-papers/blob/main/papers/2023/230516%20SpecInfer.md)\n  87.", "start_char_idx": 254697, "end_char_idx": 257514, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4c704a28-9bf2-48b4-8e0d-77ac3e48010e": {"__data__": {"id_": "4c704a28-9bf2-48b4-8e0d-77ac3e48010e", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "561f6ebf-71de-4e6e-88af-09da27c698e0", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "317ff5653bfc0bd170de7bb0165165b187b07c6d04e6fe5ef2a378afd17ea390", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ac67d285-ba98-4f0d-b1f5-99b4ac3c5ffc", "node_type": "1", "metadata": {}, "hash": "6ad415c05d6069a186849d3a09d4624f9c52335fe236cec9ba71acde8dc0c958", "class_name": "RelatedNodeInfo"}}, "text": "[230511 Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers](/rosinality/ml-papers/blob/main/papers/2023/230511%20Region-Aware%20Pretraining%20for%20Open-Vocabulary%20Object%20Detection%20with%20Vision%20Transformers.md)\n  85. [230511 Simple Token-Level Confidence Improves Caption Correctness](/rosinality/ml-papers/blob/main/papers/2023/230511%20Simple%20Token-Level%20Confidence%20Improves%20Caption%20Correctness.md)\n  86. [230516 SpecInfer](/rosinality/ml-papers/blob/main/papers/2023/230516%20SpecInfer.md)\n  87. [230518 Evidence of Meaning in Language Models Trained on Programs](/rosinality/ml-papers/blob/main/papers/2023/230518%20Evidence%20of%20Meaning%20in%20Language%20Models%20Trained%20on%20Programs.md)\n  88. [230518 \uad6c\uae00 \ub2ec\ub9ac\uae30](/rosinality/ml-papers/blob/main/papers/2023/230518%20%EA%B5%AC%EA%B8%80%20%EB%8B%AC%EB%A6%AC%EA%B8%B0.md)\n  89. [230522 Training Diffusion Models with Reinforcement Learning](/rosinality/ml-papers/blob/main/papers/2023/230522%20Training%20Diffusion%20Models%20with%20Reinforcement%20Learning.md)\n  90. [230523 ZeroSCROLLS](/rosinality/ml-papers/blob/main/papers/2023/230523%20ZeroSCROLLS.md)\n  91. [230524 Model evaluation for extreme risks](/rosinality/ml-papers/blob/main/papers/2023/230524%20Model%20evaluation%20for%20extreme%20risks.md)\n  92. [230525 The False Promise of Imitating Proprietary LLMs](/rosinality/ml-papers/blob/main/papers/2023/230525%20The%20False%20Promise%20of%20Imitating%20Proprietary%20LLMs.md)\n  93. [230527 Fine-Tuning Language Models with Just Forward Passes](/rosinality/ml-papers/blob/main/papers/2023/230527%20Fine-Tuning%20Language%20Models%20with%20Just%20Forward%20Passes.md)\n  94. [230531 Let's Verify Step by Step](/rosinality/ml-papers/blob/main/papers/2023/230531%20Let%27s%20Verify%20Step%20by%20Step.md)\n  95. [230601 Hiera](/rosinality/ml-papers/blob/main/papers/2023/230601%20Hiera.md)\n  96. [230601 SnapFusion](/rosinality/ml-papers/blob/main/papers/2023/230601%20SnapFusion.md)\n  97. [230602 Fine-Grained Human Feedback Gives Better Rewards for Language Model Training](/rosinality/ml-papers/blob/main/papers/2023/230602%20Fine-Grained%20Human%20Feedback%20Gives%20Better%20Rewards%20for%20Language%20Model%20Training.md)\n  98. [230608 SequenceMatch](/rosinality/ml-papers/blob/main/papers/2023/230608%20SequenceMatch.md)\n  99. [230611 LAMM](/rosinality/ml-papers/blob/main/papers/2023/230611%20LAMM.md)\n  100. [230616 Scaling Open-Vocabulary Object Detection](/rosinality/ml-papers/blob/main/papers/2023/230616%20Scaling%20Open-Vocabulary%20Object%20Detection.md)\n  101. [230616 ZeRO++](/rosinality/ml-papers/blob/main/papers/2023/230616%20ZeRO%2B%2B.md)\n  102. [230619 RepoFusion](/rosinality/ml-papers/blob/main/papers/2023/230619%20RepoFusion.md)\n  103. [230621 Constant Memory Attention Block](/rosinality/ml-papers/blob/main/papers/2023/230621%20Constant%20Memory%20Attention%20Block.md)\n  104.", "start_char_idx": 256961, "end_char_idx": 259883, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ac67d285-ba98-4f0d-b1f5-99b4ac3c5ffc": {"__data__": {"id_": "ac67d285-ba98-4f0d-b1f5-99b4ac3c5ffc", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4c704a28-9bf2-48b4-8e0d-77ac3e48010e", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "21986d8894f31afb9865894e6697bec21786e907708c47a1642514005e49f6c3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "09d64c6e-651d-4432-b7d4-cd15b9c1be4e", "node_type": "1", "metadata": {}, "hash": "e375129a3f66e6873d5c37022a497ac9cbeaf292274d19ce6e4365bcede95395", "class_name": "RelatedNodeInfo"}}, "text": "[230611 LAMM](/rosinality/ml-papers/blob/main/papers/2023/230611%20LAMM.md)\n  100. [230616 Scaling Open-Vocabulary Object Detection](/rosinality/ml-papers/blob/main/papers/2023/230616%20Scaling%20Open-Vocabulary%20Object%20Detection.md)\n  101. [230616 ZeRO++](/rosinality/ml-papers/blob/main/papers/2023/230616%20ZeRO%2B%2B.md)\n  102. [230619 RepoFusion](/rosinality/ml-papers/blob/main/papers/2023/230619%20RepoFusion.md)\n  103. [230621 Constant Memory Attention Block](/rosinality/ml-papers/blob/main/papers/2023/230621%20Constant%20Memory%20Attention%20Block.md)\n  104. [230621 Limits for Learning with Language Models](/rosinality/ml-papers/blob/main/papers/2023/230621%20Limits%20for%20Learning%20with%20Language%20Models.md)\n  105. [230626 Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression](/rosinality/ml-papers/blob/main/papers/2023/230626%20Pretraining%20task%20diversity%20and%20the%20emergence%20of%20non-Bayesian%20in-context%20learning%20for%20regression.md)\n  106. [230626 Understanding In-Context Learning via Supportive Pretraining Data](/rosinality/ml-papers/blob/main/papers/2023/230626%20Understanding%20In-Context%20Learning%20via%20Supportive%20Pretraining%20Data.md)\n  107. [230627 IDOL](/rosinality/ml-papers/blob/main/papers/2023/230627%20IDOL.md)\n  108. [230629 An Efficient General-Purpose Modular Vision Model via Multi-Task Heterogeneous Training](/rosinality/ml-papers/blob/main/papers/2023/230629%20An%20Efficient%20General-Purpose%20Modular%20Vision%20Model%20via%20Multi-Task%20Heterogeneous%20Training.md)\n  109. [230629 Generate Anything Anywhere in Any Scene](/rosinality/ml-papers/blob/main/papers/2023/230629%20Generate%20Anything%20Anywhere%20in%20Any%20Scene.md)\n  110. [230629 Generative AI for Programming Education](/rosinality/ml-papers/blob/main/papers/2023/230629%20Generative%20AI%20for%20Programming%20Education.md)\n  111. [230629 LLaVAR](/rosinality/ml-papers/blob/main/papers/2023/230629%20LLaVAR.md)\n  112. [230701 Let Me Teach You](/rosinality/ml-papers/blob/main/papers/2023/230701%20Let%20Me%20Teach%20You.md)\n  113. [230701 NTK Aware Scaled RoPE](/rosinality/ml-papers/blob/main/papers/2023/230701%20NTK%20Aware%20Scaled%20RoPE.md)\n  114. [230706 Superalignment](/rosinality/ml-papers/blob/main/papers/2023/230706%20Superalignment.md)\n  115. [230706 Training Models to Generate, Recognize, and Reframe Unhelpful Thoughts](/rosinality/ml-papers/blob/main/papers/2023/230706%20Training%20Models%20to%20Generate%2C%20Recognize%2C%20and%20Reframe%20Unhelpful%20Thoughts.md)\n  116. [230708 DDPO](/rosinality/ml-papers/blob/main/papers/2023/230708%20DDPO.md)\n  117. [230710 About Anthropic](/rosinality/ml-papers/blob/main/papers/2023/230710%20About%20Anthropic.md)\n  118. [230710 BeaverTails](/rosinality/ml-papers/blob/main/papers/2023/230710%20BeaverTails.md)\n  119. [230710 FreeDrag](/rosinality/ml-papers/blob/main/papers/2023/230710%20FreeDrag.md)\n  120.", "start_char_idx": 259311, "end_char_idx": 262265, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "09d64c6e-651d-4432-b7d4-cd15b9c1be4e": {"__data__": {"id_": "09d64c6e-651d-4432-b7d4-cd15b9c1be4e", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ac67d285-ba98-4f0d-b1f5-99b4ac3c5ffc", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "b38e6ad61ac6da0b703bd8a2437b0438d9347c94f8bd680b54396b172cd14a25", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c08e4b23-5352-40a4-a09b-259c53440965", "node_type": "1", "metadata": {}, "hash": "2f9cdcc200a7cedf17c09cec9588229141e8f10748460e8e525587bd0b9c3dee", "class_name": "RelatedNodeInfo"}}, "text": "[230708 DDPO](/rosinality/ml-papers/blob/main/papers/2023/230708%20DDPO.md)\n  117. [230710 About Anthropic](/rosinality/ml-papers/blob/main/papers/2023/230710%20About%20Anthropic.md)\n  118. [230710 BeaverTails](/rosinality/ml-papers/blob/main/papers/2023/230710%20BeaverTails.md)\n  119. [230710 FreeDrag](/rosinality/ml-papers/blob/main/papers/2023/230710%20FreeDrag.md)\n  120. [230710 Large Language Models as General Pattern Machines](/rosinality/ml-papers/blob/main/papers/2023/230710%20Large%20Language%20Models%20as%20General%20Pattern%20Machines.md)\n  121. [230710 VampNet](/rosinality/ml-papers/blob/main/papers/2023/230710%20VampNet.md)\n  122. [230711 GPT-4 FLOPS](/rosinality/ml-papers/blob/main/papers/2023/230711%20GPT-4%20FLOPS.md)\n  123. [230711 Objaverse-XL](/rosinality/ml-papers/blob/main/papers/2023/230711%20Objaverse-XL.md)\n  124. [230711 Self-consistency for open-ended generations](/rosinality/ml-papers/blob/main/papers/2023/230711%20Self-consistency%20for%20open-ended%20generations.md)\n  125. [230712 Claude 2](/rosinality/ml-papers/blob/main/papers/2023/230712%20Claude%202.md)\n  126. [230712 Instruction Mining](/rosinality/ml-papers/blob/main/papers/2023/230712%20Instruction%20Mining.md)\n  127. [230713 Hassabis](/rosinality/ml-papers/blob/main/papers/2023/230713%20Hassabis.md)\n  128. [230714 Code Interpreter](/rosinality/ml-papers/blob/main/papers/2023/230714%20Code%20Interpreter.md)\n  129. [230718 Flash Attention 2](/rosinality/ml-papers/blob/main/papers/2023/230718%20Flash%20Attention%202.md)\n  130. [230718 How is ChatGPT's behavior changing over time](/rosinality/ml-papers/blob/main/papers/2023/230718%20How%20is%20ChatGPT%27s%20behavior%20changing%20over%20time.md)\n  131. [230719 Llama 2](/rosinality/ml-papers/blob/main/papers/2023/230719%20Llama%202.md)\n  132. [230724 RLCD](/rosinality/ml-papers/blob/main/papers/2023/230724%20RLCD.md)\n  133. [230725 Retentive Network](/rosinality/ml-papers/blob/main/papers/2023/230725%20Retentive%20Network.md)\n  134. [230728 Exploring Format Consistency for Instruction Tuning](/rosinality/ml-papers/blob/main/papers/2023/230728%20Exploring%20Format%20Consistency%20for%20Instruction%20Tuning.md)\n  135. [230728 The Hydra Effect](/rosinality/ml-papers/blob/main/papers/2023/230728%20The%20Hydra%20Effect.md)\n  136. [230729 Configuration System](/rosinality/ml-papers/blob/main/papers/2023/230729%20Configuration%20System.md)\n  137. [230803 H100 Supply and Demand](/rosinality/ml-papers/blob/main/papers/2023/230803%20H100%20Supply%20and%20Demand.md)\n  138. [230803 Multimodal Neurons in Pretrained Text-Only Transformers](/rosinality/ml-papers/blob/main/papers/2023/230803%20Multimodal%20Neurons%20in%20Pretrained%20Text-Only%20Transformers.md)\n  139. [230804 Retroformer](/rosinality/ml-papers/blob/main/papers/2023/230804%20Retroformer.md)\n  140.", "start_char_idx": 261888, "end_char_idx": 264717, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c08e4b23-5352-40a4-a09b-259c53440965": {"__data__": {"id_": "c08e4b23-5352-40a4-a09b-259c53440965", "embedding": null, "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68f8468d-9422-45c4-af8e-1e2d6a0b910d", "node_type": "4", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "52abea362a3bea1eb951f3c7f85f6a7819e126d2716e66e4db39a2bc4782c80b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09d64c6e-651d-4432-b7d4-cd15b9c1be4e", "node_type": "1", "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}, "hash": "e72ca52923a45d79a5c9e4bd8b975803de186f8392415c077ff426ef413723da", "class_name": "RelatedNodeInfo"}}, "text": "[230729 Configuration System](/rosinality/ml-papers/blob/main/papers/2023/230729%20Configuration%20System.md)\n  137. [230803 H100 Supply and Demand](/rosinality/ml-papers/blob/main/papers/2023/230803%20H100%20Supply%20and%20Demand.md)\n  138. [230803 Multimodal Neurons in Pretrained Text-Only Transformers](/rosinality/ml-papers/blob/main/papers/2023/230803%20Multimodal%20Neurons%20in%20Pretrained%20Text-Only%20Transformers.md)\n  139. [230804 Retroformer](/rosinality/ml-papers/blob/main/papers/2023/230804%20Retroformer.md)\n  140. [230807 Intelligent Assistant Language Understanding On Device](/rosinality/ml-papers/blob/main/papers/2023/230807%20Intelligent%20Assistant%20Language%20Understanding%20On%20Device.md)\n  141. [230808 Gentopia](/rosinality/ml-papers/blob/main/papers/2023/230808%20Gentopia.md)\n  142. [230809 StableCode](/rosinality/ml-papers/blob/main/papers/2023/230809%20StableCode.md)\n  143. [230810 ReRoPE](/rosinality/ml-papers/blob/main/papers/2023/230810%20ReRoPE.md)\n  144. [210714 Deduplicating Training Data Makes Language Models Better](/rosinality/ml-papers/blob/main/papers/arXiv/210714%20Deduplicating%20Training%20Data%20Makes%20Language%20Models%20Better.md)\n  145. [211122 ExT5](/rosinality/ml-papers/blob/main/papers/arXiv/211122%20ExT5.md)\n  146. [230523 Aligning Large Language Models through Synthetic Feedback](/rosinality/ml-papers/blob/main/papers/arXiv/230523%20Aligning%20Large%20Language%20Models%20through%20Synthetic%20Feedback.md)\n\n## About\n\nMy collection of machine learning papers\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\n[ Activity ](/rosinality/ml-papers/activity)\n\n### Stars\n\n[ **255** stars ](/rosinality/ml-papers/stargazers)\n\n### Watchers\n\n[ **28** watching ](/rosinality/ml-papers/watchers)\n\n### Forks\n\n[ **21** forks ](/rosinality/ml-papers/forks)\n\n[ Report repository ](/contact/report-\ncontent?content_url=https%3A%2F%2Fgithub.com%2Frosinality%2Fml-\npapers&report=rosinality+%28user%29)\n\n##  [ Releases ](/rosinality/ml-papers/releases)\n\nNo releases published\n\n##  [ Packages 0 ](/users/rosinality/packages?repo_name=ml-papers)\n\nNo packages published  \n\n## Footer\n\n[ ](https://github.com \"GitHub\") (C) 2024 GitHub, Inc.\n\n### Footer navigation\n\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.", "start_char_idx": 264184, "end_char_idx": 266868, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"c9ef9b7c-6dd0-4935-a552-9b3674a6f388": {"node_ids": ["9e1bb884-42d3-4a53-b6fd-0c763c91b8ff"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-0.txt", "file_name": "output-0.txt", "file_type": "text/plain", "file_size": 61, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}, "7344652d-6789-4c15-96cc-ea8f7128b966": {"node_ids": ["e504fc55-ba53-482d-8ee8-08eb0be8e6f2", "951cb1fd-c1c1-48e4-9e60-c1db7e07330d"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-1.txt", "file_name": "output-1.txt", "file_type": "text/plain", "file_size": 4805, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}, "a0be635d-53c4-4af1-aa1f-159804d24d42": {"node_ids": ["c0b1c862-2f78-4caa-9563-fbf240184e19", "76e09f0d-354d-49eb-8183-61a2659bc563", "e0d9fd1d-07e8-459b-9e75-8fb3f251a5e8", "904ecbfa-69e9-4ab9-859c-d6fe5dbb6772", "df597bea-1054-4d7c-80a9-a79b03167424", "0e1af00a-a606-4caf-abe2-3c87351354ab", "6de95ee5-2f6b-4475-a7bc-5a0e045bbfac"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-2.txt", "file_name": "output-2.txt", "file_type": "text/plain", "file_size": 13531, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}, "7218ffec-ba1b-46eb-a4d8-47de9aebcd3b": {"node_ids": ["e9ce05d6-e33a-40d9-94b7-0d3187b003af", "ff8aada7-d24d-4eb8-bd37-d8bf6a2c07f1", "bfa1340d-53c2-4715-ba59-b0a5b404a84b", "03631b0e-5da0-4baa-8eb9-b90ff2c02826"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-3.txt", "file_name": "output-3.txt", "file_type": "text/plain", "file_size": 7223, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}, "93ad53d0-8842-433d-94f9-a8e6ad6c83b9": {"node_ids": ["128387ff-4463-4a80-9d22-f9b9393e8e1d", "8381e89e-3d9a-43ee-b0ce-0b28e3d6276b", "f6208959-dd0a-4c25-af91-3bb8b2e8e4a1", "fbf0b3ce-8fdd-4b54-aa50-91e99160d972"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-4.txt", "file_name": "output-4.txt", "file_type": "text/plain", "file_size": 6145, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}, "bee567a9-3d08-41be-a2ee-10c916f2455f": {"node_ids": ["774dad0b-ea64-4c36-b0f5-fcbd871218c3"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-5.txt", "file_name": "output-5.txt", "file_type": "text/plain", "file_size": 1344, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}, "736ffa74-53d0-4fef-ae17-a0ac147eb3f5": {"node_ids": ["b5b458c9-ec3d-4cfd-8e07-a4b30b392533", "77aaeb5f-e9bc-41a8-b6fc-6adce564b68e", "718a8243-5290-4bcc-9e58-53e28796a3a0"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-6.txt", "file_name": "output-6.txt", "file_type": "text/plain", "file_size": 7542, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}, "93745d78-19d1-453e-9c94-4b1fb5fb8cc8": {"node_ids": ["24719111-9af2-4786-8839-f72734d6dd93", "fdef97b7-bee4-478b-9056-9055c4a71454", "214a3f20-1676-40bd-b0b5-d84d9be7ff33"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-7.txt", "file_name": "output-7.txt", "file_type": "text/plain", "file_size": 9323, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}, "58c0404a-5344-4120-9114-567073e84eae": {"node_ids": ["0fee632c-f8a3-4512-9eea-6f99b0f2f33a", "6f341021-8fd7-4af6-bd3a-2f2f6518161a", "39a6f96e-0092-4108-9efe-e5188c4d7b5b", "653071b9-84f6-402b-a0a3-befc27ca14cb"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-8.txt", "file_name": "output-8.txt", "file_type": "text/plain", "file_size": 7494, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}, "68f8468d-9422-45c4-af8e-1e2d6a0b910d": {"node_ids": ["2bff4304-f47f-4130-a344-3f16f56915d1", "09837228-925f-41d0-a672-1e1a9d909905", "d6016afa-1808-40dc-8f75-b749e7750b53", "2ac50580-600c-4f0e-930b-e591e9190573", "2c8118d5-8ee6-459a-8d47-d0adeb7c88ea", "e4132a9e-01fc-4b83-a576-900a601a81dc", "63e78434-4316-43fc-98b4-bb5a102b5a82", "f6221846-2f0b-4d27-b2f5-d4764f14f363", "f50b83d7-83c4-4364-b9fb-c2c54c13a5d0", "29a3955f-1eec-4f21-b111-4a930a04fc57", "69e42855-2b5b-4a27-ae9a-c7a7a9b6a80e", "09e07a31-cbf9-4575-871f-82c65c439d4d", "7cc687bb-5bbf-4d3a-884a-b6d51734215d", "1796d83a-5be7-42b6-87ec-24399b21afa3", "1b4f63ef-c861-4800-9b23-19aa1867c6fc", "692dd480-b89f-44eb-bd18-a271fc308a31", "7847cd41-6bf2-496d-b331-006630532bf6", "48e7530b-4abb-43eb-ba42-8ed2c5d3d1f8", "f38f7c57-2595-4a26-a283-eac7b1493f8c", "de2f43e5-81a4-4b76-971b-09d56f830a0d", "67d5a9f1-b98f-4918-a691-2f09cd39b52e", "3f17c214-7ce9-4dd6-b23c-397afe8e3301", "841baa43-4d68-4b8a-ad99-515ea87d4970", "1b6938d8-518c-46ef-b824-4b68729c8e81", "f5cf9b75-38a5-4196-beb1-886352f4435f", "be75c88e-a3e8-4369-8907-b2abcd783d9f", "1a75e047-7241-4079-8bcf-e60eba7a861f", "81bd2cd9-2848-402a-b315-83f383fbb36d", "b608a4ed-8b87-4a28-abf0-352e0c6686ef", "a0491ea4-aae1-41e6-a26d-8b71db814d4c", "67b9db09-81af-43d4-8965-df9d05d9f063", "7bc9b8ba-5ded-4474-a89a-228102d65a56", "f4039ad2-a6cc-410a-9630-394c05fd647d", "69a56a7b-a5e4-4b28-a043-c10cedbcc356", "9436d80f-e285-41dd-a507-d4396bdf6e6a", "817185e1-164a-486b-9b0e-9001d23dd401", "3a006d69-c3e2-4b2d-9506-549de80c388a", "0518ea29-c4d0-4724-b871-7ef6d8871a87", "5b6693e2-a5f7-4b04-86d6-eabe2d477c67", "06d50fc6-c953-4536-bd20-2aac0f5a1f15", "8056d1a5-acb6-4b4a-8b6b-a230a1d06c92", "b63f9e37-bec9-4009-89f1-2c806e26e0ef", "034583f6-3a9c-4af9-a591-877e506b3c1c", "8c407867-9246-4b9e-9d39-f641013f4422", "c4cc42aa-331e-4ba2-aabd-b13525f0ef49", "f16f8843-d47c-4911-adda-d35456826266", "8d20577f-cabf-4d27-97d3-579525727cda", "1a6a2f28-3e5d-4526-8f79-37c9003e6d86", "6835c55a-f229-43ab-bbd5-87a292013817", "67b70369-c8bb-4188-bbc6-2d1e2fcf406a", "a552d385-eb25-4078-bcbe-a7fb7bbbe20d", "90b5691f-a8e1-4ce0-a541-c616310beed0", "ef2eb7f5-10af-4cc0-90dd-d8ba6cb3a618", "59212883-943f-4db3-ba9f-ff2a0a37b354", "395415da-c009-4a56-bf74-14767ffe2569", "0dba4b81-ac5e-4ddb-a599-19d7d06e467f", "b92b11b5-bc2f-44f1-b03e-6b6190be6468", "f3194d3d-ce89-4614-8cc8-8ca1ff19799e", "e4be4a19-c952-4fb3-a822-b74dc194db7a", "081ddc23-9b68-47d7-97df-e6b8144e70a6", "f792e19d-6df0-4c8e-9537-d1c8980950a1", "212c8633-e701-469a-b1f3-6a29b66ec871", "aab985eb-59c5-45de-b0d9-e916a7c38a5a", "01cce7b7-e903-49bd-b511-19b923474bf9", "85c04fbd-1a96-476f-89e5-234d7c3eaeea", "54945853-e802-4db1-b5a9-8ca6ebd8bfa6", "fe10d0cc-74fd-4188-bbe8-d31fe21b3a24", "7c64e9df-1a27-4c83-ae90-0045725d26d7", "017aad40-317b-4269-a124-46c7947efde7", "184affb0-5e02-4812-a443-37cf2d3b126e", "8bb03e2b-a7c8-47ed-aa3f-550a07cb0319", "20bbdb7a-ea09-4232-9ae0-93ef74b0485f", "6e29bc09-fd3d-432d-9621-09ca062d2689", "71697a0f-dcf8-4450-82e7-30355655667c", "f3d15e56-a243-4c8b-a1b3-eec78b49523a", "cbf26d84-2b36-463a-96f6-7b4bc7c975dc", "9fb52c0b-d599-4a2a-8ef9-fba163159f29", "5c578d8d-9d1f-425d-b9a7-87ed55410fe4", "ac0f355f-375b-470b-8436-d7c41c1f9043", "3c02b981-df4f-46ba-aeaa-9bfea91e9f5b", "5b9d14e5-9e26-4604-8dcc-510e81f136d8", "f7e3635b-8d04-4eed-88ed-dc1cae2abe74", "4f55b8aa-c792-49b5-9d80-64713df534c5", "48e1240f-8d2d-49b3-9dd1-f243a76b44e6", "b43bc357-06a4-47da-8f03-da3509491ea7", "ee0cfe5c-c3db-454b-9e13-33db1bab87f4", "0b35a892-6483-4111-adeb-2a1bea4fae9a", "e3d49e79-0357-45dd-b3b1-3d84ce5e7e19", "8ce21e9b-9a76-4a21-a3d9-a79f96cef94c", "901847c2-03d1-4186-b48b-7a6d047e1f4c", "88c3bbda-4050-4618-9836-9ef45dbb9eda", "bd9bf0d2-c2b1-4d1b-894b-4ac7416182b1", "e57147ab-9e3c-4c6b-bf0e-92f8c195843a", "2ebe27a4-ee28-4149-9743-85b59d08fd6b", "a2bfdb16-abbd-46ca-8849-e6d63bbb3f79", "0521a981-f013-442b-b558-120dbef93839", "4d6e1ecc-6a42-44bc-9e64-a625996cda4c", "aad62f9a-261f-4fac-a0d6-5f838a8e9328", "6c000b3c-f989-4b64-b81f-9e8bd376c891", "b9aba0a4-89b5-45fc-b3b2-62dcfa26196e", "5749cac3-dcf1-4276-895d-be27cbcde49f", "01708502-0de4-422b-b649-aab0c42b321f", "39e07a45-8390-477e-aca8-58c7b41415b4", "4b2e1dd2-e66c-4e6a-a4ec-ed43823045eb", "42a89060-e97c-493f-a919-89b378104baa", "940dc357-2574-4c07-af28-8b76e704d6ea", "561f6ebf-71de-4e6e-88af-09da27c698e0", "4c704a28-9bf2-48b4-8e0d-77ac3e48010e", "ac67d285-ba98-4f0d-b1f5-99b4ac3c5ffc", "09d64c6e-651d-4432-b7d4-cd15b9c1be4e", "c08e4b23-5352-40a4-a09b-259c53440965"], "metadata": {"file_path": "/nfs/home/seil/yaicon/data/instructblip/output-9.txt", "file_name": "output-9.txt", "file_type": "text/plain", "file_size": 267498, "creation_date": "2024-05-08", "last_modified_date": "2024-05-08"}}}}